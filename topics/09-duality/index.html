<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>09. Duality — Convex Optimization</title>
  <link rel="stylesheet" href="../../static/css/convex-unified.css" />
  <script src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css" />
  <script src="https://unpkg.com/feather-icons"></script>
</head>
<body>
  <header class="site-header sticky">
    <div class="container">
      <div class="brand">
        <a href="../../index.html">Convex Optimization</a>
      </div>
      <nav class="nav">
        <a href="../../index.html"><i data-feather="grid"></i> All Lectures</a>
        <a href="../08-convex-problems-conic/index.html"><i data-feather="arrow-left"></i> Previous</a>
        <a href="../10-approximation-fitting/index.html">Next <i data-feather="arrow-right"></i></a>
      </nav>
    </div>
  </header>

  <div class="lecture-container"><aside class="sidebar"><div id="toc-container"><h2><i data-feather="list"></i> Table of Contents</h2><nav id="toc"></nav></div></aside><main class="lecture-content">
    <header class="lecture-header section-card">
      <h1>09. Duality Theory</h1>
      <div class="lecture-meta">
        <span>Date: 2025-11-25</span>
        <span>Duration: 90 min</span>
        <span>Tags: duality, lagrangian, KKT, slater</span>
      </div>
      <div class="lecture-summary">
        <p><strong>Overview:</strong> This lecture presents the core of duality theory. We construct the Lagrangian dual function and prove weak and strong duality theorems. We derive the KKT conditions, interpret dual variables as shadow prices, and show how to use duality for sensitivity analysis and reformulation.</p>
        <p><strong>Prerequisites:</strong> <a href="../04-convex-sets-cones/index.html">Lecture 04: Convex Sets Cones</a> (separating hyperplane theorem), <a href="../06-convex-functions-advanced/index.html">Lecture 06: Advanced Functions</a> (conjugate functions).</p>
      </div>
    </header>

    <section class="section-card">
      <h2><i data-feather="target"></i> Learning Objectives</h2>
      <p>After this lecture, you will be able to:</p>
      <ul>
        <li>Construct the Lagrangian and Dual Function for any optimization problem</li>
        <li>State and prove Weak Duality and Slater's Condition for Strong Duality</li>
        <li>Derive KKT conditions and use them to solve problems analytically</li>
        <li>Interpret dual variables as sensitivities ("shadow prices")</li>
        <li>Compute duals of LP, QP, SOCP, and SDP problems</li>
      </ul>
    </section>

    <article>
      <section class="section-card" id="section-1">
      <h2>1. The Engine of Duality: Conjugates (Recap)</h2>
      <p>In <a href="../06-convex-functions-advanced/index.html">Lecture 06</a>, we defined the <b>Convex Conjugate</b> $f^*$ as the pointwise supremum of affine functions:
      $$ f^*(\mathbf{y}) = \sup_{\mathbf{x} \in \mathrm{dom} f} (\mathbf{y}^\top \mathbf{x} - f(\mathbf{x})) $$
      Geometric duality rests on this transformation. The conjugate $f^*(\mathbf{y})$ represents the maximum gap between the linear function $\mathbf{y}^\top \mathbf{x}$ and the function $f(\mathbf{x})$.</p>

      <h3>1.1 Key Properties for Duality</h3>
      <p>We recall two essential facts that drive the duality engine:</p>
      <ul>
        <li><b>Convexity:</b> $f^*$ is always convex (even if $f$ is not).</li>
        <li><b>Fenchel-Young Inequality:</b> For any $\mathbf{x}, \mathbf{y}$:
        $$ f(\mathbf{x}) + f^*(\mathbf{y}) \ge \mathbf{x}^\top \mathbf{y} $$
        Equality holds if and only if $\mathbf{y} \in \partial f(\mathbf{x})$. This inequality is the algebraic source of <b>Weak Duality</b> ($p^\star \ge d^\star$).</li>
      </ul>

      <h3>1.2 Support Functions</h3>
      <p>Constraints are modeled by indicator functions $I_C(\mathbf{x})$. Their conjugates are <b>Support Functions</b>:
      $$ \sigma_C(\mathbf{y}) = I_C^*(\mathbf{y}) = \sup_{\mathbf{x} \in C} \mathbf{y}^\top \mathbf{x} $$
      This explains why dual problems involve maximizing linear functions over convex sets.</p>
    </section>

    <section class="section-card" id="section-2">
        <h2>2. The Lagrangian</h2>

        <div class="insight">
          <h4>The Duality Story Arc</h4>
          <p>We are about to build a machine that converts "constraints" into "prices". Here is the logical chain:</p>
          <ol>
            <li><b>The Lagrangian</b> (§2): We "soften" hard constraints by turning them into linear penalties (prices/taxes).</li>
            <li><b>The Dual Function</b> (§3): By optimizing out the primal variables, we find the <i>best possible</i> lower bound on the optimal value for a given set of prices.</li>
            <li><b>The Dual Problem</b> (§4): We search for the <i>optimal prices</i> that give the tightest lower bound.</li>
            <li><b>KKT Conditions</b> (§5): At optimality, the forces balance perfectly—the gradient of the objective is exactly cancelled by the gradient of the constraints weighted by their optimal prices.</li>
          </ol>
        </div>

        <h3>2.1 Standard Form Primal Problem</h3>
        <p>We consider an optimization problem in standard form (not necessarily convex):</p>
        <div style="padding: 16px; background: var(--panel); border-left: 4px solid var(--brand); margin: 16px 0;">
          <p style="margin: 0;">
            $
            \begin{aligned}
            \text{minimize} \quad & f_0(\mathbf{x}) \\
            \text{subject to} \quad & f_i(\mathbf{x}) \le 0, \quad i = 1, \dots, m \\
            & h_j(\mathbf{x}) = 0, \quad j = 1, \dots, p
            \end{aligned}
            $
          </p>
        </div>
        <p>Variable $\mathbf{x} \in \mathbb{R}^n$, domain $\mathcal{D} = \bigcap \mathrm{dom}\, f_i \cap \bigcap \mathrm{dom}\, h_j$. Optimal value $p^*$.</p>

        <h3>2.2 The Lagrangian Function</h3>
        <p>The <a href="#" class="definition-link">Lagrangian</a> $L: \mathbb{R}^n \times \mathbb{R}^m \times \mathbb{R}^p \to \mathbb{R}$ augments the objective with a weighted sum of constraints:</p>
        $$
        L(\mathbf{x}, \lambda, \nu) = f_0(\mathbf{x}) + \sum_{i=1}^m \lambda_i f_i(\mathbf{x}) + \sum_{j=1}^p \nu_j h_j(\mathbf{x})
        $$
        <p>where $\lambda_i$ is the Lagrange multiplier associated with $f_i(\mathbf{x}) \le 0$, and $\nu_j$ with $h_j(\mathbf{x}) = 0$.
        <br>Domain: $\mathrm{dom}\, L = \mathcal{D} \times \mathbb{R}^m \times \mathbb{R}^p$.</p>

        <div class="example">
          <h4>Motivating Example: Primal Dual Optimization Walkthrough</h4>
          <p>Consider the simple problem:
          $$ \min_{x,y} x^2 + y^2 \quad \text{subject to} \quad x+y \ge 1 $$
          <br><b>1. Primal Problem:</b> The feasible region is the half-plane $x+y \ge 1$. The level sets of the objective are circles centered at the origin. Geometrically, the minimum is the point on the line $x+y=1$ closest to the origin, which is $(0.5, 0.5)$, yielding $p^* = 0.5$.</p>
          <p><b>2. Lagrangian:</b> $L(x, y, \lambda) = x^2 + y^2 + \lambda(1 - x - y)$. (Note the constraint $1-x-y \le 0$).</p>
          <p><b>3. Dual Function:</b> Minimize $L$ over unconstrained $x, y$:
          $$ \nabla_x L = 2x - \lambda = 0 \implies x^* = \lambda/2, \quad y^* = \lambda/2 $$
          $$ g(\lambda) = (\lambda/2)^2 + (\lambda/2)^2 + \lambda(1 - \lambda) = \lambda^2/2 + \lambda - \lambda^2 = \lambda - \lambda^2/2 $$</p>
          <p><b>4. Dual Problem:</b> Maximize $g(\lambda) = \lambda - \lambda^2/2$ for $\lambda \ge 0$.
          <br>$\nabla g = 1 - \lambda = 0 \implies \lambda^* = 1$.
          <br>Dual optimal value $d^* = g(1) = 1 - 0.5 = 0.5$.</p>
          <p><b>Result:</b> $p^* = d^* = 0.5$. Strong duality holds.</p>
        </div>

        <div class="insight">
          <h4>Idea: Lower Bound Property</h4>
          <p>For any feasible $\mathbf{x}$ and any $\lambda \succeq 0, \nu$, we have:
          $$ \sum \lambda_i f_i(x) \le 0 \quad \text{and} \quad \sum \nu_j h_j(x) = 0 $$
          Thus, $L(x, \lambda, \nu) \le f_0(x)$. The Lagrangian is a <b>pointwise underestimator</b> of the objective function on the feasible set.</p>
        </div>

        <h3>2.3 The Minimax (Saddle Point) Interpretation</h3>
        <p>We can recover the primal problem from the Lagrangian by maximizing over the dual variables. Define the function:</p>
        $$
        \sup_{\lambda \succeq 0, \nu} L(x, \lambda, \nu) = \sup_{\lambda \succeq 0, \nu} \left( f_0(x) + \sum \lambda_i f_i(x) + \sum \nu_j h_j(x) \right)
        $$
        <ul>
          <li><strong>If $\mathbf{x}$ is feasible:</strong> $f_i(\mathbf{x}) \le 0$ and $h_j(\mathbf{x})=0$. To maximize the sum, the best we can do is set $\lambda_i=0$ (since $\lambda_i \ge 0$ and $f_i(\mathbf{x}) \le 0$, any positive $\lambda$ would make the term negative). The $\nu$ term is always 0. Thus, the supremum is $f_0(\mathbf{x})$.</li>
          <li><strong>If $\mathbf{x}$ is infeasible:</strong>
            <ul>
              <li>If $f_i(x) > 0$, we can let $\lambda_i \to \infty$, making the sum $\infty$.</li>
              <li>If $h_j(x) \ne 0$, we can let $\nu_j \to \text{sign}(h_j(x)) \cdot \infty$, making the sum $\infty$.</li>
            </ul>
          </li>
        </ul>
        <p>Thus, the unconstrained problem $\min_x \sup_{\lambda \succeq 0, \nu} L(x, \lambda, \nu)$ is exactly equivalent to the original constrained primal problem.</p>
        <div class="intuition-box">
          <p><b>Duality as a Game:</b>
          <br><b>Primal:</b> $\min_x \max_{\lambda, \nu} L(x, \lambda, \nu)$ (Minimizer moves first, Maximizer exploits violations).
          <br><b>Dual:</b> $\max_{\lambda, \nu} \min_x L(x, \lambda, \nu)$ (Maximizer moves first, setting prices; Minimizer optimizes given prices).
          <br><b>Weak Duality</b> is simply the max-min inequality: $\max_{\lambda, \nu} \min_x L(x, \lambda, \nu) \le \min_x \max_{\lambda, \nu} L(x, \lambda, \nu)$. This inequality holds for <em>any</em> function, not just Lagrangians.
          <br><b>Strong Duality</b> implies the existence of a <b>Saddle Point</b> where the order of play doesn't matter, i.e., we can swap min and max.</p>
          <p>Consider a simple resource allocation example. The Primal seeks to minimize cost subject to meeting demand. The Dual sets prices for resources to maximize revenue while staying competitive. Strong duality means the minimum cost equals the maximum revenue, and the dual prices (shadow prices) reflect the true marginal value of the resources.</p>
        </div>

        <div class="theorem-box">
            <h4>Deep Dive: Minimax Theorem and Zero-Sum Games</h4>
            <p>The duality gap for convex problems is intimately related to von Neumann's Minimax Theorem.
            <br>For a matrix game with payoff matrix $A$, player 1 minimizes loss $x^\top A y$ and player 2 maximizes gain.
            $$ \min_{x \in \Delta} \max_{y \in \Delta} x^\top A y = \max_{y \in \Delta} \min_{x \in \Delta} x^\top A y $$
            Linear programming duality is essentially the statement that this equality holds for linear constraints. Lagrangian duality extends this logic to general convex functions.</p>
        </div>
      </section>

      <section class="section-card" id="section-3">
        <h2>3. The Lagrange Dual Function</h2>

        <h3>3.1 Definition</h3>
        <p>The <a href="#" class="definition-link">Lagrange dual function</a> $g: \mathbb{R}^m \times \mathbb{R}^p \to \mathbb{R}$ is the minimum value of the Lagrangian over $\mathbf{x}$:
        $$
        g(\lambda, \nu) = \inf_{x \in \mathcal{D}} L(x, \lambda, \nu) = \inf_{x \in \mathcal{D}} \left( f_0(x) + \sum_{i=1}^m \lambda_i f_i(x) + \sum_{j=1}^p \nu_j h_j(x) \right)
        $$
        </p>

        <div class="theorem-box">
          <h4>Key Property: Concavity</h4>
          <p>The dual function $g(\lambda, \nu)$ is <b>concave</b>, even if the primal problem is not convex.</p>
          <div class="proof-box">
            <h4>Proof</h4>
            <p>For each fixed $\mathbf{x}$, the function $(\lambda, \nu) \mapsto L(\mathbf{x}, \lambda, \nu)$ is affine in $(\lambda, \nu)$.
            <br>The dual function $g$ is the pointwise infimum of a family of affine functions.
            <br>The infimum of concave (linear) functions is concave.</p>
          </div>
        </div>

        <div class="insight">
          <h4>Why the Dual is Always Convex (Even When the Primal is Not)</h4>
          <p>This is a fundamental fact that deserves emphasis. The dual problem:</p>
          $$ \max_{\lambda \succeq 0, \nu} g(\lambda, \nu) $$
          <p>is <b>always a convex optimization problem</b>:</p>
          <ul>
            <li>The domain $\{\lambda \succeq 0\}$ is a convex set (the non-negative orthant).</li>
            <li>Maximizing a concave function is equivalent to minimizing a convex function.</li>
          </ul>
          <p><b>The "One-Line" Proof:</b> For any $\lambda_1, \lambda_2 \ge 0$ and $\theta \in [0,1]$:
          $$ g(\theta\lambda_1 + (1-\theta)\lambda_2) = \inf_x L(x, \theta\lambda_1 + (1-\theta)\lambda_2) = \inf_x [\theta L(x,\lambda_1) + (1-\theta) L(x,\lambda_2)] $$
          $$ \ge \theta \inf_x L(x,\lambda_1) + (1-\theta) \inf_x L(x,\lambda_2) = \theta g(\lambda_1) + (1-\theta) g(\lambda_2) $$
          The inequality holds because $\inf$ of a convex combination is at least the convex combination of $\inf$s.</p>
          <p><b>Geometric Intuition:</b> For each fixed $x$, the Lagrangian is a "hyperplane" in $(\lambda, \nu)$-space. The dual function is the <b>lower envelope</b> of these hyperplanes. Lower envelopes of affine functions are always concave, regardless of the original problem's structure.</p>
        </div>
        
        <div class="proof-box">
          <h4>Deep Dive: Deriving the Dual via Conjugates</h4>
          <p>We derive the dual of $\min c^\top x$ s.t. $f(x) \le 0$ step-by-step.</p>
          <div class="proof-step">
            <strong>1. Lagrangian:</strong> $L(x, \lambda) = c^\top x + \lambda f(x)$. Dual function $g(\lambda) = \inf_x (c^\top x + \lambda f(x))$.
          </div>
          <div class="proof-step">
            <strong>2. Factor out $\lambda > 0$:</strong>
            $$ g(\lambda) = \lambda \inf_x \left( f(x) + \frac{1}{\lambda}c^\top x \right) $$
          </div>
          <div class="proof-step">
            <strong>3. Apply Conjugate Identity:</strong>
            Use the identity $\inf_z (f(z) + y^\top z) = -f^*(-y)$.
            Here $y = c/\lambda$.
            $$ \inf_x \left( f(x) + \frac{c^\top x}{\lambda} \right) = -f^*\left(-\frac{c}{\lambda}\right) $$
          </div>
          <div class="proof-step">
            <strong>4. Result:</strong>
            $$ \boxed{g(\lambda) = -\lambda f^*\left(-\frac{c}{\lambda}\right)} $$
            This is the (negative) perspective of the conjugate function $f^*$. Since $f^*$ is convex, its perspective is convex. Thus $g(\lambda)$ is concave.
          </div>
        </div>

        <h3>3.2 Lower Bound on Optimal Value</h3>
        <p>For any $\lambda \succeq 0$ and any $\nu$, we have:</p>
        $$ g(\lambda, \nu) \le p^* $$
        <div class="proof-box">
          <h4>Proof</h4>
          <p>Let $x^*$ be an optimal feasible solution. By definition of the infimum:
          $$ g(\lambda, \nu) = \inf_x L(x, \lambda, \nu) \le L(x^*, \lambda, \nu) $$
          Expanding the Lagrangian at the optimal point:
          $$ L(x^*, \lambda, \nu) = f_0(x^*) + \sum_{i=1}^m \lambda_i f_i(x^*) + \sum_{j=1}^p \nu_j h_j(x^*) $$
          Since $x^*$ is feasible, $h_j(x^*) = 0$ for all $j$. Also $f_i(x^*) \le 0$. Given $\lambda_i \ge 0$, we have $\lambda_i f_i(x^*) \le 0$. Thus:
          $$ L(x^*, \lambda, \nu) \le f_0(x^*) + 0 + 0 = p^* $$
          Combining the inequalities gives $g(\lambda, \nu) \le p^*$.</p>
        </div>

        <h3>3.3 Examples of Dual Functions</h3>

        <div class="example">
          <h4>1. Least Squares (Quadratic)</h4>
          <p>Primal: $\min x^\top x$ subject to $Ax = b$.
          <br>Lagrangian: $L(x, \nu) = x^\top x + \nu^\top (Ax - b)$.
          <br>Minimize over $\mathbf{x}$: $\nabla_{\mathbf{x}} L = 2\mathbf{x} + A^\top \nu = 0 \implies \mathbf{x} = -A^\top \nu / 2$.
          <br>Substitute back:
          $$ g(\nu) = L(-A^\top \nu / 2, \nu) = \frac{1}{4} \nu^\top A A^\top \nu + \nu^\top (A(-A^\top \nu / 2) - b) $$
          $$ = \frac{1}{4} \|\nu^\top A\|^2 - \frac{1}{2} \|\nu^\top A\|^2 - \nu^\top b = -\frac{1}{4} \nu^\top A A^\top \nu - b^\top \nu $$
          This is a concave quadratic function of $\nu$.
          <br>Dual Problem: Maximize $g(\nu)$. Unconstrained quadratic maximization.</p>
        </div>

        <div class="example">
          <h4>2. Linear Program (Standard Form)</h4>
          <p>Primal: $\min c^\top x$ s.t. $Ax = b, x \ge 0$.
          <br>Constraints: $h(x) = Ax - b$, $f(x) = -x$.
          <br>Lagrangian: $L(x, \lambda, \nu) = c^\top x - \sum \lambda_i x_i + \nu^\top (Ax - b) = -b^\top \nu + (c + A^\top \nu - \lambda)^\top x$.
          <br>Dual function:
          $$ g(\lambda, \nu) = \inf_{x} L(x, \lambda, \nu) = \begin{cases} -b^\top \nu & \text{if } c + A^\top \nu - \lambda = 0 \\ -\infty & \text{otherwise} \end{cases} $$
          Dual Problem: Maximize $-b^\top \nu$ subject to $A^\top \nu + c = \lambda, \lambda \ge 0$.
          <br>Eliminating $\lambda$: Maximize $-b^\top \nu$ subject to $A^\top \nu + c \ge 0$ (i.e., $A^\top (-\nu) \le c$).
          <br>Usually written with $y = -\nu$: Maximize $b^\top y$ s.t. $A^\top y \le c$. Standard LP dual.</p>
        </div>

        <div class="example">
          <h4>3. Conjugate Functions</h4>
          <p>Primal: $\min f(x)$ subject to $x = 0$ (constraint $x=0$).
          <br>Lagrangian: $L(x, \nu) = f(x) + \nu^\top x$.
          <br>Dual function: $g(\nu) = \inf_x (f(x) + \nu^\top x) = -\sup_x ((-\nu)^\top x - f(x)) = -f^*(-\nu)$.
          <br>Here, the dual function is directly related to the <b>convex conjugate</b>.</p>
        </div>

        <div style="margin-top: 24px; border: 1px solid rgba(255,255,255,0.1); border-radius: 8px; overflow: hidden;">
          <iframe src="widgets/conjugate_function.html" width="100%" height="520" style="border:none; background:#0b0d12;"></iframe>
        </div>
      </section>

      <section class="section-card" id="section-3">
        <h2>4. The Dual Problem</h2>

        <h3>4.1 Definition</h3>
        <p>The <a href="#" class="definition-link">Lagrange dual problem</a> is to find the best lower bound on $p^*$:</p>
        <div style="padding: 16px; background: var(--panel); border-left: 4px solid var(--brand); margin: 16px 0;">
          <p style="margin: 0;">
            $
            \begin{aligned}
            \text{maximize} \quad & g(\lambda, \nu) \\
            \text{subject to} \quad & \lambda \succeq 0
            \end{aligned}
            $
          </p>
        </div>
        <p>This is a <b>convex optimization problem</b> (concave maximization is equivalent to convex minimization), regardless of the primal's properties.</p>

        <h3>4.2 Weak Duality</h3>
        <p>Let $d^*$ be the optimal value of the dual problem. The weak duality theorem states:</p>
        $$ \boxed{ d^* \le p^* } $$
        <p>This holds for <b>any</b> optimization problem. The difference $p^* - d^*$ is called the <b>duality gap</b>.</p>

        <div style="margin: 24px 0; border: 1px solid rgba(255,255,255,0.1); border-radius: 8px; overflow: hidden;">
          <iframe src="widgets/primal_dual_1d.html" width="100%" height="520" style="border:none; background:#0b0d12;"></iframe>
        </div>

        <div class="example">
            <h4>Example: Non-Convex Problem with Duality Gap</h4>
            <p>We illustrate the duality gap with a simple discrete optimization problem where the feasible set is not convex.</p>
            <p><b>Primal Problem:</b>
            $$ \min x \quad \text{s.t.} \quad 2x = 1, \ x \in \{0, 1\} $$
            The constraint $2x=1$ requires $x=0.5$, but the domain is $\{0, 1\}$. Thus, the problem is infeasible and $p^* = +\infty$.</p>

            <p><b>Lagrangian:</b>
            $$ L(x, \nu) = x + \nu(1 - 2x) = (1-2\nu)x + \nu $$
            </p>

            <p><b>Dual Function:</b>
            The dual function minimizes the Lagrangian over the domain $D=\{0, 1\}$:
            $$ g(\nu) = \inf_{x \in \{0, 1\}} ((1-2\nu)x + \nu) = \min((1-2\nu)(0) + \nu, (1-2\nu)(1) + \nu) = \min(\nu, 1-\nu) $$
            </p>

            <p><b>Dual Problem:</b>
            Maximize $g(\nu) = \min(\nu, 1-\nu)$. The maximum occurs at $\nu = 0.5$, yielding $d^* = 0.5$.</p>

            <p><b>Result:</b> $p^* - d^* = \infty - 0.5 = \infty$. The duality gap is infinite, demonstrating that strong duality can fail for non-convex problems.</p>
        </div>

        <h3>4.3 Strong Duality and Slater's Condition</h3>
        <p>Strong duality means $d^* = p^*$ (zero duality gap). It does not hold generally but usually holds for convex problems under mild conditions.</p>

        <div class="theorem-box">
          <h4>Theorem (Slater's Condition)</h4>
          <p>For a convex optimization problem:
          $$ \min f_0(x) \quad \text{s.t.} \quad f_i(x) \le 0, \quad Ax = b $$
          If there exists a point $x \in \mathrm{relint}(\mathcal{D})$ such that:
          $$ f_i(x) < 0, \quad i=1,\dots,m, \quad Ax = b $$
          (strictly feasible for non-affine inequalities), then <b>strong duality holds</b> ($d^* = p^*$) and the dual optimal value is attained (if $p^* > -\infty$).</p>
        </div>

        <div class="proof-box">
          <h4>Geometric Proof via Separation</h4>
          <p>This proof constructs the dual variables as the coefficients of a separating hyperplane in the space of (constraints, objective).</p>
          <div class="proof-step">
            <strong>Step 1: The Set of Achievable Values $\mathcal{A}$.</strong>
            Consider the set of triplets $(u, v, t)$ that are "worse" than some feasible point $\mathbf{x}$:
            $$ \mathcal{A} = \{ (u, v, t) \mid \exists x \in \mathcal{D}, f_i(x) \le u_i, h_j(x) = v_j, f_0(x) \le t \} $$
            This set is convex (it's the projection of the epigraph of the problem).
          </div>
          <div class="proof-step">
            <strong>Step 2: Separation.</strong>
            The point $(0, 0, p^*)$ is on the boundary of $\mathcal{A}$. The set $\mathcal{A}$ does not contain any point with $u \le 0, v=0, t < p^*$.
            By the <a href="../03-convex-sets-geometry/index.html#section-3">Separating Hyperplane Theorem</a>, there exists a non-zero vector $(\lambda, \nu, \mu)$ such that for all $(u, v, t) \in \mathcal{A}$:
            $$ \lambda^\top u + \nu^\top v + \mu t \ge \lambda^\top 0 + \nu^\top 0 + \mu p^* = \mu p^* $$
            Analyzing directions $u \to \infty$ and $t \to \infty$ implies $\lambda \succeq 0$ and $\mu \ge 0$.
          </div>
          <div class="proof-step">
            <strong>Step 3: Slater's Condition implies Non-Verticality ($\mu > 0$).</strong>
            Suppose $\mu = 0$. The inequality becomes $\sum \lambda_i f_i(\mathbf{x}) + \sum \nu_j h_j(\mathbf{x}) \ge 0$ for all $\mathbf{x}$.
            Applying this to the Slater point $\tilde{x}$ (where $f_i(\tilde{x}) < 0$):
            $$ \sum \lambda_i \underbrace{f_i(\tilde{x})}_{< 0} + 0 \ge 0 $$
            Since $\lambda_i \ge 0$, this forces $\lambda = 0$.
            If $\lambda=0, \mu=0$, then $\nu^\top (A\mathbf{x}-\mathbf{b}) \ge 0$ for all $\mathbf{x}$, which implies $A^\top \nu = 0$. If $A$ is full rank, $\nu=0$.
            This contradicts $(\lambda, \nu, \mu) \ne 0$. Thus $\mu > 0$.
          </div>
          <div class="proof-step">
            <strong>Step 4: Recovering Strong Duality.</strong>
            Divide the separation inequality by $\mu$. Let $\tilde{\lambda} = \lambda/\mu, \tilde{\nu} = \nu/\mu$.
            $$ f_0(x) + \sum \tilde{\lambda}_i f_i(x) + \sum \tilde{\nu}_j h_j(x) \ge p^* \quad \forall x \in \mathcal{D} $$
            Taking the infimum over $\mathbf{x}$, we get $g(\tilde{\lambda}, \tilde{\nu}) \ge p^*$.
            Thus the dual optimal value $d^*$ is at least $p^*$. Since $d^* \le p^*$ always (weak duality), we conclude $d^* = p^*$.
          </div>
        </div>
      </section>

      <section class="section-card" id="section-4">
        <h2>5. KKT Conditions</h2>

        <p>The Karush-Kuhn-Tucker (KKT) conditions provide a unified framework for optimality. For convex problems, they are necessary and sufficient.</p>

        <div class="theorem-box">
          <h4>Theorem (KKT Conditions)</h4>
          <p>Given a convex problem with differentiable functions that satisfies Slater's condition. $x^*$ and $(\lambda^*, \nu^*)$ are primal and dual optimal <b>if and only if</b>:</p>
          <ol>
            <li><b>Primal Feasibility:</b> $f_i(x^*) \le 0$, $h_j(x^*) = 0$.</li>
            <li><b>Dual Feasibility:</b> $\lambda^* \succeq 0$.</li>
            <li><b>Complementary Slackness:</b> $\lambda_i^* f_i(x^*) = 0$ for all $i$.</li>
            <li><b>Stationarity (Lagrangian Gradient):</b> $\nabla_x L(x^*, \lambda^*, \nu^*) = 0$:
              $$ \nabla f_0(x^*) + \sum \lambda_i^* \nabla f_i(x^*) + \sum \nu_j^* \nabla h_j(x^*) = 0 $$
            </li>
          </ol>
        </div>

        <div class="insight">
          <h4>Geometric Interpretation via Normal Cones</h4>
          <p>The stationarity condition $0 \in \nabla f_0(x^*) + \sum \lambda_i \nabla f_i(x^*) + \sum \nu_j \nabla h_j(x^*)$ has a deep geometric meaning:
          $$ -\nabla f_0(x^*) \in N_{\mathcal{F}}(x^*) $$
          The negative gradient of the objective must lie in the <b>normal cone</b> of the feasible set at the optimal point. KKT simply expresses this normal vector as a linear combination of constraint gradients, provided a constraint qualification (like Slater's) holds.</p>
        </div>

        <div class="insight">
          <h4>Preview: KKT Conditions as the Algorithm's Goal</h4>
          <p>Most convex optimization algorithms are just different ways of finding a point that satisfies the KKT conditions:</p>
          <ul>
            <li><b>Unconstrained Problems:</b> KKT reduces to $\nabla f_0(x) = 0$. <b>Gradient Descent</b> tries to find this point iteratively.</li>
            <li><b>Equality Constrained (QP/Linear):</b> KKT becomes a system of linear equations. <b>Newton's Method</b> solves this system directly (or iteratively).</li>
            <li><b>Inequality Constrained:</b> The complementary slackness condition $\lambda_i f_i(x) = 0$ is hard (combinatorial). <b>Interior-Point Methods</b> replace it with a perturbed condition $\lambda_i f_i(x) = -1/t$ and solve the sequence of smooth approximations as $t \to \infty$.</li>
          </ul>
        </div>

        <div class="proof-box">
          <h4>Derivation from Strong Duality</h4>
          <p>Assume strong duality holds ($p^* = d^*$) and let $x^*$ and $(\lambda^*, \nu^*)$ be primal and dual optimal.</p>
          <div class="proof-step">
            <strong>The Duality Sandwich:</strong>
            We construct a chain of inequalities starting from the optimal dual value and ending at the optimal primal value.
            $$
            \begin{aligned}
            d^* &= g(\lambda^*, \nu^*) \quad \text{(Definition of Dual Optimal)} \\
            &= \inf_x \left( f_0(x) + \sum \lambda_i^* f_i(x) + \sum \nu_j^* h_j(x) \right) \quad \text{(Definition of Dual Function)} \\
            &\le f_0(x^*) + \sum \lambda_i^* f_i(x^*) + \sum \nu_j^* h_j(x^*) \quad \text{(Infimum is } \le \text{ value at } x^*) \\
            &\le f_0(x^*) \quad \text{(Since } \lambda^* \ge 0 \text{ and } f_i(x^*) \le 0 \text{, the sum is } \le 0) \\
            &= p^* \quad \text{(Definition of Primal Optimal)}
            \end{aligned}
            $$
            Because Strong Duality holds ($d^* = p^*$), the start and end of this chain are equal. This forces <b>every inequality in the middle to be an equality</b>.
          </div>
          <div class="proof-step">
            <strong>Conclusion 1: Stationarity.</strong>
            The inequality $\inf_x L(x, \lambda^*, \nu^*) \le L(x^*, \lambda^*, \nu^*)$ becomes an equality.
            This implies that $\mathbf{x}^*$ is a global minimizer of the Lagrangian function $L(\mathbf{x}, \lambda^*, \nu^*)$ with respect to $\mathbf{x}$.
            If the functions are differentiable, the gradient at a global minimizer (of an unconstrained problem) must be zero:
            $$ \nabla_x L(x^*, \lambda^*, \nu^*) = 0 $$
          </div>
          <div class="proof-step">
            <strong>Conclusion 2: Complementary Slackness.</strong>
            The inequality $L(x^*, \lambda^*, \nu^*) \le f_0(x^*)$ is also an equality. This means:
            $$ \sum_{i=1}^m \lambda_i^* f_i(x^*) = 0 $$
            Since every term $\lambda_i^* f_i(x^*)$ is non-positive (product of $\ge 0$ and $\le 0$), the sum can only be zero if <b>every single term is zero</b>.
            $$ \lambda_i^* f_i(x^*) = 0, \quad \forall i $$
          </div>
        </div>

        <div class="example">
          <h4>Application: Water-Filling (Channel Capacity)</h4>
          <p>Problem: $\min -\sum \log(\alpha_i + x_i)$ subject to $x \ge 0, \sum x_i = 1$.
          <br>Lagrangian: $L = -\sum \log(\alpha_i + x_i) - \sum \lambda_i x_i + \nu (\sum x_i - 1)$.
          <br>Stationarity: $\frac{-1}{\alpha_i + x_i} - \lambda_i + \nu = 0 \implies \alpha_i + x_i = \frac{1}{\nu - \lambda_i}$.
          <br>Complementary Slackness: $\lambda_i x_i = 0$.
          <ul>
            <li>If $x_i > 0$, then $\lambda_i = 0 \implies \alpha_i + x_i = 1/\nu$.</li>
            <li>If $x_i = 0$, then $\alpha_i = 1/(\nu-\lambda_i)$. Since $\lambda_i \ge 0$, $\nu - \lambda_i \le \nu$, so $1/(\nu-\lambda_i) \ge 1/\nu$. Thus $\alpha_i \ge 1/\nu$.</li>
          </ul>
          Result: $x_i = \max(0, 1/\nu - \alpha_i)$. This is "water-filling" on the levels $\alpha_i$. We solve for $\nu$ such that $\sum x_i = 1$.</p>
        </div>
      </section>

      <section class="section-card" id="section-5">
        <h2>6. Perturbation and Sensitivity Analysis</h2>

        <p>Duality provides powerful insights into how the optimal value changes when constraints are perturbed.</p>

        <h3>6.1 The Value Function (Perturbation Function)</h3>
        <p>Consider the perturbed primal problem with optimal value $p^*(u, v)$:</p>
        $$
        \begin{aligned}
        \min \quad & f_0(x) \\
        \text{s.t.} \quad & f_i(x) \le u_i, \quad i=1\dots m \\
        & h_j(x) = v_j, \quad j=1\dots p
        \end{aligned}
        $$
        <p>Here $u \in \mathbb{R}^m$ relaxes the inequalities, and $v \in \mathbb{R}^p$ shifts the equalities. The original optimal value is $p^*(0, 0)$.
        <br><b>Domain Honesty:</b> This is an extended-real function $p^*: \mathbb{R}^{m+p} \to \mathbb{R} \cup \{+\infty, -\infty\}$. If perturbations make the problem infeasible, $p^*(u, v) = +\infty$.</p>

        <h3>6.2 Convexity of the Value Function</h3>
        <p>If the original problem is convex (convex $f_0, f_i$, affine $h_j$), then $p^*(u, v)$ is a <b>convex function</b> of $(u, v)$.</p>
        <div class="proof-box">
          <h4>Proof: Epigraph as Projection</h4>
          <p>The epigraph of $p^*$ is defined as $\text{epi } p^* = \{(u, v, t) \mid p^*(u, v) \le t\}$.
          <br>By definition of the infimum, $p^*(u, v) \le t$ if and only if there exists some $\mathbf{x}$ such that:
          $$ f_0(x) \le t, \quad f_i(x) \le u_i, \quad Ax - b = v $$
          Thus, the epigraph is the <b>projection</b> onto $(u, v, t)$ of the set:
          $$ \mathcal{S} = \{(x, u, v, t) \mid f_0(x) \le t, \ f_i(x) \le u_i, \ Ax - b = v\} $$
          Since $f_i$ are convex, the inequalities define convex sets. The equality is affine. Thus $\mathcal{S}$ is a convex set.
          <br>Since the projection of a convex set is convex, $\text{epi } p^*$ is convex. Therefore $p^*(u, v)$ is a convex function.</p>
        </div>

        <h3>6.3 Global Inequality (Subgradient Interpretation)</h3>
        <p>We derive a global lower bound on the value function using the dual function of the perturbed problem.</p>
        <div class="proof-box">
          <h4>Derivation via Perturbed Lagrangian</h4>
          <div class="proof-step">
            <strong>Step 1: Perturbed Lagrangian.</strong>
            $$ L(x, \lambda, \nu; u, v) = f_0(x) + \sum \lambda_i (f_i(x) - u_i) + \sum \nu_j (h_j(x) - v_j) $$
            $$ = L(x, \lambda, \nu) - \lambda^\top u - \nu^\top v $$
          </div>
          <div class="proof-step">
            <strong>Step 2: Perturbed Dual Function.</strong>
            Taking the infimum over $\mathbf{x}$:
            $$ g(\lambda, \nu; u, v) = g(\lambda, \nu) - \lambda^\top u - \nu^\top v $$
          </div>
          <div class="proof-step">
            <strong>Step 3: Weak Duality.</strong>
            For any dual feasible $(\lambda, \nu)$ ($\lambda \ge 0$), weak duality applies to the perturbed problem:
            $$ p^*(u, v) \ge g(\lambda, \nu; u, v) = g(\lambda, \nu) - \lambda^\top u - \nu^\top v $$
          </div>
          <div class="proof-step">
            <strong>Step 4: Strong Duality.</strong>
            If strong duality holds for the original problem at $u=0, v=0$, then $p^*(0, 0) = g(\lambda^*, \nu^*)$.
            Substituting the optimal dual variables into the inequality:
            $$ p^*(u, v) \ge p^*(0, 0) - \lambda^{*\top} u - \nu^{*\top} v $$
          </div>
        </div>

        <div class="theorem-box">
          <h4>Theorem: Optimal Multipliers as Subgradients</h4>
          <p>The inequality derived above is exactly the definition of a subgradient for the convex function $p^*(u, v)$ at $(0, 0)$. Thus:</p>
          $$ \boxed{ (-\lambda^*, -\nu^*) \in \partial p^*(0, 0) } $$
          <p><b>Shadow Price Interpretation:</b>
          <ul>
            <li>Since $p^*(u, v)$ is convex, a subgradient gives a global lower bound.</li>
            <li>$\lambda_i^* \ge 0$. Relaxing constraint $i$ ($u_i > 0$) lowers the optimal value. $\lambda_i^*$ is the rate of this improvement.</li>
            <li>If $p^*$ is differentiable, then $\frac{\partial p^*}{\partial u_i} = -\lambda_i^*$ and $\frac{\partial p^*}{\partial v_j} = -\nu_j^*$. The Lagrange multipliers are exactly the <strong>sensitivity</strong> of the optimal value to constraint perturbations.</li>
          </ul>
          </p>
        </div>

        <h3>6.4 Local Sensitivity</h3>
        <p>If $p^*(u, v)$ is differentiable at $(0, 0)$, then:</p>
        $$ \frac{\partial p^*(0, 0)}{\partial u_i} = -\lambda_i^*, \quad \frac{\partial p^*(0, 0)}{\partial v_j} = -\nu_j^* $$
        <p>Relaxing constraint $i$ ($u_i > 0$) improves the objective by approximately $\lambda_i^* u_i$. Tightening it ($u_i < 0$) worsens it.</p>
      </section>

      <section class="section-card" id="section-6">
        <h2>7. Examples of Dual Problems</h2>

        <h3>7.1 Linear Programming</h3>
        <p>Primal: $\min c^\top x$ s.t. $Ax \le b, x \ge 0$.
        <br>Dual: $\max -b^\top \lambda$ s.t. $A^\top \lambda + c \ge 0, \lambda \ge 0$. (See Sec 2.3).</p>

        <h3>7.2 Quadratic Programming</h3>
        <p>Primal: $\min \frac{1}{2}x^\top P x + q^\top x$ s.t. $Ax \le b$. ($P \succ 0$).
        <br>Lagrangian: $L(x, \lambda) = \frac{1}{2}x^\top P x + q^\top x + \lambda^\top (Ax - b)$.
        <br>Minimize over $\mathbf{x}$: $P\mathbf{x} + \mathbf{q} + A^\top \lambda = 0 \implies \mathbf{x} = -P^{-1}(\mathbf{q} + A^\top \lambda)$.
        <br>Dual Function (after algebra):
        $$ g(\lambda) = -\frac{1}{2} \lambda^\top (A P^{-1} A^\top) \lambda - (b + A P^{-1} q)^\top \lambda - \frac{1}{2} q^\top P^{-1} q $$
        This is a concave quadratic maximization (since $A P^{-1} A^\top \succeq 0$).</p>

      <figure class="animation-figure">
        <div class="animation-container">
          <img src="assets/supporting_hyperplanes_l1_linf_three_panels.gif" alt="Dual Norm Geometry Animation" loading="lazy">
        </div>
        <figcaption><i>Animation:</i> Supporting hyperplanes $u^\top x = \|u\|_*$ for the $\ell_1$ and $\ell_\infty$ balls. The dual norm determines how far the hyperplane can be pushed before touching the ball.</figcaption>
      </figure>

        <h3>7.3 Semidefinite Programming</h3>
        <p>Primal: $\min \mathrm{tr}(CX)$ s.t. $\mathrm{tr}(A_i X) = b_i, X \succeq 0$.
        <br>We derive the dual using the generalized Lagrangian with matrix inner product.
        <br>Lagrangian: $L(X, \nu) = \mathrm{tr}(CX) + \sum \nu_i (b_i - \mathrm{tr}(A_i X))$. We minimize this over the cone $X \succeq 0$.
        <br>Grouping terms by $X$: $L(X, \nu) = \sum \nu_i b_i + \mathrm{tr}( (C - \sum \nu_i A_i) X )$.
        <br>The infimum of $\mathrm{tr}(MX)$ over $X \succeq 0$ is $-\infty$ unless $M \succeq 0$ (otherwise we can align $X$ with a negative eigenvector). If $M \succeq 0$, the infimum is 0.
        <br>Thus, the dual function is finite only if $C - \sum \nu_i A_i \succeq 0$.
        <br>Dual:
        $$
        \begin{aligned}
        \text{maximize} \quad & b^\top \nu \\
        \text{subject to} \quad & \sum_{i=1}^m \nu_i A_i \preceq C
        \end{aligned}
        $$
        This is another SDP.</p>

        <div style="margin-top: 24px; border: 1px solid rgba(255,255,255,0.1); border-radius: 8px; overflow: hidden;">
          <iframe src="widgets/psd_cone_2x2.html" width="100%" height="520" style="border:none; background:#0b0d12;"></iframe>
        </div>
      </section>

      <section class="section-card" id="section-7">
        <h2>8. Generalized Inequalities and Conic Duality</h2>

        <div class="insight">
          <h4>Why Conic Duality Matters</h4>
          <p>The componentwise inequality $x \le 0$ (meaning $x \in -\mathbb{R}_+^n$) is just one special case of a <b>generalized inequality</b> $x \preceq_K 0$ (meaning $x \in -K$) where $K$ is a proper cone. Conic duality theory shows that <b>all convex optimization problems</b>—linear, quadratic, second-order cone, semidefinite, and beyond—are instances of the same unified framework. This unification yields:</p>
          <ul>
            <li>A single duality theorem that covers LP, SOCP, and SDP</li>
            <li>Elegant complementary slackness conditions via inner products</li>
            <li>Efficient interior-point methods that exploit cone geometry</li>
          </ul>
        </div>

        <h3>8.1 Proper Cones and Dual Cones: A Quick Review</h3>
        <p>Recall from Lecture 04 that a <b>proper cone</b> $K \subseteq \mathbb{R}^n$ is a closed, convex, pointed cone with nonempty interior. The <b>dual cone</b> is:
        $$ K^* = \{ y \mid x^\top y \ge 0 \text{ for all } x \in K \} $$
        The dual cone encodes which directions have nonnegative inner product with all elements of $K$.</p>

        <div class="example-box">
          <h4>Standard Proper Cones and Their Duals</h4>
          <ul>
            <li><b>Nonnegative Orthant:</b> $\mathbb{R}_+^n = \{x \mid x_i \ge 0\}$. Self-dual: $(\mathbb{R}_+^n)^* = \mathbb{R}_+^n$.</li>
            <li><b>Second-Order Cone (Lorentz Cone):</b> $\mathcal{Q}^n = \{(t, x) \in \mathbb{R} \times \mathbb{R}^{n-1} \mid \|x\|_2 \le t\}$. Self-dual: $(\mathcal{Q}^n)^* = \mathcal{Q}^n$.</li>
            <li><b>Positive Semidefinite Cone:</b> $\mathbb{S}_+^n = \{X \in \mathbb{S}^n \mid X \succeq 0\}$. Self-dual: $(\mathbb{S}_+^n)^* = \mathbb{S}_+^n$ (under trace inner product).</li>
          </ul>
        </div>

        <h3>8.2 The Generalized Lagrangian</h3>
        <p>Consider the primal problem with generalized inequality constraints:
        $$
        \begin{aligned}
        \text{minimize} \quad & f_0(x) \\
        \text{subject to} \quad & f_i(x) \preceq_{K_i} 0, \quad i=1,\ldots,m \\
        & h_j(x) = 0, \quad j=1,\ldots,p
        \end{aligned}
        $$
        where $f_i: \mathbb{R}^n \to \mathbb{R}^{k_i}$ and $K_i \subseteq \mathbb{R}^{k_i}$ is a proper cone.</p>

        <p>The <b>generalized Lagrangian</b> replaces componentwise products with inner products:
        $$ L(x, \lambda, \nu) = f_0(x) + \sum_{i=1}^m \lambda_i^\top f_i(x) + \sum_{j=1}^p \nu_j h_j(x) $$
        where $\lambda_i \in K_i^*$ (the dual cone) ensures $\lambda_i^\top f_i(x) \le 0$ when $f_i(x) \preceq_{K_i} 0$.</p>

        <div class="theorem-box">
          <h4>Conic Duality: Dual Variables Live in the Dual Cone</h4>
          <p>For the Lagrangian to satisfy weak duality, we require $\lambda_i \in K_i^*$. This generalizes the constraint $\lambda_i \ge 0$ for componentwise inequalities:
          <ul>
            <li>If $K = \mathbb{R}_+$, then $\lambda \in K^* = \mathbb{R}_+$ means $\lambda \ge 0$ (standard LP).</li>
            <li>If $K = \mathcal{Q}^n$, then $\lambda \in K^* = \mathcal{Q}^n$ (SOCP).</li>
            <li>If $K = \mathbb{S}_+^n$, then $\lambda \in K^* = \mathbb{S}_+^n$ means $\lambda \succeq 0$ (SDP).</li>
          </ul>
          </p>
        </div>

        <div style="margin: 24px 0; border: 1px solid rgba(255,255,255,0.1); border-radius: 8px; overflow: hidden;">
          <iframe src="widgets/soc_dual_cone.html" width="100%" height="520" style="border:none; background:#0b0d12;"></iframe>
        </div>

        <h3>8.3 The Standard Conic Form</h3>
        <p>All conic programs can be written in a canonical form that makes the duality symmetric. The <b>primal</b> is:
        $$
        \begin{aligned}
        \text{minimize} \quad & c^\top x \\
        \text{subject to} \quad & Ax = b \\
        & x \in K
        \end{aligned}
        $$
        The <b>dual</b> is:
        $$
        \begin{aligned}
        \text{maximize} \quad & b^\top y \\
        \text{subject to} \quad & c - A^\top y = s \\
        & s \in K^*
        \end{aligned}
        $$
        This unifies <b>LP</b> ($K=\mathbb{R}_+^n$), <b>SOCP</b> ($K = \mathcal{Q}^{n_1} \times \cdots \times \mathcal{Q}^{n_k}$), and <b>SDP</b> ($K=\mathbb{S}_+^n$).</p>

        <div class="proof-box">
          <h4>Derivation of the Standard Conic Dual</h4>
          <p>The Lagrangian for the primal is:
          $$ L(x, y, s) = c^\top x + y^\top (b - Ax) = b^\top y + (c - A^\top y)^\top x $$
          The dual function is:
          $$ g(y, s) = \inf_{x \in K} L(x, y, s) = b^\top y + \inf_{x \in K} s^\top x $$
          where $s = c - A^\top y$. The infimum $\inf_{x \in K} s^\top x$ is:
          <ul>
            <li>$0$ if $s^\top x \ge 0$ for all $x \in K$ (i.e., $s \in K^*$)</li>
            <li>$-\infty$ otherwise (we can pick $x \in K$ with $s^\top x < 0$ and scale arbitrarily)</li>
          </ul>
          Thus, the dual problem maximizes $b^\top y$ subject to $s = c - A^\top y \in K^*$.</p>
        </div>

        <h3>8.4 Example: Second-Order Cone Programming (SOCP)</h3>
        <p>Consider the SOCP problem:
        $$
        \begin{aligned}
        \text{minimize} \quad & c^\top x \\
        \text{subject to} \quad & \|A_i x + b_i\|_2 \le c_i^\top x + d_i, \quad i=1,\ldots,m \\
        & Fx = g
        \end{aligned}
        $$
        Each SOC constraint can be written as $(c_i^\top x + d_i, A_i x + b_i) \in \mathcal{Q}^{n_i+1}$.</p>

        <div class="example-box">
          <h4>SOCP Dual: Robust Least Squares</h4>
          <p>For the robust least squares problem:
          $$
          \text{minimize} \quad \|Ax - b\|_2 + \gamma \|x\|_2
          $$
          we can reformulate as an SOCP:
          $$
          \begin{aligned}
          \text{minimize} \quad & t + \gamma s \\
          \text{subject to} \quad & \|Ax - b\|_2 \le t \\
          & \|x\|_2 \le s
          \end{aligned}
          $$
          which is equivalent to $(t, Ax - b) \in \mathcal{Q}$ and $(s, x) \in \mathcal{Q}$.</p>

          <p>The <b>dual problem</b> (derived using the standard conic form) is:
          $$
          \begin{aligned}
          \text{maximize} \quad & -b^\top u \\
          \text{subject to} \quad & A^\top u + v = 0 \\
          & \|u\|_2 \le 1, \quad \|v\|_2 \le \gamma
          \end{aligned}
          $$
          The dual multipliers $(1, u)$ and $(\gamma, v)$ live in the dual cone $\mathcal{Q}^* = \mathcal{Q}$ (self-dual!).</p>
        </div>

        <h3>8.5 Example: Semidefinite Programming (SDP) Revisited</h3>
        <p>Recall from Section 7.3 that the SDP primal-dual pair is:
        $$
        \begin{aligned}
        \text{Primal:} \quad & \min \mathrm{tr}(CX) \text{ s.t. } \mathrm{tr}(A_i X) = b_i, \, X \succeq 0 \\
        \text{Dual:} \quad & \max b^\top \nu \text{ s.t. } \sum \nu_i A_i \preceq C
        \end{aligned}
        $$
        This fits the standard conic form with $K = \mathbb{S}_+^n$ and inner product $\langle X, Y \rangle = \mathrm{tr}(X^\top Y)$.</p>

        <div class="insight">
          <h4>Why SDP is Self-Dual</h4>
          <p>The positive semidefinite cone $\mathbb{S}_+^n$ is self-dual under the trace inner product: $(\mathbb{S}_+^n)^* = \mathbb{S}_+^n$. This means:
          $$ \mathrm{tr}(XY) \ge 0 \text{ for all } X \succeq 0 \iff Y \succeq 0 $$
          This beautiful symmetry mirrors the self-duality of $\mathbb{R}_+$ and $\mathcal{Q}$ and is the foundation of primal-dual interior-point methods for SDP.</p>
        </div>

        <h3>8.6 Complementary Slackness for Conic Programs</h3>
        <p>For the standard conic form, complementary slackness states:
        $$ s^\top x = 0 $$
        where $x \in K$ (primal feasible) and $s \in K^*$ (dual feasible). This generalizes to:
        <ul>
          <li><b>LP:</b> $\lambda_i (c_i - a_i^\top y) = 0$ for each component (componentwise product).</li>
          <li><b>SOCP:</b> $\lambda^\top x = 0$ where $\lambda, x \in \mathcal{Q}$ (inner product in the cone).</li>
          <li><b>SDP:</b> $\mathrm{tr}(SX) = 0$ where $S, X \succeq 0$ (trace inner product). Equivalently, $SX = 0$ (zero matrix product).</li>
        </ul>
        </p>

        <div class="example-box">
          <h4>Geometric Interpretation: Orthogonal Complementarity</h4>
          <p>Since $x \in K$ and $s \in K^*$, we always have $s^\top x \ge 0$ (by definition of dual cone). Complementary slackness $s^\top x = 0$ means the vectors are <b>orthogonal</b> despite both being "nonnegative" in their respective cones.
          <br><br>For SDP: If $X \succeq 0$ and $S \succeq 0$, then $\mathrm{tr}(SX) = 0$ implies that $S$ and $X$ have <b>complementary support</b>: whenever $X$ has a positive eigenvalue in direction $v$, $S$ must have zero component in that direction, and vice versa. This gives $SX = XS = 0$.</p>
        </div>

        <h3>8.7 Applications: Why Conic Duality is Powerful</h3>
        <div class="insight">
          <h4>Practical Impact</h4>
          <ul>
            <li><b>Interior-Point Methods:</b> Modern solvers (MOSEK, SeDuMi, CVXOPT) use primal-dual path-following algorithms that exploit the symmetric structure of conic duality. The central path $\{(x, s) \mid xs = \tau e, x \in K, s \in K^*\}$ guides the solver to optimality.</li>
            <li><b>Approximation Algorithms:</b> SDP relaxations of combinatorial problems (Max-Cut, graph coloring) derive approximation guarantees from the duality gap and rounding schemes.</li>
            <li><b>Robust Optimization:</b> Uncertainty sets defined by cones (ellipsoidal, polyhedral) lead to tractable robust counterparts via conic duality.</li>
            <li><b>Control Theory:</b> Lyapunov stability conditions (LMIs) are SDPs; the dual variables provide certificates of stability.</li>
          </ul>
        </div>

      </section>

      <section class="section-card" id="section-8">
        <h2>9. Review & Cheat Sheet</h2>
        <h3>Key Definitions</h3>
        <ul>
          <li><b>Lagrangian:</b> $L(x, \lambda, \nu) = f_0(x) + \lambda^\top f(x) + \nu^\top h(x)$.</li>
          <li><b>Dual Function:</b> $g(\lambda, \nu) = \inf_x L(x, \lambda, \nu)$. (Always Concave).</li>
          <li><b>Weak Duality:</b> $d^* \le p^*$. (Always true).</li>
          <li><b>Strong Duality:</b> $d^* = p^*$. (Usually true for convex via Slater).</li>
        </ul>

        <h3>KKT Conditions (Convex + Slater $\iff$ Optimal)</h3>
        <ol>
          <li>$f_i(x) \le 0, h_j(x) = 0$ (Primal Feas)</li>
          <li>$\lambda_i \ge 0$ (Dual Feas)</li>
          <li>$\lambda_i f_i(x) = 0$ (Comp. Slackness)</li>
          <li>$\nabla f_0 + \sum \lambda_i \nabla f_i + \sum \nu_j \nabla h_j = 0$ (Stationarity)</li>
        </ol>

        <h3>Algorithms Preview</h3>
        <p>Duality is the foundation for many modern algorithms:</p>
        <ul>
          <li><b>Dual Ascent:</b> Maximize $g(\lambda)$ via gradient ascent: $\lambda^{k+1} = (\lambda^k + \alpha \nabla g(\lambda^k))_+$. Useful for distributed optimization.</li>
          <li><b>Augmented Lagrangian:</b> Adds a quadratic penalty $\frac{\rho}{2}\|Ax-b\|^2$ to the Lagrangian. Smoothes the dual function and improves convergence.</li>
          <li><b>ADMM (Alternating Direction Method of Multipliers):</b> Splits problems into smaller subproblems ($x$-update, $z$-update) coordinated by a dual update.</li>
        </ul>
      </section>

    <section class="section-card" id="section-canonical-duals">
      <h2>10. Canonical Duals: A Problem Pack</h2>
      <p>This section provides a "micro-toolbox" of derivations for standard problems. Mastering these specific derivations builds the pattern-matching skills needed for general duality.</p>

      <div class="insight">
        <h4>Micro-Toolbox</h4>
        <ul>
          <li><b>Lemma A1 (Linear Term):</b> $\inf_x a^\top x = 0$ if $a=0$, else $-\infty$. This generates equality constraints ($A^\top \nu + c = 0$).</li>
          <li><b>Lemma A2 (Quadratic Min):</b> $\inf_x (\frac{1}{2}x^\top P x + q^\top x) = -\frac{1}{2}q^\top P^{-1} q$ (if $P \succ 0$). This handles QP terms.</li>
          <li><b>Lemma A3 (Conjugate of Norm):</b> $\sup_x (y^\top x - \|x\|) = 0$ if $\|y\|_* \le 1$, else $\infty$. This generates dual norm constraints.</li>
        </ul>
      </div>

      <figure class="animation-figure">
        <div class="animation-container">
          <img src="assets/l1_linf_polar_swap.gif" alt="Polar Duality Animation" loading="lazy">
        </div>
        <figcaption><i>Animation:</i> The polar of the $\ell_1$ ball is the $\ell_\infty$ ball, and vice versa. This geometric duality underpins the relationship between sparse primal solutions and box-constrained dual variables.</figcaption>
      </figure>

      <div class="problem">
        <h3>Problem 1: Least Squares (Residual Form)</h3>
        <p><b>Primal:</b> $\min \frac{1}{2} \|Ax - b\|_2^2$. Rewrite as $\min \frac{1}{2}\|y\|_2^2$ s.t. $y = Ax - b$.</p>
        <p><b>Lagrangian:</b> $L(x, y, \nu) = \frac{1}{2}\|y\|^2 + \nu^\top (Ax - b - y) = (\frac{1}{2}\|y\|^2 - \nu^\top y) + (A^\top \nu)^\top x - b^\top \nu$.</p>
        <p><b>Dual Function:</b>
        <br>1. Min over $\mathbf{x}$: Requires $A^\top \nu = 0$ (Lemma A1).
        <br>2. Min over $\mathbf{y}$: $\inf (\frac{1}{2}\|\mathbf{y}\|^2 - \nu^\top \mathbf{y}) = -\frac{1}{2}\|\nu\|^2$ (Lemma A2 with $P=I$).
        <br><b>Dual Problem:</b> $\max -\frac{1}{2}\|\nu\|^2 - b^\top \nu$ s.t. $A^\top \nu = 0$.
        </p>
      </div>

      <div class="problem">
        <h3>Problem 2: Ridge Regression</h3>
        <p><b>Primal:</b> $\min \frac{1}{2}\|Ax - b\|_2^2 + \frac{\lambda}{2}\|x\|_2^2$. Rewrite with $y = Ax - b$.</p>
        <p><b>Lagrangian:</b> $L(x, y, \nu) = \frac{1}{2}\|y\|^2 + \frac{\lambda}{2}\|x\|^2 + \nu^\top(Ax - b - y)$.</p>
        <p><b>Dual Function:</b>
        <br>1. Min over $\mathbf{y}$: same as above, $-\frac{1}{2}\|\nu\|^2$.
        <br>2. Min over $\mathbf{x}$: $\inf (\frac{\lambda}{2}\|\mathbf{x}\|^2 + (A^\top \nu)^\top \mathbf{x}) = -\frac{1}{2\lambda}\|A^\top \nu\|^2$.
        <br><b>Dual Problem:</b> $\max -b^\top \nu - \frac{1}{2}\|\nu\|^2 - \frac{1}{2\lambda}\|A^\top \nu\|^2$. (Unconstrained!)
        </p>
      </div>

      <div class="problem">
        <h3>Problem 3: LASSO</h3>
        <p><b>Primal:</b> $\min \frac{1}{2}\|Ax - b\|_2^2 + \lambda \|x\|_1$. Rewrite with $y = Ax - b$.</p>
        <p><b>Lagrangian:</b> $L(x, y, \nu) = \frac{1}{2}\|y\|^2 + \lambda \|x\|_1 + \nu^\top(Ax - b - y)$.</p>
        <p><b>Dual Function:</b>
        <br>1. Min over $\mathbf{y}$: $-\frac{1}{2}\|\nu\|^2$.
        <br>2. Min over $\mathbf{x}$: $\inf_{\mathbf{x}} (\lambda \|\mathbf{x}\|_1 + (A^\top \nu)^\top \mathbf{x}) = -\sup_{\mathbf{x}} (-(A^\top \nu)^\top \mathbf{x} - \lambda \|\mathbf{x}\|_1)$.
        This is finite (0) only if $\|A^\top \nu\|_\infty \le \lambda$ (Lemma A3 scaled).
        <br><b>Dual Problem:</b> $\max -b^\top \nu - \frac{1}{2}\|\nu\|^2$ s.t. $\|A^\top \nu\|_\infty \le \lambda$.
        </p>
      </div>

      <div class="problem">
        <h3>Problem 4: Basis Pursuit (Problem 5.3)</h3>
        <p><b>Primal:</b> $\min \|x\|_1$ s.t. $Ax = b$.</p>
        <p><b>Lagrangian:</b> $L(x, \nu) = \|x\|_1 + \nu^\top(b - Ax) = b^\top \nu + (\|x\|_1 - (A^\top \nu)^\top x)$.</p>
        <p><b>Dual Function:</b>
        <br>The term $\inf_x (\|x\|_1 - z^\top x)$ is related to the conjugate of the L1 norm. It is finite (zero) iff the dual norm condition holds: $\|z\|_\infty \le 1$.
        <br>Here $z = A^\top \nu$.
        <br><b>Dual Problem:</b> $\max b^\top \nu$ s.t. $\|A^\top \nu\|_\infty \le 1$.
        <br><b>KKT Insight:</b> At optimum, $A^\top \nu \in \partial \|x\|_1$. Dual variables certify the support of the sparse solution.
        </p>
        <div class="proof-box">
          <h4>Deep Dive: Dual of $\min c^\top x$ s.t. $f(x) \le 0$ via Conjugates</h4>
          <p>We derive the general dual for a single inequality constraint using conjugates.</p>
          <div class="proof-step">
            <strong>1. Lagrangian:</strong> $L(x, \lambda) = c^\top x + \lambda f(x)$ with $\lambda \ge 0$.
          </div>
          <div class="proof-step">
            <strong>2. Dual Function $g(\lambda) = \inf_x L(x, \lambda)$.</strong>
            If $\lambda = 0$, $\inf c^\top x = -\infty$ unless $c=0$. Assume $\lambda > 0$.
            $$ g(\lambda) = \lambda \inf_x \left( f(x) + \frac{c^\top x}{\lambda} \right) = -\lambda \sup_x \left( \left(-\frac{c}{\lambda}\right)^\top x - f(x) \right) = -\lambda f^*\left(-\frac{c}{\lambda}\right) $$
          </div>
          <div class="proof-step">
            <strong>3. Convexity.</strong>
            The function $g(\lambda) = -\lambda f^*(-c/\lambda)$ is concave because it is the perspective of the (negative) conjugate function. Thus the dual problem is convex.
          </div>
        </div>
      </div>

      <div class="problem">
        <h3>Problem 5: LP Dual via Relaxed Problems (Problem 5.4)</h3>
        <p><b>Primal:</b> $\min c^\top x$ s.t. $Ax \le b$.</p>
        <p><b>Interpretation:</b> Instead of enforcing all constraints, consider a non-negative weighted sum $w^\top A x \le w^\top b$.
        $$ \tilde{p}(w) = \min c^\top x \quad \text{s.t.} \quad (A^\top w)^\top x \le b^\top w $$
        The set of points satisfying the weighted constraint contains the original feasible set, so $\tilde{p}(w)$ is a lower bound.
        <br>The minimization $\min c^\top x$ s.t. $a^\top x \le \beta$ is finite only if $c$ is a multiple of $a$ (specifically $c = -ka$ for $k \ge 0$) or if $a=0$.
        <br>Setting the gradient to match: $c = -A^\top w$ (implies the objective is supported by the constraint).
        <br>The value is $-b^\top w$.
        <br>The best lower bound is $\max -b^\top w$ s.t. $A^\top w + c = 0, w \ge 0$. This recovers the standard LP dual.</p>
      </div>

      <div class="problem">
        <h3>Problem 6: Support Vector Machine (Hinge Loss)</h3>
        <p><b>Primal:</b> $\min \frac{1}{2}\|w\|^2 + C \sum \max(0, 1 - y_i w^\top x_i)$.
        <br>Rewrite: $\min \frac{1}{2}\|w\|^2 + C \sum \xi_i$ s.t. $\xi_i \ge 1 - y_i w^\top x_i, \xi_i \ge 0$.</p>
        <p><b>Dual Derivation:</b>
        <br>Lagrangian involves multipliers $\alpha_i, \mu_i$. Minimizing over $\mathbf{w}$ gives $\mathbf{w} = \sum \alpha_i y_i \mathbf{x}_i$.
        <br>Minimizing over $\xi$ gives constraint $0 \le \alpha_i \le C$.
        <br><b>Dual Problem:</b> $\max \sum \alpha_i - \frac{1}{2} \sum_{i,j} \alpha_i \alpha_j y_i y_j x_i^\top x_j$ s.t. $0 \le \alpha_i \le C, \sum \alpha_i y_i = 0$.
        </p>
      </div>

      <div class="problem">
        <h3>Problem 7: Trust-Region QCQP (Nonconvex with Strong Duality)</h3>
        <p><b>Primal:</b> $\min x^\top A x + 2 b^\top x$ s.t. $x^\top x \le 1$.</p>
        <p>This is the classic <b>trust-region subproblem</b>. Even if $A \not\succeq 0$ (making the objective nonconvex), strong duality still holds.</p>
        
        <div class="insight">
          <h4>Why It Matters</h4>
          <p>This problem arises in Newton-type methods when optimizing within a trusted region. The constraint $\|x\|_2 \le 1$ is the unit ball—the "trust region" where a quadratic approximation is valid.</p>
        </div>
        
        <p><b>Lagrangian:</b></p>
        $$ L(x, \lambda) = x^\top A x + 2 b^\top x + \lambda(x^\top x - 1) = x^\top (A + \lambda I) x + 2 b^\top x - \lambda $$
        
        <div class="proof-box">
          <h4>Deep Dive: Zero-to-Hero Derivation of the Dual</h4>
          <p>We derive the dual function $g(\lambda) = \inf_x L(x, \lambda)$ from first principles, showing why this nonconvex problem behaves nicely.</p>

          <div class="proof-step">
            <strong>1. The Lagrangian Form.</strong>
            Define $H(\lambda) = A + \lambda I$. The Lagrangian is a quadratic function of $x$:
            $$ L(x, \lambda) = x^\top H(\lambda) x + 2b^\top x - \lambda $$
            Even if $A$ is indefinite (negative eigenvalues), we can choose $\lambda$ large enough such that $H(\lambda) \succeq 0$. This "convexifies" the Lagrangian.
          </div>

          <div class="proof-step">
            <strong>2. Finiteness Conditions (Avoiding $-\infty$).</strong>
            The quadratic $L(x, \lambda)$ has a finite minimum if and only if:
            <ul>
              <li><b>Curvature:</b> $H(\lambda) \succeq 0$. If $H(\lambda)$ has a negative eigenvalue, we can send $x$ to infinity along that eigenvector to drive $L \to -\infty$. This forces $\lambda \ge -\lambda_{\min}(A)$.</li>
              <li><b>Range:</b> $b \in \mathcal{R}(H(\lambda))$. If $H(\lambda)$ is singular (has 0 eigenvalues), the quadratic is "flat" along the nullspace. If $b$ has a component in that nullspace ($b \notin \mathcal{R}(H(\lambda))$), the linear term $2b^\top x$ tilts the flat valley, driving the minimum to $-\infty$.</li>
            </ul>
          </div>

          <div class="proof-step">
            <strong>3. Computing the Minimum.</strong>
            When finite, the minimum is attained at any $x$ satisfying the stationarity condition $2H(\lambda)x + 2b = 0 \implies H(\lambda)x = -b$.
            <br>The optimal value is obtained by completing the square or using the pseudoinverse $H(\lambda)^\dagger$:
            $$ g(\lambda) = -b^\top H(\lambda)^\dagger b - \lambda $$
          </div>

          <div class="proof-step">
            <strong>4. Eigen-Decomposition Form.</strong>
            Let $A = Q \Lambda Q^\top$. In the eigenbasis, $H(\lambda)$ is diagonal with entries $\lambda_i + \lambda$. Let $\beta = Q^\top b$ be the coordinates of $b$.
            The quadratic form becomes a sum:
            $$ g(\lambda) = -\sum_{i=1}^n \frac{\beta_i^2}{\lambda_i + \lambda} - \lambda $$
            <b>Convention:</b> If $\lambda_i + \lambda = 0$, the term is $0$ if $\beta_i=0$, and $-\infty$ if $\beta_i \neq 0$ (enforcing the range condition).
            <br>This explicitly displays $g(\lambda)$ as a concave function to be maximized over $\lambda \ge \max(0, -\lambda_{\min}(A))$.
          </div>
        </div>
        
        <div class="theorem-box">
          <h4>Strong Duality Theorem</h4>
          <p><b>Theorem:</b> For the Trust Region Subproblem, $p^\star = d^\star$ even if non-convex.</p>
          <p><b>Geometric Intuition (The S-Lemma):</b>
          The joint range of $(x^\top x, x^\top A x + 2b^\top x)$ is a convex set in $\mathbb{R}^2$ (this is specific to having only <i>one</i> quadratic constraint).
          Because the image is convex, we can separate the optimal point from the infeasible region with a hyperplane. The normal vector to this hyperplane corresponds to the dual variable $\lambda$. Thus, a linear combination of the objective and constraint supports the optimal value exactly.</p>
        </div>
        
        <div class="insight">
          <h4>Recovering the Primal Solution</h4>
          <p>Solve the 1D dual problem $\max_{\lambda} g(\lambda)$. Let $\lambda^*$ be the optimum.</p>
          <ul>
            <li><b>Easy Case ($H(\lambda^*) \succ 0$):</b> $x^* = -(A + \lambda^* I)^{-1} b$.</li>
            <li><b>Hard Case ($H(\lambda^*)$ singular):</b> This happens if $\lambda^* = -\lambda_{\min}(A)$. The system $(A + \lambda^* I)x = -b$ has infinitely many solutions. We must choose the specific solution $x = x_{base} + \alpha v_{null}$ such that $\|x\|_2 = 1$.</li>
          </ul>
        </div>
      </div>

      <div class="problem">
        <h3>Problem 8: Sum of Largest Elements (Constructive Duality)</h3>
        <p>Consider the function $f(x) = \sum_{i=1}^r x_{[i]}$, the sum of the $r$ largest components of $x$. Derive a compact LP formulation for the constraint $f(x) \le \alpha$.</p>
        <div class="solution-box">
          <h4>Solution</h4>
          <div class="proof-step">
            <strong>Step 1: Variational Definition.</strong>
            $f(x) = \max \{ x^\top y \mid 0 \le y \le \mathbf{1}, \mathbf{1}^\top y = r \}$. The extreme points of this polytope correspond to selecting exactly $r$ coordinates.
      <div class="intuition-box">
        <p><b>Why this works (The Swap Argument):</b> Suppose the optimal $y$ puts weight on a smaller component $x_j$ (i.e., $y_j > 0$) while a larger component $x_i$ is not fully selected ($y_i < 1$). We can move mass $\epsilon$ from $j$ to $i$. The objective changes by $\epsilon(x_i - x_j) > 0$. Thus, the optimizer must greedily fill the buckets corresponding to the largest $x_i$'s.</p>
      </div>
          </div>
          <div class="proof-step">
            <strong>Step 2: Dual of the Inner Maximization.</strong>
            We want to express $f(x) \le \alpha$. Using LP duality on the inner problem:
            $$ \max_y \{ x^\top y \mid y \le \mathbf{1}, \mathbf{1}^\top y = r, y \ge 0 \} = \min_{t, u} \{ rt + \mathbf{1}^\top u \mid t\mathbf{1} + u \ge x, u \ge 0 \} $$
          </div>
          <div class="proof-step">
            <strong>Step 3: Dual of the Inner Maximization.</strong>
            We want to express $f(x) \le \alpha$. The inner problem is an LP:
            $$ \max_y \{ x^\top y \mid y \le \mathbf{1}, -y \le 0, \mathbf{1}^\top y = r \} $$
            Using LP duality (minimizing variables $t$ for equality, $u$ for $y \le \mathbf{1}$):
            $$ \max_y x^\top y = \min_{t, u} \{ rt + \mathbf{1}^\top u \mid t\mathbf{1} + u \ge x, u \ge 0 \} $$
          </div>
          <div class="proof-step">
            <strong>Step 4: Deeper Insight - The Threshold Interpretation.</strong>
            Consider the constraints on the dual variables: $u_i \ge x_i - t$ and $u_i \ge 0$. To minimize the objective $rt + \sum u_i$, we should choose the smallest feasible $u_i$:
            $$ u_i(t) = \max(0, x_i - t) = (x_i - t)_+ $$
            Substituting this back, the dual value is $\min_t (rt + \sum_{i=1}^n (x_i - t)_+)$. Here, $t$ acts as a <b>threshold</b>. The optimization automatically finds the $r$-th largest element as the cutoff.
          </div>
          <div class="proof-step">
            <strong>Step 5: Compact Formulation.</strong>
            The condition $f(x) \le \alpha$ is satisfied iff there exist $t, u$ such that:
            $$ rt + \sum u_i \le \alpha, \quad u_i \ge x_i - t, \quad u_i \ge 0 $$
            This replaces a combinatorial condition ($\binom{n}{r}$ inequalities) with $2n+1$ linear inequalities.
          </div>
        </div>
      </div>

      <div class="problem">
        <h3>Problem 9: Markowitz Portfolio with Diversification</h3>
        <p>Add a constraint to the Markowitz problem to ensure "no more than 80% of capital in any 10% of assets".</p>
        <div class="solution-box">
          <h4>Solution</h4>
          <p>Let $r = \lfloor 0.1 n \rfloor$. The diversification constraint is $\sum_{i=1}^r x_{[i]} \le 0.8$.
          <br>Using the compact representation from Problem 7, we introduce auxiliary variables $t \in \mathbb{R}$ and $u \in \mathbb{R}^n$.
          <br>The full Markowitz problem becomes:</p>
          $$
          \begin{aligned}
          \text{minimize}_{x, t, u} \quad & x^\top \Sigma x \\
          \text{subject to} \quad & \bar{p}^\top x \ge r_{\min}, \quad \mathbf{1}^\top x = 1, \quad x \ge 0 \\
          & rt + \mathbf{1}^\top u \le 0.8 \\
          & t\mathbf{1} + u \ge x \\
          & u \ge 0
          \end{aligned}
          $$
          <p>This is a <b>Convex QP</b> because the objective $x^\top \Sigma x$ is convex ($\Sigma \succeq 0$) and all constraints are linear inequalities or equalities in the variables $(x, t, u)$.</p>
        </div>
      </div>

      <div class="problem">
        <h3>Problem 10: Simplex Projection</h3>
        <p><b>Primal:</b> $\min \frac{1}{2}\|x-z\|_2^2$ s.t. $\mathbf{1}^\top x = 1, x \ge 0$.</p>
        <p><b>KKT Approach (No explicit dual needed for solution):</b>
        <br>Stationarity: $x - z - \lambda + \nu \mathbf{1} = 0 \implies x = z + \lambda - \nu \mathbf{1}$.
        <br>Complementary Slackness: $\lambda \ge 0, x \ge 0, \lambda_i x_i = 0$.
        <br>If $x_i > 0$, $\lambda_i=0 \implies x_i = z_i - \nu$.
        <br>If $x_i = 0$, $\lambda_i = \nu - z_i \ge 0 \implies z_i \le \nu$.
        <br>Unified: $x_i = \max(0, z_i - \nu)$.
        <br><b>Algorithm:</b> Find $\nu$ such that $\sum \max(0, z_i - \nu) = 1$ via sorting.
        </p>
      </div>

      <div class="problem">
        <h3>Problem 11: Logistic Regression</h3>
        <p><b>Primal:</b> $\min \sum \log(1 + e^{x_i^\top w}) - y_i x_i^\top w + \frac{\lambda}{2}\|w\|^2$.</p>
        <p><b>Dual:</b> Uses the conjugate of the logistic loss (binary entropy).
        <br>The dual involves maximizing entropy subject to correlation constraints with data.
        <br>This duality is the basis for Maximum Entropy models.
        </p>
      </div>
    </section>

    <section class="section-card" id="section-exercises">
      <h2><i data-feather="edit-3"></i> 11. Exercises</h2>

      <div class="insight">
        <h4>Recap & Key Concepts</h4>
        <p>These exercises consolidate your understanding of Lagrangian duality. We move from deriving duals of standard problems (QP, LP) to applying KKT conditions for analytic solutions (Water-filling), and finally using Strong Duality to prove fundamental theorems like Farkas' Lemma.</p>
      </div>

      <div class="proof-box">
        <h4>Appendix: Gap Certificate Cookbook</h4>
        <p>How to construct primal-dual certificates for common problems. In each case, $\text{gap} = p(x) - d(\text{dual vars})$.</p>

        <h5>1. Least Squares: $\min \frac{1}{2}\|Ax - b\|_2^2$</h5>
        <ul>
          <li><b>Primal:</b> Any $\mathbf{x}$.</li>
          <li><b>Dual:</b> Any $\mathbf{y}$ such that $A^\top \mathbf{y} = 0$ (orthogonal to range).</li>
          <li><b>Dual Objective:</b> $b^\top y - \frac{1}{2}\|y\|_2^2$.</li>
          <li><b>Gap:</b> $\frac{1}{2}\|Ax - b\|_2^2 - (b^\top y - \frac{1}{2}\|y\|_2^2)$.</li>
          <li><b>Recipe:</b> Let $\mathbf{r} = \mathbf{b} - A\mathbf{x}$. Project $\mathbf{r}$ onto $\mathcal{N}(A^\top)$ to get $\mathbf{y}$.</li>
        </ul>

        <h5>2. LASSO: $\min \frac{1}{2}\|Ax - b\|_2^2 + \lambda \|x\|_1$</h5>
        <ul>
          <li><b>Dual Feasibility:</b> $\|A^\top y\|_\infty \le \lambda$.</li>
          <li><b>Dual Objective:</b> $b^\top y - \frac{1}{2}\|y\|_2^2$.</li>
          <li><b>Recipe:</b> Let $r = b - Ax$. Scale $r$ to be feasible: $y = \min(1, \lambda / \|A^\top r\|_\infty) r$.</li>
        </ul>

        <h5>3. SVM: $\min \frac{1}{2}\|w\|_2^2 + C \sum \xi_i$</h5>
        <ul>
          <li><b>Dual Variable:</b> $0 \le \alpha \le C \mathbf{1}, \alpha^\top y_{labels} = 0$.</li>
          <li><b>Gap:</b> Standard primal-dual gap from SMO algorithm.</li>
        </ul>
      </div>

<div class="problem">
  <h3>P9.1 — Deriving the Dual of a Quadratic Program</h3>
  <p>Consider the QP: $\min x^\top x$ subject to $Ax \preceq b$.
  <br>(a) Derive the Lagrange dual function $g(\lambda)$.
  <br>(b) State the dual problem explicitly.
  <br>(c) Verify weak duality directly for any feasible $\mathbf{x}$ and $\lambda$.</p>

  <div class="recap-box">
    <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
    <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
        <li><b>Algebraic Completion:</b> The derivation of the QP dual ($x^\top x \to \lambda^\top A A^\top \lambda$) is essentially completing the square in the Lagrangian.</li>
        <li><b>Geometric Insight:</b> The term $A A^\top$ in the dual objective reflects the geometry of the constraint boundaries. If $A A^\top$ is ill-conditioned, the dual is hard to solve.</li>
    </ul>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      <strong>(a) Dual Function:</strong>
      $L(x, \lambda) = x^\top x + \lambda^\top (Ax - b)$.
      $\nabla_x L = 2x + A^\top \lambda = 0 \implies x^* = -1/2 A^\top \lambda$.
      $g(\lambda) = (-1/2 A^\top \lambda)^\top (-1/2 A^\top \lambda) + \lambda^\top (A(-1/2 A^\top \lambda) - b)$
      $= 1/4 \lambda^\top A A^\top \lambda - 1/2 \lambda^\top A A^\top \lambda - b^\top \lambda$
      $= -1/4 \lambda^\top (A A^\top) \lambda - b^\top \lambda$.
    </div>
    <div class="proof-step">
      <strong>(b) Dual Problem:</strong>
      $\max -1/4 \lambda^\top (A A^\top) \lambda - b^\top \lambda$ subject to $\lambda \ge 0$.
    </div>
    <div class="proof-step">
      <strong>(c) Weak Duality:</strong>
      $x^\top x - (-1/4 \lambda^\top A A^\top \lambda - b^\top \lambda) = \|x + 1/2 A^\top \lambda\|^2 - \lambda^\top(Ax - b)$.
      Since $\lambda \ge 0$ and $Ax - b \le 0$, the term $-\lambda^\top(Ax-b) \ge 0$. The norm is $\ge 0$. Sum $\ge 0$.
    </div>
  </div>
</div>

<div class="problem">
  <h3>P9.2 — KKT Conditions for Entropy Maximization</h3>
  <p>Maximize the entropy $-\sum x_i \log x_i$ subject to $\mathbf{1}^\top x = 1$ and $Ax \le b$.
  <br>Derive the KKT conditions. Show that the optimal solution has the form $x_i = e^{-\nu - 1 - (A^\top \lambda)_i}$.</p>

  <div class="recap-box">
    <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
    <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
        <li><b>Exponential Families:</b> The solution form $x_i \propto e^{-(A^\top \lambda)_i}$ shows that linear constraints on the probability mass function lead to exponential family distributions.</li>
        <li><b>Partition Function:</b> The Lagrange multiplier $\nu$ associated with normalization ($\sum x_i = 1$) becomes the log-partition function (normalizing constant) in the solution.</li>
    </ul>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <p>Lagrangian: $L = \sum x_i \log x_i + \nu(\sum x_i - 1) + \lambda^\top (Ax - b)$. (Note: minimizing neg entropy).
    <br>Stationarity: $1 + \log x_i + \nu + (A^\top \lambda)_i = 0$.
    <br>Solving for $x_i$: $\log x_i = -1 - \nu - (A^\top \lambda)_i \implies x_i = \exp(\dots)$.
    <br>Constraints: $\lambda \ge 0$, $\lambda^\top (Ax - b) = 0$, primal feasibility.</p>
  </div>
</div>

<div class="problem">
  <h3>P9.3 — Sensitivity Analysis and Shadow Prices</h3>
  <p>Consider $\min x^2$ s.t. $x \le -1$. Optimal $x^*=-1, p^*=1$.
  <br>Perturb to $\mathbf{x} \le -1 + u$. New optimum $\mathbf{x}^* = -1+u$ (for small $u$), $p^*(u) = (-1+u)^2 \approx 1 - 2u$.
  <br>Find the dual optimal $\lambda^*$ of the original problem and verify $p^*(u) \approx p^*(0) - \lambda^* u$.</p>

  <div class="recap-box">
    <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
    <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
        <li><b>Shadow Prices:</b> $\lambda^*$ quantifies the "marginal cost" of the constraint. If $\lambda^* = 2$, relaxing the bound by $\epsilon$ saves $2\epsilon$.</li>
        <li><b>Local vs Global:</b> For convex problems, $p^*(u) \ge p^*(0) - \lambda^* u$ is a global lower bound, offering a guarantee on the best possible improvement.</li>
    </ul>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <p>$L(x, \lambda) = x^2 + \lambda(x+1)$. $\nabla_x L = 2x + \lambda = 0 \implies x = -\lambda/2$.
    <br>Dual $g(\lambda) = \lambda^2/4 - \lambda^2/2 + \lambda = -1/4 \lambda^2 + \lambda$.
    <br>Max at $\lambda^* = 2$. Dual value $-1 + 2 = 1 = p^*$.
    <br>Sensitivity: $p^*(u) \approx 1 - \lambda^* u = 1 - 2u$. Matches first order expansion of $(1-u)^2$.</p>
  </div>
</div>
<div class="problem">
  <h3>P9.4 — Dual of a Linear Program</h3>
  <p>Derive the dual of the standard form LP:
  $$ \min c^\top x \quad \text{s.t.} \quad Ax = b, \ x \ge 0 $$
  Show it is $\max -b^\top \nu$ s.t. $A^\top \nu + c \ge 0$ (or equivalently $\max b^\top y$ s.t. $A^\top y \le c$ via reparameterization).</p>

  <div class="recap-box">
    <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
    <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
        <li><b>Symmetry:</b> The dual of the dual is the primal. For standard LP ($\min c^\top x, Ax=b, x \ge 0$), the dual is ($\max b^\top y, A^\top y \le c$).</li>
        <li><b>Economic Interpretation:</b> If primal variables are production quantities, dual variables are prices of resources ($Ax=b$). The dual constraint $A^\top y \le c$ means "value of resources consumed $\le$ cost/profit".</li>
    </ul>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      <strong>Step 1: Lagrangian.</strong>
      The constraints are $Ax - b = 0$ and $-x \le 0$.
      $L(x, \lambda, \nu) = c^\top x - \lambda^\top x + \nu^\top (Ax - b) = -b^\top \nu + (c - \lambda + A^\top \nu)^\top x$.
    </div>
    <div class="proof-step">
      <strong>Step 2: Dual Function.</strong>
      $g(\lambda, \nu) = \inf_x L(x, \lambda, \nu)$.
      If the coefficient of $x$ is not zero, the infimum is $-\infty$.
      Thus $g(\lambda, \nu) = -b^\top \nu$ if $c - \lambda + A^\top \nu = 0$, else $-\infty$.
    </div>
    <div class="proof-step">
      <strong>Step 3: Dual Problem.</strong>
      Maximize $-b^\top \nu$ subject to $\lambda \ge 0$ and $c - \lambda + A^\top \nu = 0$.
      Eliminate $\lambda$: $\lambda = c + A^\top \nu$. The condition $\lambda \ge 0$ becomes $c + A^\top \nu \ge 0$, or $A^\top (-\nu) \le c$.
      Let $y = -\nu$. Then we maximize $b^\top y$ subject to $A^\top y \le c$.
    </div>
  </div>
</div>

<div class="problem">
  <h3>P9.5 — Farkas' Lemma</h3>
  <p>Use Strong Duality for LP to prove Farkas' Lemma:
  Exactly one of the following systems has a solution:
  <ol>
    <li>$Ax = b, \ x \ge 0$</li>
    <li>$A^\top y \ge 0, \ b^\top y < 0$</li>
  </ol>
  </p>

  <div class="recap-box">
    <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
    <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
        <li><b>Theorems of Alternatives:</b> Farkas' Lemma is the linear instance of a broad class of theorems (Gordan, Stiemke) relating feasibility of one system to infeasibility of another.</li>
        <li><b>Duality Proof:</b> The proof relies on Strong Duality: if the primal is infeasible ($p^*=\infty$), the dual must be unbounded ($d^*=\infty$), implying the existence of an improving direction (the certificate).</li>
    </ul>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      Consider the LP: $p^* = \min \{ 0^\top x \mid Ax = b, x \ge 0 \}$.
      If (1) is feasible, $p^* = 0$. If infeasible, $p^* = \infty$.
    </div>
    <div class="proof-step">
      The dual of the LP $\min \{ 0^\top x \mid Ax = b, x \ge 0 \}$ is:
      $$ d^* = \max \{ -b^\top \nu \mid A^\top \nu \ge 0 \} $$
      (Using the standard derivation where equality constraints $Ax=b$ have dual variables $\nu$).
      Alternatively, writing the dual in terms of $y = -\nu$, we maximize $b^\top y$ subject to $A^\top y \le 0$.
    </div>
    <div class="proof-step">
      <strong>Case 1: (1) has a solution (Feasible).</strong>
      If there exists $x \ge 0$ such that $Ax=b$, the primal optimal value is $p^* = 0$.
      <br>By Weak Duality, for any dual feasible $y$ (where $A^\top y \le 0$), we have $b^\top y \le p^* = 0$.
      <br>Thus $A^\top y \le 0 \implies b^\top y \le 0$.
      <br>Let $z = -y$. Then $A^\top (-z) \le 0 \implies A^\top z \ge 0$, and $b^\top (-z) \le 0 \implies b^\top z \ge 0$.
      <br>System (2) requires $A^\top z \ge 0$ and $b^\top z < 0$. But we showed $b^\top z \ge 0$.
      <br>Thus, system (2) has <b>no solution</b>.
    </div>
    <div class="proof-step">
      <strong>Case 2: (1) has no solution (Infeasible).</strong>
      If the primal is infeasible, then $p^* = +\infty$ (by convention for minimization).
      <br>By Strong Duality for LPs, $d^* = p^* = +\infty$.
      <br>This means the dual problem $\max \{ b^\top y \mid A^\top y \le 0 \}$ is unbounded above.
      <br>For the objective $b^\top y$ to grow arbitrarily large while $y$ remains in the cone $A^\top y \le 0$, there must exist a direction $y$ such that $A^\top y \le 0$ and $b^\top y > 0$ (otherwise the max would be 0).
      <br>Let $z = -y$. Then $A^\top (-z) \le 0 \implies A^\top z \ge 0$ and $b^\top (-z) > 0 \implies b^\top z < 0$.
      <br>This $z$ is a solution to system (2). Thus, system (2) <b>has a solution</b>.
    </div>
  </div>
</div>

<div class="problem">
  <h3>P9.6 — KKT for Water-filling</h3>
  <p>Solve $\min \sum_{i=1}^n -\log(\alpha_i + x_i)$ subject to $x \ge 0, \mathbf{1}^\top x = 1$. Assume $\alpha_i > 0$. Derive the water-filling solution.</p>

  <div class="recap-box">
    <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
    <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
        <li><b>Marginal Utility:</b> Optimality requires equalizing marginal utility ($1/(\alpha_i+x_i)$) across all active allocations.</li>
        <li><b>Active Set:</b> The "water level" $\nu$ determines which channels are active. Channels with high noise ($\alpha_i > 1/\nu$) receive zero power.</li>
    </ul>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      <strong>Lagrangian:</strong> $L(x, \lambda, \nu) = -\sum \log(\alpha_i + x_i) - \lambda^\top x + \nu(\sum x_i - 1)$.
    </div>
    <div class="proof-step">
      <strong>Stationarity:</strong> $\frac{-1}{\alpha_i + x_i} - \lambda_i + \nu = 0 \implies \alpha_i + x_i = \frac{1}{\nu - \lambda_i}$.
    </div>
    <div class="proof-step">
      <strong>Complementary Slackness:</strong> $\lambda_i x_i = 0, \lambda_i \ge 0, x_i \ge 0$.
      <ul>
        <li>Case 1: $x_i > 0$. Then $\lambda_i = 0$. The stationarity condition becomes $\frac{1}{\alpha_i + x_i} = \nu \implies \alpha_i + x_i = \frac{1}{\nu}$. Thus $x_i = \frac{1}{\nu} - \alpha_i$. (Note: for $x_i > 0$, we need $1/\nu > \alpha_i$).</li>
        <li>Case 2: $x_i = 0$. The stationarity condition is $\frac{1}{\alpha_i} = \nu - \lambda_i$. Since $\lambda_i \ge 0$, we have $\nu - \lambda_i \le \nu$.
        Assuming $\nu > 0$ and $\nu - \lambda_i > 0$, taking reciprocals reverses the inequality:
        $$ \frac{1}{\nu - \lambda_i} \ge \frac{1}{\nu} $$
        Substituting back: $\alpha_i \ge \frac{1}{\nu}$.
        </li>
      </ul>
    </div>
    <div class="proof-step">
      <strong>Combined Solution:</strong>
      Combining the cases:
      $$ x_i = \max\left(0, \frac{1}{\nu} - \alpha_i\right) $$
      Here $\mu = 1/\nu$ acts as the "water level". We choose the water level such that the total amount of water poured equals the budget: $\sum x_i = 1$.
    </div>
  </div>
</div>

<div class="problem">
  <h3>P9.7 — KKT for Standard QP</h3>
  <p>Consider the Quadratic Program:</p>
  $$ \min_x \frac{1}{2} x^\top P x + q^\top x \quad \text{s.t.} \quad Ax \le b $$
  <p>where $P \in \mathbb{S}^n_{++}$ (positive definite).</p>
  <p><strong>(a)</strong> Write down the KKT conditions for this problem.</p>
  <p><strong>(b)</strong> Combine them to show that solving the KKT system is equivalent to solving a system of equations involving the active set.</p>

  <div class="recap-box">
    <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
    <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
        <li><b>Linear KKT Systems:</b> For QPs, the stationarity condition is linear in $x$ and $\lambda$. If we knew which constraints were active (the "active set"), the KKT conditions would reduce to a single system of linear equations.</li>
        <li><b>Active Set Methods:</b> Many QP solvers work by iteratively guessing the active set and solving the resulting linear system.</li>
    </ul>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      <strong>Part (a): KKT Conditions.</strong>
      <ol>
        <li><b>Primal Feasibility:</b> $Ax \le b$.</li>
        <li><b>Dual Feasibility:</b> $\lambda \ge 0$.</li>
        <li><b>Complementary Slackness:</b> $\lambda_i (a_i^\top x - b_i) = 0$ for all $i$.</li>
        <li><b>Stationarity:</b> $\nabla f_0(x) + \sum \lambda_i \nabla f_i(x) = 0 \implies Px + q + A^\top \lambda = 0$.</li>
      </ol>
    </div>
    <div class="proof-step">
      <strong>Part (b): Active Set Interpretation.</strong>
      Let $I \subseteq \{1, \dots, m\}$ be the set of indices where $a_i^\top x = b_i$ (active constraints).
      Complementary slackness implies $\lambda_i = 0$ for $i \notin I$.
      The stationarity equation becomes:
      $$ Px + q + \sum_{i \in I} \lambda_i a_i = 0 $$
      Combined with $a_i^\top x = b_i$ for $i \in I$, we have a square linear system (assuming $|I| \le n$ and independence):
      $$
      \begin{bmatrix} P & A_I^\top \\ A_I & 0 \end{bmatrix} \begin{bmatrix} x \\ \lambda_I \end{bmatrix} = \begin{bmatrix} -q \\ b_I \end{bmatrix}
      $$
    </div>
  </div>
</div>

<div class="problem">
  <h3>P9.8 — Certificates of Infeasibility (Gordan's Theorem)</h3>
  <p>A system of inequalities is <b>infeasible</b> if no solution exists. A <b>certificate of infeasibility</b> is a dual vector that proves this fact.
  <br><strong>Gordan's Theorem</strong> states that exactly one of the following systems has a solution:</p>
  <ol>
    <li>$Ax < 0$ (Strict homogeneous inequalities)</li>
    <li>$A^\top y = 0, y \ge 0, y \ne 0$ (Dual certificate)</li>
  </ol>
  <p>Prove this using the separation of convex sets.</p>

  <div class="recap-box">
    <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
    <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
        <li><b>Theorems of Alternatives:</b> Gordan's Theorem is another variant of Farkas' Lemma. It deals with strict inequalities.</li>
        <li><b>Separation Argument:</b> If the set $K = \{Ax \mid x \in \mathbb{R}^n\}$ (a subspace) does not intersect the open negative orthant $\mathbb{R}^m_{--}$, we can separate them with a hyperplane. This hyperplane normal gives the certificate $y$.</li>
    </ul>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      <strong>Step 1: Set definitions.</strong>
      Let $S = \{Ax \mid x \in \mathbb{R}^n\}$ be the range space of $A$. This is a convex set (a subspace).
      Let $C = \{z \in \mathbb{R}^m \mid z < 0\}$ be the open negative orthant. This is a convex cone.
    </div>
    <div class="proof-step">
      <strong>Step 2: Mutual Exclusivity.</strong>
      System (1) has a solution iff $S \cap C \ne \emptyset$.
      Suppose both have solutions. There exists $x$ such that $Ax < 0$, and $y \ge 0, y \ne 0$ such that $A^\top y = 0$.
      Consider the inner product $y^\top (Ax)$.
      On one hand, $y^\top A x = (A^\top y)^\top x = 0^\top x = 0$.
      On the other hand, $y \ge 0, y \ne 0$ and $Ax < 0$ (strictly negative components). The dot product of a non-negative non-zero vector and a strictly negative vector must be strictly negative.
      $y^\top (Ax) < 0$.
      Contradiction ($0 < 0$). Thus, both cannot be true.
    </div>
    <div class="proof-step">
      <strong>Step 3: Covering all cases (Separating Hyperplane).</strong>
      If (1) has no solution, then $S \cap C = \emptyset$.
      Since $C$ is open and convex and $S$ is convex, there exists a separating hyperplane defined by normal $y \ne 0$ such that:
      $y^\top z \le y^\top w$ for all $z \in C, w \in S$.
      Since $S$ is a subspace, $y^\top w$ must be bounded below, which implies $y^\top w = 0$ for all $w \in S$ (otherwise it goes to $-\infty$). Thus $y \perp \text{range}(A) \implies A^\top y = 0$.
      The condition becomes $y^\top z \le 0$ for all $z < 0$. This implies $y \ge 0$.
      Thus we found $y \ge 0, y \ne 0$ with $A^\top y = 0$. This is a solution to (2).
    </div>
  </div>
</div>



<div class="problem">
  <h3>P9.9 — The Gap Certificate Cookbook</h3>
  <p>For each of the following problems, determine the dual variables, the dual objective function $d(\lambda, \nu)$, and the formula for the duality gap $\text{gap} = p(x) - d(\lambda, \nu)$.</p>
  <ol>
    <li><b>Least Squares:</b> $\min_x \frac{1}{2}\|Ax-b\|_2^2$ (Use the equivalent constrained form $\min \frac{1}{2}\|y\|_2^2$ s.t. $y=Ax-b$)</li>
    <li><b>Ridge Regression:</b> $\min_x \frac{1}{2}\|Ax-b\|_2^2 + \frac{\lambda}{2}\|x\|_2^2$</li>
    <li><b>LASSO:</b> $\min_x \frac{1}{2}\|Ax-b\|_2^2 + \rho \|x\|_1$</li>
    <li><b>Basis Pursuit:</b> $\min_x \|x\|_1$ s.t. $Ax=b$</li>
  </ol>
  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      <strong>1. Least Squares:</strong>
      Primal: $\min_x \frac{1}{2}\|Ax-b\|^2$. No explicit dual usually, but using $y=Ax-b$:
      Dual Feasibility: $A^\top \nu = 0$.
      Dual Objective: $d(\nu) = -\frac{1}{2}\|\nu\|^2 - \nu^\top b$.
      Gap: $\frac{1}{2}\|Ax-b\|^2 + \frac{1}{2}\|\nu\|^2 + \nu^\top b$.
    </div>
    <div class="proof-step">
      <strong>2. Ridge Regression:</strong>
      Primal: $\min \frac{1}{2}\|Ax-b\|^2 + \frac{\lambda}{2}\|x\|^2$.
      Dual Variable: $y$ (unconstrained).
      Dual Objective: $d(y) = -\frac{1}{2}\|y\|^2 - y^\top b - \frac{1}{2\lambda}\|A^\top y\|^2$.
      Gap: $\frac{1}{2}\|Ax-b\|^2 + \frac{\lambda}{2}\|x\|^2 + \frac{1}{2}\|y\|^2 + y^\top b + \frac{1}{2\lambda}\|A^\top y\|^2$.
    </div>
    <div class="proof-step">
      <strong>3. LASSO:</strong>
      Primal: $\min \frac{1}{2}\|Ax-b\|^2 + \rho\|x\|_1$.
      Dual Variable: $y$. Constraint: $\|A^\top y\|_\infty \le \rho$.
      Dual Objective: $d(y) = -\frac{1}{2}\|y\|^2 - y^\top b$.
      Gap: $\frac{1}{2}\|Ax-b\|^2 + \rho\|x\|_1 + \frac{1}{2}\|y\|^2 + y^\top b$.
    </div>
    <div class="proof-step">
      <strong>4. Basis Pursuit:</strong>
      Primal: $\min \|x\|_1$ s.t. $Ax=b$.
      Dual Variable: $y$. Constraint: $\|A^\top y\|_\infty \le 1$.
      Dual Objective: $d(y) = b^\top y$.
      Gap: $\|x\|_1 - b^\top y$.
    </div>
  </div>
</div>

<div class="problem">
  <h3>P9.10 — SDP Duality: Max Cut Relaxation</h3>
  <p>The Max Cut problem can be relaxed to the following SDP:
  $$ \max_X \quad \frac{1}{4} \mathrm{tr}(W X) \quad \text{s.t.} \quad X_{ii} = 1, \quad X \succeq 0 $$
  where $W$ is the weighted adjacency matrix. Derive the dual problem.</p>
  <div class="recap-box">
    <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
    <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
        <li><b>Matrix Lagrange Multipliers:</b> For the constraint $X \succeq 0$, the multiplier is a matrix $Z \succeq 0$, and the term is $-\mathrm{tr}(ZX)$.</li>
        <li><b>Diagonal Constraints:</b> The constraints $X_{ii} = 1$ can be written as $\mathrm{diag}(X) = \mathbf{1}$. The multiplier is a vector $\nu$.</li>
    </ul>
  </div>
  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      <strong>Step 1: Lagrangian.</strong>
      We want to minimize the negative objective: $\min -\frac{1}{4}\mathrm{tr}(WX)$.
      Constraints: $X_{ii} = 1$ (multiplier $\nu_i$) and $X \succeq 0$ (multiplier $Z \succeq 0$).
      $$ L(X, \nu, Z) = -\frac{1}{4}\mathrm{tr}(WX) + \sum_{i=1}^n \nu_i (X_{ii} - 1) - \mathrm{tr}(ZX) $$
      Note: $\sum \nu_i X_{ii} = \mathrm{tr}(\mathrm{diag}(\nu) X)$.
      $$ L(X, \nu, Z) = \mathrm{tr}\left( \left( \mathrm{diag}(\nu) - \frac{1}{4}W - Z \right) X \right) - \sum \nu_i $$
    </div>
    <div class="proof-step">
      <strong>Step 2: Dual Function.</strong>
      Minimizing $L$ over $X$ (unconstrained symmetric matrix) requires the gradient to vanish.
      $$ \mathrm{diag}(\nu) - \frac{1}{4}W - Z = 0 $$
      If this holds, the minimum is $-\sum \nu_i$. Otherwise $-\infty$.
    </div>
    <div class="proof-step">
      <strong>Step 3: Dual Problem.</strong>
      Maximize $-\sum \nu_i$ subject to $Z \succeq 0$ and $Z = \mathrm{diag}(\nu) - \frac{1}{4}W$.
      Substituting $Z$: $\mathrm{diag}(\nu) - \frac{1}{4}W \succeq 0$.
      Equivalent Dual: $\min \sum \nu_i$ s.t. $\mathrm{diag}(\nu) \succeq \frac{1}{4}W$.
      (Usually written as $\min \mathbf{1}^\top \nu$ s.t. $4 \mathrm{diag}(\nu) \succeq W$).
    </div>
  </div>
</div>

<div class="problem">
  <h3>P9.11 — SOCP Duality: Robust Least Squares</h3>
  <p>Derive the dual of the Robust Least Squares problem:
  $$ \min_x \|Ax - b\|_2 + \rho \|x\|_2 $$
  Formulate the primal as an SOCP first.</p>
  <div class="recap-box">
    <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
    <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
        <li><b>SOCP Standard Form:</b> $\min c^\top x$ s.t. $\|A_i x + b_i\|_2 \le c_i^\top x + d_i$.</li>
        <li><b>Conic Duality:</b> The dual variables for second-order cone constraints lie in the second-order cone (self-dual).</li>
    </ul>
  </div>
  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      <strong>Step 1: Primal SOCP.</strong>
      Introduce $t_1, t_2$. Minimize $t_1 + \rho t_2$ subject to:
      $$ \|Ax - b\|_2 \le t_1 \iff (b - Ax, t_1) \in \mathcal{Q}_{m+1} $$
      $$ \|x\|_2 \le t_2 \iff (x, t_2) \in \mathcal{Q}_{n+1} $$
      (Note: we use $b-Ax$ to align with standard form $Ax=b$, but inside the norm signs matter less).
    </div>
    <div class="proof-step">
      <strong>Step 2: Lagrangian.</strong>
      We associate dual variables $(z_1, \mu_1) \in \mathcal{Q}_{m+1}$ and $(z_2, \mu_2) \in \mathcal{Q}_{n+1}$.
      The Lagrangian term for a conic constraint $y \in K$ is $-s^\top y$ where $s \in K^*$. Here $K=K^*$.
      $$ L = t_1 + \rho t_2 - [z_1^\top(Ax - b) + \mu_1 t_1] - [z_2^\top x + \mu_2 t_2] $$
      Minimizing over $t_1 \implies 1 - \mu_1 = 0 \implies \mu_1 = 1$.
      Minimizing over $t_2 \implies \rho - \mu_2 = 0 \implies \mu_2 = \rho$.
      Minimizing over $x \implies -A^\top z_1 - z_2 = 0 \implies z_2 = -A^\top z_1$.
    </div>
    <div class="proof-step">
      <strong>Step 3: Dual Constraints.</strong>
      From conic feasibility of dual vars:
      $\|z_1\|_2 \le \mu_1 \implies \|z_1\|_2 \le 1$.
      $\|z_2\|_2 \le \mu_2 \implies \|z_2\|_2 \le \rho$.
      Substituting $z_2 = -A^\top z_1$, we get $\|A^\top z_1\|_2 \le \rho$.
    </div>
    <div class="proof-step">
      <strong>Step 4: Dual Problem.</strong>
      The remaining term in Lagrangian is $z_1^\top b$.
      $$ \max_{z_1} \quad b^\top z_1 \quad \text{s.t.} \quad \|z_1\|_2 \le 1, \quad \|A^\top z_1\|_2 \le \rho $$
      This is the dual of Robust Least Squares. It is a maximization of a linear function over the intersection of a ball and an ellipsoidal cylinder.
    </div>
  </div>
</div>

<div class="problem">
  <h3>P9.12 — Chebyshev Approximation vs Least Squares</h3>
  <p>Consider the problem of minimizing the $\ell_\infty$ norm of the residual: $p^* = \min_x \|Ax - b\|_\infty$.
  <br>Let $x_{ls}$ be the least-squares solution ($p_{ls} = \min \|Ax-b\|_2$).
  <br><strong>(a)</strong> Prove that the least-squares solution provides a $\sqrt{m}$-approximation: $\|Ax_{ls} - b\|_\infty \le \sqrt{m} p^*$.
  <br><strong>(b)</strong> Derive the dual problem and show how to construct a lower bound certificate using the least-squares residual.</p>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      <strong>(a) Primal Bound ($\sqrt{m}$-approximation).</strong>
      Let $r(x) = Ax - b$. We use the norm inequalities $\|z\|_\infty \le \|z\|_2 \le \sqrt{m}\|z\|_\infty$.
      <br>1. $\|r(x_{ls})\|_\infty \le \|r(x_{ls})\|_2$ (Max entry $\le$ Euclidean length).
      <br>2. $\|r(x_{ls})\|_2 \le \|r(x^*)\|_2$ (Since $x_{ls}$ minimizes the 2-norm, it beats any other $x$, including the Chebyshev optimizer $x^*$).
      <br>3. $\|r(x^*)\|_2 \le \sqrt{m}\|r(x^*)\|_\infty = \sqrt{m} p^*$ (Euclidean length $\le \sqrt{m} \times$ max entry).
      <br>Chaining these gives the result: $\|r(x_{ls})\|_\infty \le \sqrt{m} p^*$.
    </div>
    <div class="proof-step">
      <strong>(b) Zero-to-Hero Dual Derivation.</strong>
      Rewrite the primal as an LP: $\min_{x,t} t$ s.t. $Ax - b \le t\mathbf{1}$ and $-(Ax - b) \le t\mathbf{1}$.
      <br>The dual problem simplifies to:
      $$ \max_{\nu} b^\top \nu \quad \text{subject to} \quad A^\top \nu = 0, \ \|\nu\|_1 \le 1 $$
      Any feasible $\nu$ provides a lower bound $b^\top \nu \le p^*$.
    </div>
    <div class="proof-step">
      <strong>Constructing Certificates from Least Squares.</strong>
      Let $r_{ls} = b - Ax_{ls}$. The normal equations imply $A^\top r_{ls} = 0$. We can normalize $r_{ls}$ to be dual feasible.
      <br><b>Candidate 1 ($\ell_1$ normalized):</b> $\hat{\nu} = r_{ls} / \|r_{ls}\|_1$.
      <br>This is always feasible. Bound: $b^\top \hat{\nu} = \frac{b^\top r_{ls}}{\|r_{ls}\|_1} = \frac{(r_{ls} + Ax_{ls})^\top r_{ls}}{\|r_{ls}\|_1} = \frac{\|r_{ls}\|_2^2}{\|r_{ls}\|_1}$.
      <br><b>Candidate 2 ($\ell_\infty$ normalized):</b> $\tilde{\nu} = r_{ls} / \|r_{ls}\|_\infty$.
      <br>Feasible only if $\|\tilde{\nu}\|_1 \le 1$ (i.e., $\|r_{ls}\|_1 \le \|r_{ls}\|_\infty$). Bound: $\frac{\|r_{ls}\|_2^2}{\|r_{ls}\|_\infty}$.
      <br>Since $\|r\|_1 \ge \|r\|_\infty$, Candidate 2 is rarely feasible, but Candidate 1 provides a guaranteed computable lower bound.
    </div>
    <div class="proof-step">
      <strong>Bound Comparison.</strong>
      Is the dual bound better than the crude bound from (a)?
      <br>From (a), $p^* \ge \frac{1}{\sqrt{m}}\|r_{ls}\|_\infty$.
      <br>The dual bound is $\frac{\|r_{ls}\|_2^2}{\|r_{ls}\|_1}$. Using Cauchy-Schwarz ($\|r\|_1 \le \sqrt{m}\|r\|_2$), we have $\frac{\|r\|_2^2}{\|r\|_1} \ge \frac{\|r\|_2^2}{\sqrt{m}\|r\|_2} = \frac{\|r\|_2}{\sqrt{m}}$.
      <br>Since $\|r\|_2 \ge \|r\|_\infty$, the dual bound is strictly tighter (or equal): $\frac{\|r_{ls}\|_2^2}{\|r_{ls}\|_1} \ge \frac{1}{\sqrt{m}}\|r_{ls}\|_\infty$.
    </div>
  </div>
</div>

<div class="problem">
  <h3>P9.13 — Log-Sum-Exp Smoothing and Entropy</h3>
  <p>Consider minimizing the piecewise-linear function $f(x) = \max_i (a_i^\top x + b_i)$.
  <br><strong>(a)</strong> Derive the dual of the smooth approximation $f_{sm}(x) = \log(\sum \exp(a_i^\top x + b_i))$.
  <br><strong>(b)</strong> Show that the smoothing corresponds to adding an entropy regularization term to the dual.</p>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      <strong>(a) Dual Derivation.</strong>
      Using the conjugate identity $\log(\sum e^{u_i}) = \max_{\lambda \in \Delta} (\lambda^\top u - \sum \lambda_i \log \lambda_i)$.
      <br>Let $u_i = a_i^\top x + b_i$.
      $$ \min_x f_{sm}(x) = \min_x \max_{\lambda \in \Delta} \left( \sum \lambda_i (a_i^\top x + b_i) - \sum \lambda_i \log \lambda_i \right) $$
      Swap min and max (by minimax theorem). The inner min over $x$ is $\min_x (\sum \lambda_i a_i)^\top x$. This is bounded only if $A^\top \lambda = 0$ (weighted slope is zero).
    </div>
    <div class="proof-step">
      <strong>(b) Entropy Interpretation.</strong>
      The dual problem becomes:
      $$ \max_{\lambda} \quad b^\top \lambda - \sum_{i=1}^m \lambda_i \log \lambda_i \quad \text{s.t.} \quad A^\top \lambda = 0, \ \mathbf{1}^\top \lambda = 1, \ \lambda \ge 0 $$
      Comparing to the dual of the original max-function ($\max b^\top \lambda$ s.t. same constraints), we see the only difference is the term $-\sum \lambda_i \log \lambda_i$.
      <br>This <b>entropy term</b> regularizes the dual, encouraging the weights $\lambda$ to be uniform rather than sparse (sparse $\lambda$ corresponds to a "hard" max).
    </div>
  </div>
</div>

</section>
    </article>

    <footer class="site-footer">
      <div class="container">
        <p>© <span id="year"></span> Convex Optimization Course</p>
      </div>
    </footer>
  </main></div>

  <script src="../../static/js/math-renderer.js"></script>
  <script src="../../static/js/ui.js"></script>
  <script src="../../static/js/toc.js"></script>
  <script>
    feather.replace();
    document.getElementById('year').textContent = new Date().getFullYear();
  </script>
  <script src="../../static/js/glossary-loader.js"></script>
<script src="../../static/js/notes-widget.js"></script>
<script src="../../static/js/pomodoro.js"></script>
<script src="../../static/js/progress-tracker.js"></script>
</body>
</html>
<!-- Verified Phase 3 Content -->
