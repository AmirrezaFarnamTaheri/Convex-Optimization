<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>09. Duality — Convex Optimization</title>
  <link rel="stylesheet" href="../../static/css/convex-unified.css" />
  <script src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css" />
  <script src="https://unpkg.com/feather-icons"></script>
  <script type="importmap">
    {
      "imports": {
        "three": "https://cdn.jsdelivr.net/npm/three@0.128/build/three.module.js"
      }
    }
  </script>
</head>
<body>
  <header class="site-header">
    <div class="container header-inner">
      <div class="brand">
        <a href="../../index.html">Convex Optimization</a>
      </div>
      <nav class="nav">
        <a href="../../index.html"><i data-feather="grid"></i> All Lectures</a>
        <a href="../08-convex-problems-conic/index.html"><i data-feather="arrow-left"></i> Previous</a>
        <a href="../10-approximation-fitting/index.html">Next <i data-feather="arrow-right"></i></a>
      </nav>
    </div>
  </header>

  <div class="lecture-container"><aside class="sidebar"><div id="toc-container"><h2><i data-feather="list"></i> Table of Contents</h2><nav id="toc"></nav></div></aside><main class="lecture-content">
    <header class="lecture-header section-card">
      <h1>09. Duality</h1>
      <div class="lecture-meta">
        <span>Date: 2025-11-25</span>
        <span>Duration: 90 min</span>
        <span>Tags: duality, lagrangian, kkt, sensitivity</span>
      </div>
      <div class="lecture-summary">
        <p>This lecture explores the powerful theory of duality in convex optimization. We learn how to construct the Lagrangian and dual function to obtain lower bounds on the optimal value. We study the conditions for Strong Duality (Slater's condition) and derive the KKT conditions—the fundamental optimality criteria for convex problems. Finally, we interpret dual variables as shadow prices and sensitivity measures.</p>
      </div>
    </header>

    <section class="section-card">
      <h2><i data-feather="target"></i> Learning Objectives</h2>
      <p>After this lecture, you will be able to:</p>
      <ul>
        <li>Construct the Lagrangian and Dual Function for any optimization problem</li>
        <li>State and prove Weak Duality and Slater's Condition for Strong Duality</li>
        <li>Derive KKT conditions and use them to solve problems analytically</li>
        <li>Interpret dual variables as sensitivities ("shadow prices")</li>
        <li>Compute duals of LP, QP, SOCP, and SDP problems</li>
      </ul>
    </section>

    <div class="insight" style="margin-bottom: 24px;">
      <h4>The Meta-Question</h4>
      <p>Before we begin, we must fix the central question of this lecture:</p>
      <blockquote style="border-left: 4px solid var(--accent); padding-left: 16px; margin: 16px 0; font-size: 1.1em; font-style: italic;">
        "How can we certify optimality without solving the primal problem directly?"
      </blockquote>
      <p>Everything in primal–dual theory is an answer to that question.
      <br>$\bullet$ Dual variables are <b>prices</b>, <b>forces</b>, or <b>supporting hyperplanes</b>.
      <br>$\bullet$ Dual objectives are <b>lower bounds</b>.
      <br>$\bullet$ Strong duality is the miracle that the bound is <b>tight</b>.</p>
    </div>

    <article>
      <section class="section-card" id="section-1">
        <h2>1. Foundations: Geometry & Conjugates</h2>

        <div class="insight">
          <h4>The Road to Duality</h4>
          <p>Duality is a journey with four main stops. We will visit them in order:</p>
          <ol>
            <li><b>The Lagrangian</b> (§2): A tool from calculus to "soften" constraints into objective penalties.</li>
            <li><b>The Dual Function</b> (§3): The <i>best possible</i> lower bound obtained by minimizing the Lagrangian.</li>
            <li><b>The Dual Problem</b> (§4): The search for the optimal prices (multipliers) that maximize this lower bound.</li>
            <li><b>Strong Duality & KKT</b> (§5): The conditions under which the bound is tight ($p^\star = d^\star$) and the "equilibrium" equations that characterize the solution.</li>
          </ol>
        </div>

        <h3>1.1 Optimization Problem as an Object</h3>
        <p>You must be fluent with:</p>
        <ul>
            <li><b>Decision variable</b> $x \in \mathbb{R}^n$: The "knob" you turn. It is not an "unknown" to be solved for algebraically, but a choice to be made.</li>
            <li><b>Objective</b> $f_0(x)$: The cost function mapping choices to values in $\mathbb{R} \cup \{+\infty\}$.</li>
            <li><b>Constraints:</b> $f_i(x) \le 0$ (inequality) and $h_j(x) = 0$ (equality). These define the <b>feasible set</b> $\mathcal{F}$.</li>
        </ul>
        <p><b>Optimal Value Definition:</b> The primary mathematical object is the optimal value $p^\star$, defined as an <b>infimum</b>:</p>
        $$ p^\star = \inf_{x \in \mathcal{F}} f_0(x) $$
        <p>Why infimum? Because a minimum might not be attained (e.g., $\min e^{-x}$). The infimum always exists in the extended reals.
        <br><b>Infeasibility:</b> If $\mathcal{F} = \emptyset$, then $p^\star = +\infty$ (infimum over empty set).
        <br><b>Unboundedness:</b> If we can drive $f_0$ to $-\infty$ inside $\mathcal{F}$, then $p^\star = -\infty$.</p>

        <h3>1.2 Geometry of Constraints</h3>
        <p>This phase explains <i>why</i> Lagrange multipliers are even a reasonable idea.</p>
        <p><b>Constraint Geometry:</b>
        <ul>
            <li>Inequality constraints $f_i(x) \le 0$ define curved regions (sublevel sets).</li>
            <li>Equality constraints $h_j(x) = 0$ define manifolds (surfaces).</li>
            <li><b>Active constraints</b> define the boundary where the optimum lives.</li>
        </ul>
        </p>
        <p><b>Normal Cone Definition:</b> For a convex set $C$ and a point $\mathbf{x} \in C$, the <b>normal cone</b> $N_C(\mathbf{x})$ describes the "outward" directions that are blocked by the boundary.
        $$ N_C(\mathbf{x}) = \{\mathbf{g} \in \mathbb{R}^n \mid \mathbf{g}^\top (\mathbf{y} - \mathbf{x}) \le 0 \text{ for all } \mathbf{y} \in C\} $$
        <b>Key Geometric Fact:</b> At the optimum $x^\star$, the negative gradient of the objective $-\nabla f_0(x^\star)$ points "into the wall". Formally, $-\nabla f_0(x^\star) \in N_C(x^\star)$.
        <br>This "pressure" against the boundary is what <b>dual variables</b> (Lagrange multipliers) measure.</p>

        <h3>1.3 Supporting Hyperplanes (The Skeleton)</h3>
        <p>This is the deep geometric backbone of optimization.</p>
        <div class="theorem-box">
            <h4>Supporting Hyperplane Theorem</h4>
            <p>A hyperplane $H = \{x \mid a^\top x = \alpha\}$ <b>supports</b> a set $C$ at a point $x_0 \in \partial C$ if:
            <ol>
                <li>$x_0$ lies on the hyperplane ($a^\top x_0 = \alpha$).</li>
                <li>The entire set $C$ lies in one of the halfspaces defined by $H$ (e.g., $a^\top x \le \alpha$ for all $x \in C$).</li>
            </ol>
            <b>Key Fact:</b> If $C$ is convex, then <i>every</i> point on its boundary has at least one supporting hyperplane.</p>
        </div>
        <p><b>Optimality Connection:</b> In optimization, we usually minimize $f_0(x)$ over a convex set $\mathcal{F}$.
        <br>At the optimal point $x^\star$, the level set $\{x \mid f_0(x) \le p^\star\}$ and the feasible set $\mathcal{F}$ touch but do not overlap (their interiors are disjoint).
        <br>Thus, there exists a <b>separating hyperplane</b> between them. This hyperplane supports both sets at $x^\star$.
        <br><b>Internalize:</b> Optimality = Existence of a hyperplane that supports the feasible set <i>and</i> the objective epigraph.</p>

        <div style="margin-top: 24px; border: 1px solid rgba(255,255,255,0.1); border-radius: 8px; overflow: hidden;">
            <iframe src="widgets/separation_two_disks.html" width="100%" height="500" style="border:none; background:#0b0d12; box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06); width: 100%; max-width: 900px; display: block; margin: 0 auto;"></iframe>
        </div>

        <h3>1.4 The Engine of Duality: Conjugates (Recap)</h3>
        <p>In <a href="../06-convex-functions-advanced/index.html">Lecture 06</a>, we defined the <b>Convex Conjugate</b> $f^*$ as the pointwise supremum of affine functions:
        $$ f^*(\mathbf{y}) = \sup_{\mathbf{x} \in \mathrm{dom} f} (\mathbf{y}^\top \mathbf{x} - f(\mathbf{x})) $$
        Geometric duality rests on this transformation. The conjugate $f^*(\mathbf{y})$ represents the maximum gap between the linear function $\mathbf{y}^\top \mathbf{x}$ and the function $f(\mathbf{x})$.</p>

        <p>We recall two essential facts that drive the duality engine:</p>
        <ul>
        <li><b>Convexity:</b> $f^*$ is always convex (even if $f$ is not).</li>
        <li><b>Fenchel-Young Inequality:</b> For any $\mathbf{x}, \mathbf{y}$:
        $$ f(\mathbf{x}) + f^*(\mathbf{y}) \ge \mathbf{x}^\top \mathbf{y} $$
        Equality holds if and only if $\mathbf{y} \in \partial f(\mathbf{x})$. This inequality is the algebraic source of <b>Weak Duality</b> ($p^\star \ge d^\star$).</li>
        </ul>

        <h3>1.5 Support Functions</h3>
        <p>Constraints are modeled by indicator functions $I_C(\mathbf{x})$. Their conjugates are <b>Support Functions</b>:
        $$ \sigma_C(\mathbf{y}) = I_C^*(\mathbf{y}) = \sup_{\mathbf{x} \in C} \mathbf{y}^\top \mathbf{x} $$
        This explains why dual problems involve maximizing linear functions over convex sets.</p>
      </section>

      <section class="section-card" id="section-2">
        <h2>2. The Lagrangian: Bending Constraints into the Objective</h2>

        <div class="insight">
          <h4>The Duality Story Arc</h4>
          <p>We are about to build a machine that converts "constraints" into "prices". Here is the logical chain:</p>
          <ol>
            <li><b>The Lagrangian</b> (§2): We "soften" hard constraints by turning them into linear penalties (prices/taxes).</li>
            <li><b>The Dual Function</b> (§3): By optimizing out the primal variables, we find the <i>best possible</i> lower bound on the optimal value for a given set of prices.</li>
            <li><b>The Dual Problem</b> (§4): We search for the <i>optimal prices</i> that give the tightest lower bound.</li>
            <li><b>KKT Conditions</b> (§5): At optimality, the forces balance perfectly—the gradient of the objective is exactly cancelled by the gradient of the constraints weighted by their optimal prices.</li>
          </ol>
        </div>

        <div class="insight">
          <h4>Why Penalties Alone Are Not Enough</h4>
          <p>We want to minimize $f_0(x)$ subject to constraints. We could just add a huge penalty for violating constraints ("soft constraints"), but how huge?
          <br>$\bullet$ If the penalty is too small, we violate the constraints.
          <br>$\bullet$ If the penalty is too large, the problem becomes numerically ill-conditioned.
          <br>The Lagrangian introduces <b>adaptive penalties</b> (multipliers) that are determined by the geometry of the problem itself, not by an arbitrary choice.</p>
        </div>

        <h3>2.1 Definition of the Lagrangian</h3>
        <p>Given the standard form primal problem:</p>
        <div style="padding: 16px; background: var(--panel); border-left: 4px solid var(--brand); margin: 16px 0;">
          <p style="margin: 0;">
            $
            \begin{aligned}
            \min_{x \in \mathbb{R}^n} \quad & f_0(x) \\
            \text{s.t.} \quad & f_i(x) \le 0, \quad i = 1, \dots, m \\
            & h_j(x) = 0, \quad j = 1, \dots, p
            \end{aligned}
            $
          </p>
        </div>
        <p>The <a href="#" class="definition-link">Lagrangian</a> $\mathcal{L}: \mathbb{R}^n \times \mathbb{R}^m \times \mathbb{R}^p \to \mathbb{R}$ augments the objective with a weighted sum of constraints:</p>
        $$
        \mathcal{L}(x, \lambda, \nu) = f_0(x) + \sum_{i=1}^m \lambda_i f_i(x) + \sum_{j=1}^p \nu_j h_j(x)
        $$
        <p>Key sign requirements you must internalize:</p>
        <ul>
            <li>$\mathbf{\lambda_i \ge 0}$ <b>is forced, not optional.</b> (Inequalities are one-sided).</li>
            <li>$\mathbf{\nu_j \in \mathbb{R}}$ <b>is free.</b> (Equalities are two-sided).</li>
        </ul>

        <h3>2.2 The Key Monotonicity Trick</h3>
        <p>Why do we require $\lambda_i \ge 0$? To ensure the Lagrangian is a <b>lower bound</b> on the objective for feasible points.</p>
        <p>Let $x$ be any feasible point. Then $f_i(x) \le 0$ and $h_j(x) = 0$.
        <br>If $\lambda_i \ge 0$, then $\lambda_i f_i(x) \le 0$.
        <br>Thus:</p>
        $$
        \mathcal{L}(x, \lambda, \nu) = f_0(x) + \underbrace{\sum \lambda_i f_i(x)}_{\le 0} + \underbrace{\sum \nu_j h_j(x)}_{= 0} \le f_0(x)
        $$
        <p>The Lagrangian is a <b>pointwise underestimator</b> of the objective function on the feasible set.</p>

        <h3>2.3 The Geometric Interpretation</h3>
        <p>Recall from <a href="../03-convex-sets-geometry/index.html">Lecture 03</a> that optimality is related to <b>supporting hyperplanes</b>. The Lagrangian is simply the algebraic representation of a hyperplane supporting the "achievable set" of objective and constraint values.
        <br>The multipliers $(\lambda, \nu)$ are the normal vector to this hyperplane. The condition $\lambda \ge 0$ ensures the hyperplane orientation respects the "less than or equal to" direction of the inequality constraints.</p>

        <img src="assets/duality_lagrangian_demo.gif" alt="Lagrangian as Lower Bound" style="max-width: 900px; width: 100%; height: auto; border-radius: 8px; border: 1px solid var(--border); padding: 16px; background: white; box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1); display: block; margin: 24px auto;">

        <div class="example">
          <h4>Motivating Example: Primal Dual Optimization Walkthrough</h4>
          <p>Consider the simple problem:
          $$ \min_{x,y} x^2 + y^2 \quad \text{subject to} \quad x+y \ge 1 $$
          <br><b>1. Primal Problem:</b> The feasible region is the half-plane $x+y \ge 1$. The level sets of the objective are circles centered at the origin. Geometrically, the minimum is the point on the line $x+y=1$ closest to the origin, which is $(0.5, 0.5)$, yielding $p^* = 0.5$.</p>
          <p><b>2. Lagrangian:</b> $L(x, y, \lambda) = x^2 + y^2 + \lambda(1 - x - y)$. (Note the constraint $1-x-y \le 0$).</p>
          <p><b>3. Dual Function:</b> Minimize $L$ over unconstrained $x, y$:
          $$ \nabla_x L = 2x - \lambda = 0 \implies x^* = \lambda/2, \quad y^* = \lambda/2 $$
          $$ g(\lambda) = (\lambda/2)^2 + (\lambda/2)^2 + \lambda(1 - \lambda) = \lambda^2/2 + \lambda - \lambda^2 = \lambda - \lambda^2/2 $$</p>
          <p><b>4. Dual Problem:</b> Maximize $g(\lambda) = \lambda - \lambda^2/2$ for $\lambda \ge 0$.
          <br>$\nabla g = 1 - \lambda = 0 \implies \lambda^* = 1$.
          <br>Dual optimal value $d^* = g(1) = 1 - 0.5 = 0.5$.</p>
          <p><b>Result:</b> $p^* = d^* = 0.5$. Strong duality holds.</p>
        </div>

        <h3>2.4 The Minimax (Saddle Point) Interpretation</h3>
        <p>We can recover the primal problem from the Lagrangian by maximizing over the dual variables. Define the function:</p>
        $$
        \sup_{\lambda \succeq 0, \nu} \mathcal{L}(x, \lambda, \nu) = \sup_{\lambda \succeq 0, \nu} \left( f_0(x) + \sum \lambda_i f_i(x) + \sum \nu_j h_j(x) \right)
        $$
        <ul>
          <li><strong>If $\mathbf{x}$ is feasible:</strong> $f_i(\mathbf{x}) \le 0$ and $h_j(\mathbf{x})=0$. To maximize the sum, the best we can do is set $\lambda_i=0$. The $\nu$ term is always 0. Thus, the supremum is $f_0(\mathbf{x})$.</li>
          <li><strong>If $\mathbf{x}$ is infeasible:</strong>
            <ul>
              <li>If $f_i(x) > 0$, we can let $\lambda_i \to \infty$, making the sum $\infty$.</li>
              <li>If $h_j(x) \ne 0$, we can let $\nu_j \to \text{sign}(h_j(x)) \cdot \infty$, making the sum $\infty$.</li>
            </ul>
          </li>
        </ul>
        <p>Thus, the unconstrained problem $\min_x \sup_{\lambda \succeq 0, \nu} \mathcal{L}(x, \lambda, \nu)$ is exactly equivalent to the original constrained primal problem.</p>

        <div class="intuition-box">
          <p><b>Duality as a Game:</b>
          <br><b>Primal:</b> $\min_x \max_{\lambda, \nu} \mathcal{L}(x, \lambda, \nu)$ (Minimizer moves first, Maximizer exploits violations).
          <br><b>Dual:</b> $\max_{\lambda, \nu} \min_x \mathcal{L}(x, \lambda, \nu)$ (Maximizer moves first, setting prices; Minimizer optimizes given prices).
          <br><b>Weak Duality</b> is simply the max-min inequality: $\max_{\lambda, \nu} \min_x \mathcal{L}(x, \lambda, \nu) \le \min_x \max_{\lambda, \nu} \mathcal{L}(x, \lambda, \nu)$. This inequality holds for <em>any</em> function, not just Lagrangians.
          <br><b>Strong Duality</b> implies the existence of a <b>Saddle Point</b> where the order of play doesn't matter, i.e., we can swap min and max.</p>
        </div>

        <div class="theorem-box">
            <h4>Deep Dive: Minimax Theorem and Zero-Sum Games</h4>
            <p>The duality gap for convex problems is intimately related to von Neumann's Minimax Theorem.
            <br>For a matrix game with payoff matrix $A$, player 1 minimizes loss $x^\top A y$ and player 2 maximizes gain.
            $$ \min_{x \in \Delta} \max_{y \in \Delta} x^\top A y = \max_{y \in \Delta} \min_{x \in \Delta} x^\top A y $$
            Linear programming duality is essentially the statement that this equality holds for linear constraints. Lagrangian duality extends this logic to general convex functions.</p>
        </div>

        <img src="assets/duality_saddle_path.gif" alt="Saddle Path Dynamics" style="max-width: 900px; width: 100%; height: auto; border-radius: 8px; border: 1px solid var(--border); padding: 16px; background: white; box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1); display: block; margin: 24px auto;">

        <div style="margin-top: 24px; border: 1px solid rgba(255,255,255,0.1); border-radius: 8px; overflow: hidden;">
            <iframe src="widgets/primal_dual_1d.html" width="100%" height="500" style="border:none; background:#0b0d12; box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06); width: 100%; max-width: 900px; display: block; margin: 0 auto;"></iframe>
        </div>
      </section>

      <section class="section-card" id="section-3">
        <h2>3. The Lagrange Dual Function: Lower Bounds from Nowhere</h2>

        <div class="insight">
          <h4>The Core Idea</h4>
          <p>This is the first conceptual leap. We convert the Lagrangian $\mathcal{L}(x, \lambda, \nu)$ into a function of only the dual variables $(\lambda, \nu)$ by minimizing out $x$. This new function $g(\lambda, \nu)$ is the <b>engine</b> of duality.</p>
        </div>

        <h3>3.1 Dual Function Definition</h3>
        <p>The <a href="#" class="definition-link">Lagrange dual function</a> $g: \mathbb{R}^m \times \mathbb{R}^p \to \mathbb{R} \cup \{-\infty\}$ is defined as the pointwise infimum of the Lagrangian over $x$:</p>
        $$
        g(\lambda, \nu) = \inf_{x \in \mathbb{R}^n} \mathcal{L}(x, \lambda, \nu) = \inf_{x \in \mathbb{R}^n} \left( f_0(x) + \sum_{i=1}^m \lambda_i f_i(x) + \sum_{j=1}^p \nu_j h_j(x) \right)
        $$
        <p><b>Note:</b> The infimum is over the <i>entire domain</i> of the functions (usually $\mathbb{R}^n$), not the feasible set. We have "relaxed" the constraints.</p>

        <div class="theorem-box">
          <h4>Key Property: Concavity</h4>
          <p>The dual function $g(\lambda, \nu)$ is <b>concave</b>, even if the primal problem is not convex.</p>
          <div class="proof-box">
            <h4>Proof</h4>
            <p>For each fixed $\mathbf{x}$, the function $(\lambda, \nu) \mapsto \mathcal{L}(\mathbf{x}, \lambda, \nu)$ is affine in $(\lambda, \nu)$.
            <br>The dual function $g$ is the pointwise infimum of a family of affine functions.
            <br>The infimum of concave (linear) functions is concave.</p>
          </div>
        </div>

        <div class="insight">
          <h4>Why the Dual is Always Convex (Even When the Primal is Not)</h4>
          <p>This is a fundamental fact that deserves emphasis. The dual problem:</p>
          $$ \max_{\lambda \succeq 0, \nu} g(\lambda, \nu) $$
          <p>is <b>always a convex optimization problem</b>:</p>
          <ul>
            <li>The domain $\{\lambda \succeq 0\}$ is a convex set (the non-negative orthant).</li>
            <li>Maximizing a concave function is equivalent to minimizing a convex function.</li>
          </ul>
          <p><b>Geometric Intuition:</b> For each fixed $x$, the Lagrangian is a "hyperplane" in $(\lambda, \nu)$-space. The dual function is the <b>lower envelope</b> of these hyperplanes. Lower envelopes of affine functions are always concave.</p>
        </div>

        <div class="proof-box">
          <h4>Deep Dive: The Dual of a Non-Convex Problem</h4>
          <p>We perform a rigorous derivation of the Lagrange dual for the problem $\min c^\top x$ subject to a single inequality $f(x) \le 0$. Crucially, we do <b>not</b> assume $f$ is convex.</p>

          <div class="proof-step">
            <strong>Step 0: The Primal Problem.</strong>
            Given $c \ne 0$ and $f: \mathbb{R}^n \to \mathbb{R} \cup \{+\infty\}$, we minimize $c^\top x$ subject to $f(x) \le 0$.
            $$ p^\star = \inf \{ c^\top x \mid f(x) \le 0 \} $$
          </div>

          <div class="proof-step">
            <strong>Step 1: The Lagrangian.</strong>
            We introduce a multiplier $\lambda \ge 0$. The Lagrangian is:
            $$ L(x, \lambda) = c^\top x + \lambda f(x) $$
          </div>

          <div class="proof-step">
            <strong>Step 2: The Dual Function.</strong>
            The dual function is the best lower bound certified by $\lambda$:
            $$ g(\lambda) = \inf_x L(x, \lambda) = \inf_x (c^\top x + \lambda f(x)) $$
          </div>

          <div class="proof-step">
            <strong>Step 3: Introducing the Conjugate.</strong>
            We rewrite the infimum using the conjugate $f^*(y) = \sup_x (y^\top x - f(x))$.
            Recall the key identity: $\inf_x (f(x) + a^\top x) = -f^*(-a)$.
            <br>For $\lambda > 0$:
            $$ g(\lambda) = \lambda \inf_x \left( f(x) + \frac{c^\top x}{\lambda} \right) = \lambda \left[ -f^*\left(-\frac{c}{\lambda}\right) \right] $$
          </div>

          <div class="proof-step">
            <strong>Step 4: The Dual Problem.</strong>
            We maximize $g(\lambda)$ over $\lambda > 0$:
            $$ \boxed{ \text{maximize } -\lambda f^*\left(-\frac{c}{\lambda}\right) \quad \text{subject to } \lambda > 0 } $$
          </div>
        </div>

        <h3>3.2 Weak Duality (The Universal Inequality)</h3>
        <p>The fundamental property of the dual function is that it yields lower bounds on the optimal value $p^\star$.</p>

        <div class="theorem-box">
          <h4>Theorem (Weak Duality)</h4>
          <p>For <b>any</b> optimization problem (convex or not), and any $\lambda \succeq 0, \nu$:</p>
          $$
          g(\lambda, \nu) \le p^\star
          $$
          <div class="proof-box">
            <h4>Proof</h4>
            <p>For any feasible $\tilde{x}$ and any $\lambda \succeq 0$:</p>
            $$
            \begin{aligned}
            g(\lambda, \nu) &= \inf_x \mathcal{L}(x, \lambda, \nu) \le \mathcal{L}(\tilde{x}, \lambda, \nu) \quad \text{(infimum is } \le \text{ value at } \tilde{x}) \\
            &\le f_0(\tilde{x}) \quad \text{(by the Monotonicity Trick from §2.2)}
            \end{aligned}
            $$
            <p>Since this holds for <i>every</i> feasible $\tilde{x}$, it holds for the infimum of the right side: $g(\lambda, \nu) \le \inf \{f_0(\tilde{x})\} = p^\star$.</p>
          </div>
        </div>

        <h3>3.3 Examples of Dual Functions</h3>
        <p>Calculating the dual function means solving an unconstrained minimization problem parameterized by $\lambda, \nu$. There are three main patterns:</p>

        <div class="example">
          <h4>1. Least Squares (Quadratic)</h4>
          <p>Primal: $\min x^\top x$ subject to $Ax = b$.
          <br>Lagrangian: $L(x, \nu) = x^\top x + \nu^\top (Ax - b)$.
          <br>Minimize over $\mathbf{x}$: $\nabla_{\mathbf{x}} L = 2\mathbf{x} + A^\top \nu = 0 \implies \mathbf{x} = -A^\top \nu / 2$.
          <br>Substitute back:
          $$ g(\nu) = L(-A^\top \nu / 2, \nu) = -\frac{1}{4} \nu^\top A A^\top \nu - b^\top \nu $$
          This is a concave quadratic function of $\nu$.
          <br>Dual Problem: Maximize $g(\nu)$. Unconstrained quadratic maximization.</p>
        </div>

        <div class="example">
          <h4>2. Linear Program (Standard Form)</h4>
          <p>Primal: $\min c^\top x$ s.t. $Ax = b, x \ge 0$.
          <br>Lagrangian: $L(x, \lambda, \nu) = c^\top x - \sum \lambda_i x_i + \nu^\top (Ax - b) = -b^\top \nu + (c + A^\top \nu - \lambda)^\top x$.
          <br>Dual function:
          $$ g(\lambda, \nu) = \inf_{x} L(x, \lambda, \nu) = \begin{cases} -b^\top \nu & \text{if } c + A^\top \nu - \lambda = 0 \\ -\infty & \text{otherwise} \end{cases} $$
          Dual Problem: Maximize $-b^\top \nu$ subject to $A^\top \nu + c = \lambda, \lambda \ge 0$.
          <br>Eliminating $\lambda$: Maximize $-b^\top \nu$ subject to $A^\top \nu + c \ge 0$.
          <br>Usually written with $y = -\nu$: Maximize $b^\top y$ s.t. $A^\top y \le c$. Standard LP dual.</p>
        </div>

        <div class="example">
          <h4>3. Conjugate Functions</h4>
          <p>Primal: $\min f(x)$ subject to $x = 0$ (constraint $x=0$).
          <br>Lagrangian: $L(x, \nu) = f(x) + \nu^\top x$.
          <br>Dual function: $g(\nu) = \inf_x (f(x) + \nu^\top x) = -\sup_x ((-\nu)^\top x - f(x)) = -f^*(-\nu)$.
          <br>Here, the dual function is directly related to the <b>convex conjugate</b>.</p>
        </div>

        <div style="margin-top: 24px; border: 1px solid rgba(255,255,255,0.1); border-radius: 8px; overflow: hidden;">
          <iframe src="widgets/logsumexp_conjugate_widget.html" width="100%" height="500" style="border:none; background:#0b0d12; box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06); width: 100%; max-width: 900px; display: block; margin: 0 auto;"></iframe>
        </div>

        <div style="margin-top: 24px; border: 1px solid rgba(255,255,255,0.1); border-radius: 8px; overflow: hidden;">
            <iframe src="widgets/equality_dual_projection_2d.html" width="100%" height="500" style="border:none; background:#0b0d12; box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06); width: 100%; max-width: 900px; display: block; margin: 0 auto;"></iframe>
        </div>
      </section>

      <section class="section-card" id="section-4">
        <h2>4. The Dual Problem and Strong Duality</h2>

        <h3>4.1 The Dual Problem</h3>
        <p>The <a href="#" class="definition-link">Lagrange dual problem</a> is to find the best lower bound on $p^*$:</p>
        <div style="padding: 16px; background: var(--panel); border-left: 4px solid var(--brand); margin: 16px 0;">
          <p style="margin: 0;">
            $
        \begin{aligned}
        \text{maximize} \quad & g(\lambda, \nu) \\
        \text{subject to} \quad & \lambda \succeq 0
        \end{aligned}
            $
          </p>
        </div>
        <p>This is a <b>convex optimization problem</b>, regardless of the primal's properties.</p>

        <div class="example">
            <h4>Example: Non-Convex Problem with Duality Gap</h4>
            <p>We illustrate the duality gap with a simple discrete optimization problem where the feasible set is not convex.</p>
            <p><b>Primal Problem:</b>
            $$ \min x \quad \text{s.t.} \quad 2x = 1, \ x \in \{0, 1\} $$
            The constraint $2x=1$ requires $x=0.5$, but the domain is $\{0, 1\}$. Thus, the problem is infeasible and $p^* = +\infty$.</p>

            <p><b>Lagrangian:</b>
            $$ L(x, \nu) = x + \nu(1 - 2x) = (1-2\nu)x + \nu $$
            </p>

            <p><b>Dual Function:</b>
            The dual function minimizes the Lagrangian over the domain $D=\{0, 1\}$:
            $$ g(\nu) = \inf_{x \in \{0, 1\}} ((1-2\nu)x + \nu) = \min((1-2\nu)(0) + \nu, (1-2\nu)(1) + \nu) = \min(\nu, 1-\nu) $$
          </p>

            <p><b>Dual Problem:</b>
            Maximize $g(\nu) = \min(\nu, 1-\nu)$. The maximum occurs at $\nu = 0.5$, yielding $d^* = 0.5$.</p>

            <p><b>Result:</b> $p^* - d^* = \infty - 0.5 = \infty$. The duality gap is infinite.</p>
        </div>

        <img src="assets/duality_gap_convergence.gif" alt="Duality Gap Convergence" style="max-width: 900px; width: 100%; height: auto; border-radius: 8px; border: 1px solid var(--border); padding: 16px; background: white; box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1); display: block; margin: 24px auto;">

        <h3>4.2 Strong Duality and Slater's Condition</h3>
        <p>Strong duality means $d^* = p^*$ (zero duality gap). It does not hold generally but usually holds for convex problems under mild conditions.</p>

        <div class="theorem-box">
          <h4>Theorem (Slater's Condition)</h4>
          <p>For a convex optimization problem:
          $$ \min f_0(x) \quad \text{s.t.} \quad f_i(x) \le 0, \quad Ax = b $$
          If there exists a point $x \in \mathrm{relint}(\mathcal{D})$ such that:
          $$ f_i(x) < 0, \quad i=1,\dots,m, \quad Ax = b $$
          (strictly feasible for non-affine inequalities), then <b>strong duality holds</b> ($d^* = p^*$) and the dual optimal value is attained (if $p^* > -\infty$).</p>
        </div>

        <div style="margin-top: 24px; border: 1px solid rgba(255,255,255,0.1); border-radius: 8px; overflow: hidden;">
            <iframe src="widgets/slater_failure_dual_attainment.html" width="100%" height="500" style="border:none; background:#0b0d12; box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06); width: 100%; max-width: 900px; display: block; margin: 0 auto;"></iframe>
        </div>

        <div class="proof-box">
          <h4>Geometric Proof via Separation</h4>
          <p>This proof constructs the dual variables as the coefficients of a separating hyperplane in the space of (constraints, objective).</p>
          <div class="proof-step">
            <strong>Step 1: The Set of Achievable Values $\mathcal{A}$.</strong>
            Consider the set of triplets $(u, v, t)$ that are "worse" than some feasible point $\mathbf{x}$:
            $$ \mathcal{A} = \{ (u, v, t) \mid \exists x \in \mathcal{D}, f_i(x) \le u_i, h_j(x) = v_j, f_0(x) \le t \} $$
            This set is convex (it's the projection of the epigraph of the problem).
          </div>
          <div class="proof-step">
            <strong>Step 2: Separation.</strong>
            The point $(0, 0, p^*)$ is on the boundary of $\mathcal{A}$.
            By the <a href="../03-convex-sets-geometry/index.html#section-3">Separating Hyperplane Theorem</a>, there exists a non-zero vector $(\lambda, \nu, \mu)$ separating $\mathcal{A}$ from $(0,0,p^*)$.
          </div>
          <div class="proof-step">
            <strong>Step 3: Slater's Condition implies Non-Verticality ($\mu > 0$).</strong>
            Analysis of the directions implies $\lambda \succeq 0, \mu \ge 0$.
            If $\mu = 0$, the separation implies a contradiction with Slater's strictly feasible point. Thus $\mu > 0$.
          </div>
          <div class="proof-step">
            <strong>Step 4: Recovering Strong Duality.</strong>
            Divide the separation inequality by $\mu$. Let $\tilde{\lambda} = \lambda/\mu, \tilde{\nu} = \nu/\mu$.
            This leads to $g(\tilde{\lambda}, \tilde{\nu}) \ge p^*$.
            Since $d^* \le p^*$ always, we conclude $d^* = p^*$.
          </div>
        </div>
      </section>

      <section class="section-card" id="section-5">
        <h2>5. KKT Conditions: Optimality as Equilibrium</h2>

        <p>The Karush-Kuhn-Tucker (KKT) conditions provide a unified framework for optimality. For convex problems, they are necessary and sufficient.</p>

        <div class="theorem-box">
          <h4>Theorem (KKT Conditions)</h4>
          <p>Given a convex problem with differentiable functions that satisfies Slater's condition. $x^*$ and $(\lambda^*, \nu^*)$ are primal and dual optimal <b>if and only if</b>:</p>
        <ol>
            <li><b>Primal Feasibility:</b> $f_i(x^*) \le 0$, $h_j(x^*) = 0$.</li>
            <li><b>Dual Feasibility:</b> $\lambda^* \succeq 0$.</li>
            <li><b>Complementary Slackness:</b> $\lambda_i^* f_i(x^*) = 0$ for all $i$.</li>
            <li><b>Stationarity (Lagrangian Gradient):</b> $\nabla_x \mathcal{L}(x^*, \lambda^*, \nu^*) = 0$:
              $$ \nabla f_0(x^*) + \sum \lambda_i^* \nabla f_i(x^*) + \sum \nu_j^* \nabla h_j(x^*) = 0 $$
            </li>
        </ol>
        </div>

        <div class="insight">
          <h4>The Grand Unification: KKT as the Algorithm's Goal</h4>
          <p>The entire journey from Lagrangian $\to$ Dual Function $\to$ Dual Problem culminates here. The KKT conditions are the <b>necessary and sufficient conditions</b> for optimality in convex problems. This means solving an optimization problem is equivalent to solving the KKT system of equations.</p>
        </div>

        <h3>5.2 Algorithms: Solving via Duality</h3>
        <p>Why do we care about KKT conditions? Because they are the blueprint for modern solvers.</p>
        <p><b>1. Primal-Dual Interior-Point Methods:</b>
        <br>Solvers like CVXPY (using ECOS or SCS) solve the <b>Primal</b> and <b>Dual</b> problems simultaneously. They maintain a primal point $x$ and dual points $(\lambda, \nu)$ and try to satisfy the KKT conditions.
        <br>Specifically, they relax the <b>Complementary Slackness</b> condition:
        $$ \lambda_i f_i(x) = -1/t $$
        This defines the "Central Path". As $t \to \infty$, the solution converges to the true KKT point.</p>

        <p><b>2. The Duality Gap as a Stopping Criterion:</b>
        <br>How does a solver know when to stop? It computes the duality gap:
        $$ \text{Gap} = f_0(x) - g(\lambda, \nu) $$
        If the gap is $\le \epsilon$, we are guaranteed to be $\epsilon$-close to the global optimum. No other method gives this <b>certificate of optimality</b>.</p>

        <div class="proof-box">
          <h4>Derivation from Strong Duality</h4>
          <p>Assume strong duality holds ($p^* = d^*$) and let $x^*$ and $(\lambda^*, \nu^*)$ be primal and dual optimal.</p>
          <div class="proof-step">
            <strong>The Duality Sandwich:</strong>
            We construct a chain of inequalities starting from the optimal dual value and ending at the optimal primal value.
            $$
            \begin{aligned}
            d^* &= g(\lambda^*, \nu^*) \quad \text{(Definition of Dual Optimal)} \\
            &= \inf_x \mathcal{L}(x, \lambda^*, \nu^*) \quad \text{(Definition of Dual Function)} \\
            &\le \mathcal{L}(x^*, \lambda^*, \nu^*) \quad \text{(Infimum is } \le \text{ value at } x^*) \\
            &\le f_0(x^*) \quad \text{(Since } \lambda^* \ge 0 \text{ and } f_i(x^*) \le 0 \text{, the sum is } \le 0) \\
            &= p^* \quad \text{(Definition of Primal Optimal)}
            \end{aligned}
            $$
            Because Strong Duality holds ($d^* = p^*$), the start and end of this chain are equal. This forces <b>every inequality in the middle to be an equality</b>.
          </div>
          <div class="proof-step">
            <strong>Conclusion 1: Stationarity.</strong>
            The inequality $\inf_x \mathcal{L}(x, \lambda^*, \nu^*) \le \mathcal{L}(x^*, \lambda^*, \nu^*)$ becomes an equality.
            This implies that $\mathbf{x}^*$ is a global minimizer of the Lagrangian function.
            $$ \nabla_x \mathcal{L}(x^*, \lambda^*, \nu^*) = 0 $$
          </div>
          <div class="proof-step">
            <strong>Conclusion 2: Complementary Slackness.</strong>
            The inequality $\mathcal{L}(x^*, \lambda^*, \nu^*) \le f_0(x^*)$ is also an equality. This means:
            $$ \sum_{i=1}^m \lambda_i^* f_i(x^*) = 0 $$
            Since every term is non-positive, the sum can only be zero if <b>every single term is zero</b>.
          </div>
        </div>

        <img src="assets/duality_kkt_2d_fast.gif" alt="KKT Geometry" style="max-width: 900px; width: 100%; height: auto; border-radius: 8px; border: 1px solid var(--border); padding: 16px; background: white; box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1); display: block; margin: 24px auto;">
        <img src="assets/duality_comp_slack_switch.gif" alt="Complementary Slackness Switch" style="max-width: 900px; width: 100%; height: auto; border-radius: 8px; border: 1px solid var(--border); padding: 16px; background: white; box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1); display: block; margin: 24px auto;">

        <div class="insight">
          <h4>Geometric Interpretation via Normal Cones</h4>
          <p>The stationarity condition $0 \in \nabla f_0(x^*) + \sum \lambda_i \nabla f_i(x^*) + \sum \nu_j \nabla h_j(x^*)$ has a deep geometric meaning:
          $$ -\nabla f_0(x^*) \in N_{\mathcal{F}}(x^*) $$
          The negative gradient of the objective must lie in the <b>normal cone</b> of the feasible set at the optimal point.</p>
        </div>

        <div class="example">
          <h4>Application: Water-Filling (Channel Capacity)</h4>
          <p>Problem: $\min -\sum \log(\alpha_i + x_i)$ subject to $x \ge 0, \sum x_i = 1$.
          <br>Lagrangian: $L = -\sum \log(\alpha_i + x_i) - \sum \lambda_i x_i + \nu (\sum x_i - 1)$.
          <br>Stationarity: $\frac{-1}{\alpha_i + x_i} - \lambda_i + \nu = 0 \implies \alpha_i + x_i = \frac{1}{\nu - \lambda_i}$.
          <br>Complementary Slackness: $\lambda_i x_i = 0$.
          <ul>
            <li>If $x_i > 0$, then $\lambda_i = 0 \implies \alpha_i + x_i = 1/\nu$.</li>
            <li>If $x_i = 0$, then $\alpha_i = 1/(\nu-\lambda_i)$. Thus $\alpha_i \ge 1/\nu$.</li>
          </ul>
          Result: $x_i = \max(0, 1/\nu - \alpha_i)$. This is "water-filling" on the levels $\alpha_i$. We solve for $\nu$ such that $\sum x_i = 1$.</p>
        </div>

        <div style="margin-top: 24px; border: 1px solid rgba(255,255,255,0.1); border-radius: 8px; overflow: hidden;">
          <iframe src="widgets/kkt_vector_balance.html" width="100%" height="500" style="border:none; background:#0b0d12; box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06); width: 100%; max-width: 900px; display: block; margin: 0 auto;"></iframe>
        </div>
      </section>

      <section class="section-card" id="section-6">
        <h2>6. Perturbation and Sensitivity Analysis</h2>

        <p>Duality provides powerful insights into how the optimal value changes when constraints are perturbed.</p>

        <h3>6.1 The Value Function (Perturbation Function)</h3>
        <p>Consider the perturbed primal problem with optimal value $p^*(u, v)$:</p>
        $$
        \begin{aligned}
        \min \quad & f_0(x) \\
        \text{s.t.} \quad & f_i(x) \le u_i, \quad i=1\dots m \\
        & h_j(x) = v_j, \quad j=1\dots p
        \end{aligned}
        $$

        <h3>6.2 Convexity of the Value Function</h3>
        <p>If the original problem is convex (convex $f_0, f_i$, affine $h_j$), then $p^*(u, v)$ is a <b>convex function</b> of $(u, v)$.</p>

        <h3>6.3 Global Inequality (Subgradient Interpretation)</h3>
        <div class="theorem-box">
          <h4>Theorem: Optimal Multipliers as Subgradients</h4>
          <p>The optimal dual variables are (negative) subgradients of the value function at zero:</p>
          $$ \boxed{ (-\lambda^*, -\nu^*) \in \partial p^*(0, 0) } $$
          <p>This implies the global inequality:
          $$ p^*(u, v) \ge p^*(0, 0) - \lambda^{*\top} u - \nu^{*\top} v $$
          <b>Shadow Price Interpretation:</b>
          <ul>
            <li>$\lambda_i^* \ge 0$. Relaxing constraint $i$ ($u_i > 0$) lowers the optimal value. $\lambda_i^*$ is the rate of this improvement.</li>
            <li>If $p^*$ is differentiable, then $\frac{\partial p^*}{\partial u_i} = -\lambda_i^*$ and $\frac{\partial p^*}{\partial v_j} = -\nu_j^*$. The Lagrange multipliers are exactly the <strong>sensitivity</strong> of the optimal value to constraint perturbations.</li>
          </ul>
          </p>
        </div>

        <h3>6.4 Local Sensitivity</h3>
        <p>If $p^*(u, v)$ is differentiable at $(0, 0)$, then:</p>
        $$ \frac{\partial p^*(0, 0)}{\partial u_i} = -\lambda_i^*, \quad \frac{\partial p^*(0, 0)}{\partial v_j} = -\nu_j^* $$
        <p>Relaxing constraint $i$ ($u_i > 0$) improves the objective by approximately $\lambda_i^* u_i$. Tightening it ($u_i < 0$) worsens it.</p>

        <img src="assets/duality_sensitivity_supporting_line_fast.gif" alt="Sensitivity Analysis" style="max-width: 900px; width: 100%; height: auto; border-radius: 8px; border: 1px solid var(--border); padding: 16px; background: white; box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1); display: block; margin: 24px auto;">

        <div style="margin-top: 24px; border: 1px solid rgba(255,255,255,0.1); border-radius: 8px; overflow: hidden;">
          <iframe src="widgets/value_function_support.html" width="100%" height="500" style="border:none; background:#0b0d12; box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06); width: 100%; max-width: 900px; display: block; margin: 0 auto;"></iframe>
        </div>

        <h3>6.5 Certificates of Infeasibility</h3>
        <p>Duality can also prove that a problem is infeasible (primal) or unbounded below.</p>
        <div class="insight">
          <h4>The Core Pattern: Dual Rays</h4>
          <p>If the primal problem is infeasible, the dual problem is typically unbounded. We can find a "dual ray" (direction) along which the dual objective goes to $+\infty$.
          <br><b>Farkas' Lemma:</b> The system $Ax \le b$ is infeasible if and only if there exists $y \ge 0$ such that $A^\top y = 0$ and $b^\top y < 0$.
          <br>This vector $y$ is a <b>certificate of infeasibility</b>.</p>
        </div>
        <img src="assets/duality_farkas_xy_infeasible.gif" alt="Farkas Certificate" style="max-width: 900px; width: 100%; height: auto; border-radius: 8px; border: 1px solid var(--border); padding: 16px; background: white; box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1); display: block; margin: 24px auto;">
      </section>

      <section class="section-card" id="section-7">
        <h2>7. Examples of Dual Problems</h2>

        <h3>7.1 Linear Programming</h3>
        <p>Primal: $\min c^\top x$ s.t. $Ax \le b, x \ge 0$.
        <br>Dual: $\max -b^\top \lambda$ s.t. $A^\top \lambda + c \ge 0, \lambda \ge 0$. (See Sec 2.3).</p>

        <h3>7.2 Quadratic Programming</h3>
        <p>Primal: $\min \frac{1}{2}x^\top P x + q^\top x$ s.t. $Ax \le b$. ($P \succ 0$).
        <br>Lagrangian: $L(x, \lambda) = \frac{1}{2}x^\top P x + q^\top x + \lambda^\top (Ax - b)$.
        <br>Minimize over $\mathbf{x}$: $P\mathbf{x} + \mathbf{q} + A^\top \lambda = 0 \implies \mathbf{x} = -P^{-1}(\mathbf{q} + A^\top \lambda)$.
        <br>Dual Function (after algebra):
        $$ g(\lambda) = -\frac{1}{2} \lambda^\top (A P^{-1} A^\top) \lambda - (b + A P^{-1} q)^\top \lambda - \frac{1}{2} q^\top P^{-1} q $$
        This is a concave quadratic maximization (since $A P^{-1} A^\top \succeq 0$).</p>

      <figure class="animation-figure">
        <div class="animation-container">
          <img src="assets/supporting_hyperplanes_l1_linf_three_panels.gif" alt="Dual Norm Geometry Animation" loading="lazy" style="max-width: 900px; width: 100%; height: auto; border-radius: 8px; border: 1px solid var(--border); padding: 16px; background: white; box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1); display: block; margin: 24px auto;">
        </div>
        <figcaption><i>Animation:</i> Supporting hyperplanes $u^\top x = \|u\|_*$ for the $\ell_1$ and $\ell_\infty$ balls. The dual norm determines how far the hyperplane can be pushed before touching the ball.</figcaption>
      </figure>

        <h3>7.3 Semidefinite Programming</h3>
        <p>Primal: $\min \mathrm{tr}(CX)$ s.t. $\mathrm{tr}(A_i X) = b_i, X \succeq 0$.
        <br>Dual:
        $$
        \begin{aligned}
        \text{maximize} \quad & b^\top \nu \\
        \text{subject to} \quad & \sum_{i=1}^m \nu_i A_i \preceq C
        \end{aligned}
        $$
        This is another SDP.</p>
      </section>

      <section class="section-card" id="section-8">
        <h2>8. Generalized Inequalities and Conic Duality</h2>

        <div class="insight">
          <h4>Why Conic Duality Matters</h4>
          <p>The componentwise inequality $x \le 0$ (meaning $x \in -\mathbb{R}_+^n$) is just one special case of a <b>generalized inequality</b> $x \preceq_K 0$ (meaning $x \in -K$) where $K$ is a proper cone. Conic duality theory shows that <b>all convex optimization problems</b>—linear, quadratic, second-order cone, semidefinite, and beyond—are instances of the same unified framework.</p>
        </div>

        <h3>8.1 Proper Cones and Dual Cones</h3>
        <p>Recall from Lecture 04 that a <b>proper cone</b> $K \subseteq \mathbb{R}^n$ is a closed, convex, pointed cone with nonempty interior. The <b>dual cone</b> is:
        $$ K^* = \{ y \mid x^\top y \ge 0 \text{ for all } x \in K \} $$
        </p>

        <div class="example-box">
          <h4>Standard Proper Cones and Their Duals</h4>
          <ul>
            <li><b>Nonnegative Orthant:</b> $\mathbb{R}_+^n = \{x \mid x_i \ge 0\}$. Self-dual: $(\mathbb{R}_+^n)^* = \mathbb{R}_+^n$.</li>
            <li><b>Second-Order Cone (Lorentz Cone):</b> $\mathcal{Q}^n = \{(t, x) \in \mathbb{R} \times \mathbb{R}^{n-1} \mid \|x\|_2 \le t\}$. Self-dual: $(\mathcal{Q}^n)^* = \mathcal{Q}^n$.</li>
            <li><b>Positive Semidefinite Cone:</b> $\mathbb{S}_+^n = \{X \in \mathbb{S}^n \mid X \succeq 0\}$. Self-dual: $(\mathbb{S}_+^n)^* = \mathbb{S}_+^n$ (under trace inner product).</li>
          </ul>
        </div>

        <div style="margin: 24px 0; border: 1px solid rgba(255,255,255,0.1); border-radius: 8px; overflow: hidden;">
          <iframe src="widgets/soc_dual_cone.html" width="100%" height="500" style="border:none; background:#0b0d12; box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06); width: 100%; max-width: 900px; display: block; margin: 0 auto;"></iframe>
        </div>

        <h3>8.2 The Standard Conic Form</h3>
        <p>All conic programs can be written in a canonical form that makes the duality symmetric. The <b>primal</b> is:
        $$
        \begin{aligned}
        \text{minimize} \quad & c^\top x \\
        \text{subject to} \quad & Ax = b \\
        & x \in K
        \end{aligned}
        $$
        The <b>dual</b> is:
        $$
        \begin{aligned}
        \text{maximize} \quad & b^\top y \\
        \text{subject to} \quad & c - A^\top y = s \\
        & s \in K^*
        \end{aligned}
        $$
        This unifies <b>LP</b>, <b>SOCP</b>, and <b>SDP</b>.</p>

        <h3>8.3 Complementary Slackness for Conic Programs</h3>
        <p>For the standard conic form, complementary slackness states:
        $$ s^\top x = 0 $$
        where $x \in K$ (primal feasible) and $s \in K^*$ (dual feasible).
        <br>For SDP: If $X \succeq 0$ and $S \succeq 0$, then $\mathrm{tr}(SX) = 0$ implies $SX = 0$ (zero matrix product).</p>

        <div style="margin-top: 24px; border: 1px solid rgba(255,255,255,0.1); border-radius: 8px; overflow: hidden;">
          <iframe src="widgets/psd_cone_2x2.html" width="100%" height="500" style="border:none; background:#0b0d12; box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06); width: 100%; max-width: 900px; display: block; margin: 0 auto;"></iframe>
        </div>
      </section>

      <section class="section-card" id="section-9">
        <h2>9. Review & Cheat Sheet</h2>
        <h3>Key Definitions</h3>
        <ul>
          <li><b>Lagrangian:</b> $L(x, \lambda, \nu) = f_0(x) + \lambda^\top f(x) + \nu^\top h(x)$.</li>
          <li><b>Dual Function:</b> $g(\lambda, \nu) = \inf_x L(x, \lambda, \nu)$. (Always Concave).</li>
          <li><b>Weak Duality:</b> $d^* \le p^*$. (Always true).</li>
          <li><b>Strong Duality:</b> $d^* = p^*$. (Usually true for convex via Slater).</li>
        </ul>

        <h3>KKT Conditions (Convex + Slater $\iff$ Optimal)</h3>
        <ol>
          <li>$f_i(x) \le 0, h_j(x) = 0$ (Primal Feas)</li>
          <li>$\lambda_i \ge 0$ (Dual Feas)</li>
          <li>$\lambda_i f_i(x) = 0$ (Comp. Slackness)</li>
          <li>$\nabla f_0 + \sum \lambda_i \nabla f_i + \sum \nu_j \nabla h_j = 0$ (Stationarity)</li>
        </ol>
      </section>

      <section class="section-card" id="section-10">
      <h2>10. Canonical Duals: A Problem Pack</h2>
        <p>This section provides a "micro-toolbox" of derivations for standard problems. Mastering these specific derivations builds the pattern-matching skills needed for general duality.</p>

      <div class="insight">
        <h4>Micro-Toolbox</h4>
        <ul>
          <li><b>Lemma A1 (Linear Term):</b> $\inf_x a^\top x = 0$ if $a=0$, else $-\infty$. This generates equality constraints ($A^\top \nu + c = 0$).</li>
          <li><b>Lemma A2 (Quadratic Min):</b> $\inf_x (\frac{1}{2}x^\top P x + q^\top x) = -\frac{1}{2}q^\top P^{-1} q$ (if $P \succ 0$). This handles QP terms.</li>
          <li><b>Lemma A3 (Conjugate of Norm):</b> $\sup_x (y^\top x - \|x\|) = 0$ if $\|y\|_* \le 1$, else $\infty$. This generates dual norm constraints.</li>
        </ul>
      </div>

      <figure class="animation-figure">
        <div class="animation-container">
          <img src="assets/l1_linf_polar_swap.gif" alt="Polar Duality Animation" loading="lazy" style="max-width: 900px; width: 100%; height: auto; border-radius: 8px; border: 1px solid var(--border); padding: 16px; background: white; box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1); display: block; margin: 24px auto;">
        </div>
        <figcaption><i>Animation:</i> The polar of the $\ell_1$ ball is the $\ell_\infty$ ball, and vice versa. This geometric duality underpins the relationship between sparse primal solutions and box-constrained dual variables.</figcaption>
      </figure>

        <div class="problem">
          <h3>Problem 1: Least Squares (Residual Form)</h3>
        <p><b>Primal:</b> $\min \frac{1}{2} \|Ax - b\|_2^2$. Rewrite as $\min \frac{1}{2}\|y\|_2^2$ s.t. $y = Ax - b$.</p>
        <p><b>Lagrangian:</b> $L(x, y, \nu) = \frac{1}{2}\|y\|^2 + \nu^\top (Ax - b - y) = (\frac{1}{2}\|y\|^2 - \nu^\top y) + (A^\top \nu)^\top x - b^\top \nu$.</p>
        <p><b>Dual Function:</b>
        <br>1. Min over $\mathbf{x}$: Requires $A^\top \nu = 0$ (Lemma A1).
        <br>2. Min over $\mathbf{y}$: $\inf (\frac{1}{2}\|\mathbf{y}\|^2 - \nu^\top \mathbf{y}) = -\frac{1}{2}\|\nu\|^2$ (Lemma A2 with $P=I$).
        <br><b>Dual Problem:</b> $\max -\frac{1}{2}\|\nu\|^2 - b^\top \nu$ s.t. $A^\top \nu = 0$.
        </p>
        </div>

        <div class="problem">
        <h3>Problem 2: Ridge Regression</h3>
        <p><b>Primal:</b> $\min \frac{1}{2}\|Ax - b\|_2^2 + \frac{\lambda}{2}\|x\|_2^2$. Rewrite with $y = Ax - b$.</p>
        <p><b>Lagrangian:</b> $L(x, y, \nu) = \frac{1}{2}\|y\|^2 + \frac{\lambda}{2}\|x\|^2 + \nu^\top(Ax - b - y)$.</p>
        <p><b>Dual Function:</b>
        <br>1. Min over $\mathbf{y}$: same as above, $-\frac{1}{2}\|\nu\|^2$.
        <br>2. Min over $\mathbf{x}$: $\inf (\frac{\lambda}{2}\|\mathbf{x}\|^2 + (A^\top \nu)^\top \mathbf{x}) = -\frac{1}{2\lambda}\|A^\top \nu\|^2$.
        <br><b>Dual Problem:</b> $\max -b^\top \nu - \frac{1}{2}\|\nu\|^2 - \frac{1}{2\lambda}\|A^\top \nu\|^2$. (Unconstrained!)
        </p>
        </div>

        <div class="problem">
        <h3>Problem 3: LASSO</h3>
        <p><b>Primal:</b> $\min \frac{1}{2}\|Ax - b\|_2^2 + \lambda \|x\|_1$. Rewrite with $y = Ax - b$.</p>
        <p><b>Lagrangian:</b> $L(x, y, \nu) = \frac{1}{2}\|y\|^2 + \lambda \|x\|_1 + \nu^\top(Ax - b - y)$.</p>
        <p><b>Dual Function:</b>
        <br>1. Min over $\mathbf{y}$: $-\frac{1}{2}\|\nu\|^2$.
        <br>2. Min over $\mathbf{x}$: $\inf_{\mathbf{x}} (\lambda \|\mathbf{x}\|_1 + (A^\top \nu)^\top \mathbf{x}) = -\sup_{\mathbf{x}} (-(A^\top \nu)^\top \mathbf{x} - \lambda \|\mathbf{x}\|_1)$.
        This is finite (0) only if $\|A^\top \nu\|_\infty \le \lambda$ (Lemma A3 scaled).
        <br><b>Dual Problem:</b> $\max -b^\top \nu - \frac{1}{2}\|\nu\|^2$ s.t. $\|A^\top \nu\|_\infty \le \lambda$.
        </p>
        </div>

        <div class="problem">
        <h3>Problem 4: Basis Pursuit</h3>
        <p><b>Primal:</b> $\min \|x\|_1$ s.t. $Ax = b$.</p>
        <p><b>Lagrangian:</b> $L(x, \nu) = \|x\|_1 + \nu^\top(b - Ax) = b^\top \nu + (\|x\|_1 - (A^\top \nu)^\top x)$.</p>
        <p><b>Dual Function:</b>
        <br>The term $\inf_x (\|x\|_1 - z^\top x)$ is related to the conjugate of the L1 norm. It is finite (zero) iff the dual norm condition holds: $\|z\|_\infty \le 1$.
        <br>Here $z = A^\top \nu$.
        <br><b>Dual Problem:</b> $\max b^\top \nu$ s.t. $\|A^\top \nu\|_\infty \le 1$.
        <br><b>KKT Insight:</b> At optimum, $A^\top \nu \in \partial \|x\|_1$. Dual variables certify the support of the sparse solution.
        </p>
        </div>

        <div class="problem">
        <h3>Problem 5: LP Dual via Relaxed Problems</h3>
        <p><b>Primal:</b> $\min c^\top x$ s.t. $Ax \le b$.</p>
        <p><b>Interpretation:</b> Instead of enforcing all constraints, consider a non-negative weighted sum $w^\top A x \le w^\top b$.
        $$ \tilde{p}(w) = \min c^\top x \quad \text{s.t.} \quad (A^\top w)^\top x \le b^\top w $$
        The set of points satisfying the weighted constraint contains the original feasible set, so $\tilde{p}(w)$ is a lower bound.
        <br>The minimization $\min c^\top x$ s.t. $a^\top x \le \beta$ is finite only if $c$ is a multiple of $a$ (specifically $c = -ka$ for $k \ge 0$) or if $a=0$.
        <br>Setting the gradient to match: $c = -A^\top w$ (implies the objective is supported by the constraint).
        <br>The value is $-b^\top w$.
        <br>The best lower bound is $\max -b^\top w$ s.t. $A^\top w + c = 0, w \ge 0$. This recovers the standard LP dual.</p>
        </div>

        <div class="problem">
        <h3>Problem 6: Support Vector Machine (Hinge Loss)</h3>
        <p><b>Primal:</b> $\min \frac{1}{2}\|w\|^2 + C \sum \max(0, 1 - y_i w^\top x_i)$.
        <br>Rewrite: $\min \frac{1}{2}\|w\|^2 + C \sum \xi_i$ s.t. $\xi_i \ge 1 - y_i w^\top x_i, \xi_i \ge 0$.</p>
        <p><b>Dual Derivation:</b>
        <br>Lagrangian involves multipliers $\alpha_i, \mu_i$. Minimizing over $\mathbf{w}$ gives $\mathbf{w} = \sum \alpha_i y_i \mathbf{x}_i$.
        <br>Minimizing over $\xi$ gives constraint $0 \le \alpha_i \le C$.
        <br><b>Dual Problem:</b> $\max \sum \alpha_i - \frac{1}{2} \sum_{i,j} \alpha_i \alpha_j y_i y_j x_i^\top x_j$ s.t. $0 \le \alpha_i \le C, \sum \alpha_i y_i = 0$.
        </p>
        </div>

        <div class="problem">
        <h3>Problem 7: Trust-Region QCQP (Nonconvex with Strong Duality)</h3>
        <p><b>Primal:</b> $\min x^\top A x + 2 b^\top x$ s.t. $x^\top x \le 1$.</p>
        <p>This is the classic <b>trust-region subproblem</b>. Even if $A \not\succeq 0$ (making the objective nonconvex), strong duality still holds.</p>

        <div class="insight">
          <h4>Why It Matters</h4>
          <p>This problem arises in Newton-type methods when optimizing within a trusted region. The constraint $\|x\|_2 \le 1$ is the unit ball—the "trust region" where a quadratic approximation is valid.</p>
        </div>

        <p><b>Lagrangian:</b></p>
        $$ L(x, \lambda) = x^\top A x + 2 b^\top x + \lambda(x^\top x - 1) = x^\top (A + \lambda I) x + 2 b^\top x - \lambda $$

        <div class="proof-box">
          <h4>Deep Dive: Zero-to-Hero Derivation of the Dual</h4>
          <p>We derive the dual function $g(\lambda) = \inf_x L(x, \lambda)$ from first principles, showing why this nonconvex problem behaves nicely.</p>

          <div class="proof-step">
            <strong>1. The Lagrangian Form.</strong>
            Define $H(\lambda) = A + \lambda I$. The Lagrangian is a quadratic function of $x$:
            $$ L(x, \lambda) = x^\top H(\lambda) x + 2b^\top x - \lambda $$
            Even if $A$ is indefinite (negative eigenvalues), we can choose $\lambda$ large enough such that $H(\lambda) \succeq 0$. This "convexifies" the Lagrangian.
          </div>

          <div class="proof-step">
            <strong>2. Finiteness Conditions (Avoiding $-\infty$).</strong>
            The quadratic $L(x, \lambda)$ has a finite minimum if and only if:
            <ul>
              <li><b>Curvature:</b> $H(\lambda) \succeq 0$. If $H(\lambda)$ has a negative eigenvalue, we can send $x$ to infinity along that eigenvector to drive $L \to -\infty$. This forces $\lambda \ge -\lambda_{\min}(A)$.</li>
              <li><b>Range:</b> $b \in \mathcal{R}(H(\lambda))$. If $H(\lambda)$ is singular (has 0 eigenvalues), the quadratic is "flat" along the nullspace. If $b$ has a component in that nullspace ($b \notin \mathcal{R}(H(\lambda))$), the linear term $2b^\top x$ tilts the flat valley, driving the minimum to $-\infty$.</li>
            </ul>
          </div>

          <div class="proof-step">
            <strong>3. Computing the Minimum.</strong>
            When finite, the minimum is attained at any $x$ satisfying the stationarity condition $2H(\lambda)x + 2b = 0 \implies H(\lambda)x = -b$.
            <br>The optimal value is obtained by completing the square or using the pseudoinverse $H(\lambda)^\dagger$:
            $$ g(\lambda) = -b^\top H(\lambda)^\dagger b - \lambda $$
          </div>
        </div>

        <div class="theorem-box">
          <h4>Strong Duality Theorem</h4>
          <p><b>Theorem:</b> For the Trust Region Subproblem, $p^\star = d^\star$ even if non-convex.</p>
          <p><b>Geometric Intuition (The S-Lemma):</b>
          The joint range of $(x^\top x, x^\top A x + 2b^\top x)$ is a convex set in $\mathbb{R}^2$ (this is specific to having only <i>one</i> quadratic constraint).
          Because the image is convex, we can separate the optimal point from the infeasible region with a hyperplane. The normal vector to this hyperplane corresponds to the dual variable $\lambda$. Thus, a linear combination of the objective and constraint supports the optimal value exactly.</p>
        </div>
        </div>

        <div class="problem">
        <h3>Problem 8: Sum of Largest Elements (The Deep Dive) (Problem 5.19)</h3>
        <p><strong>Context:</strong> This problem is a masterclass in "Constructive Duality"—using duality to convert a combinatorial object (sum of sorted components) into a clean set of linear inequalities.
        <br>Let $f(x) = \sum_{i=1}^r x_{[i]}$ be the sum of the $r$ largest components of $x \in \mathbb{R}^n$.
        <br><strong>Goal:</strong> Prove that $f(x) \le \alpha$ is equivalent to a small system of linear inequalities.</p>
        <div class="solution-box">
          <h4>Solution</h4>

          <div class="proof-step">
            <strong>Step 1: The Variational Identity (Max over Subsets).</strong>
            First, we establish what $f(x)$ is combinatorially.
            $$ f(x) = \max \left\{ \sum_{i \in S} x_i \mid S \subseteq \{1,\dots,n\}, |S|=r \right\} $$
            <b>Proof:</b> Let $S^\star$ be the indices of the $r$ largest components. Then $\sum_{S^\star} x_i = f(x)$. For any other set $S$ of size $r$, its elements $x_{i_k}$ are term-by-term dominated by the globally largest elements $x_{[k]}$. Thus $\sum_S x_i \le f(x)$.
            <br><i>Implication:</i> The constraint $f(x) \le \alpha$ is equivalent to $\binom{n}{r}$ linear inequalities. We want to reduce this to $O(n)$.
          </div>

          <div class="proof-step">
            <strong>Step 2: The LP Representation (Primal).</strong>
            We relax the discrete subset choice to a continuous LP. Let $\mathcal{Y} = \{ y \in \mathbb{R}^n \mid 0 \le y \le \mathbf{1}, \mathbf{1}^\top y = r \}$.
            $$ f(x) = \max_{y \in \mathcal{Y}} x^\top y $$
            <p>We provide two rigorous proofs for why this relaxation is exact.</p>

            <p><b>Proof 1: Extreme Points (The Geometry).</b></p>
            <ul>
              <li>The feasible set $\mathcal{Y}$ is a bounded polyhedron (a polytope). Linearity of the objective implies the maximum is attained at an extreme point (vertex).</li>
              <li><b>Claim:</b> $\mathrm{ext}(\mathcal{Y}) = \{v \in \{0,1\}^n : \mathbf{1}^\top v = r\}$. (The vertices are exactly the subset indicators).</li>
              <li><b>Reasoning:</b> Suppose $y \in \mathcal{Y}$ has two fractional components $0 < y_i, y_j < 1$. We can perturb $y$ by adding/subtracting $\epsilon(e_i - e_j)$ while staying feasible. This shows $y$ is the midpoint of two distinct points in $\mathcal{Y}$, so it cannot be a vertex. Thus, vertices have at most one fractional component. But since $\sum y_i = r$ is integer, there cannot be exactly one fractional component. Therefore, all vertices are binary.</li>
            </ul>

            <p><b>Proof 2: The Exchange Argument (The Mechanics).</b></p>
            <p>Suppose an optimal $y$ puts positive weight on a "small" entry $x_j$ ($y_j > 0$) while a "large" entry $x_i$ ($x_i > x_j$) is not fully selected ($y_i < 1$).
            <br>We can define a new vector $y'$ by shifting $\epsilon = \min(y_j, 1-y_i)$ mass from $j$ to $i$.
            $$ y'_i = y_i + \epsilon, \quad y'_j = y_j - \epsilon $$
            The change in objective is $\epsilon(x_i - x_j) > 0$. This contradicts optimality. Thus, the optimal $y$ must fill the buckets corresponding to the largest $x_i$'s first, which recovers the "sum of largest" logic.</p>
          </div>

          <div class="proof-step">
            <strong>Step 3: Deriving the Dual.</strong>
            We transform the maximization LP into a minimization problem to expose the hidden variables.
            <br><b>Primal (P):</b> $\max x^\top y$ s.t. $y \le \mathbf{1}$, $y \ge 0$, $\mathbf{1}^\top y = r$.
            <br><b>Lagrangian Construction:</b> To minimize the upper bound, we format as $\min -x^\top y$.
            $$ L(y, u, v, t) = -x^\top y + u^\top(y-\mathbf{1}) + v^\top(-y) + t(\mathbf{1}^\top y - r) $$
            Here $u \ge 0$ handles the upper bound, $v \ge 0$ handles the lower bound, and $t \in \mathbb{R}$ handles the sum.
            $$ L = (-x + u - v + t\mathbf{1})^\top y - \mathbf{1}^\top u - rt $$
            <br><b>Dual Function:</b> The infimum over $y$ is finite only if the gradient vanishes (Stationarity):
            $$ -x + u - v + t\mathbf{1} = 0 \iff u - v + t\mathbf{1} = x $$
            If this holds, $g(u, v, t) = -\mathbf{1}^\top u - rt$.
            <br><b>Dual Problem (D):</b> Maximize the dual function (or minimize its negation):
            $$ \min_{t, u, v} \ rt + \mathbf{1}^\top u \quad \text{s.t.} \quad u - v + t\mathbf{1} = x, \ u, v \ge 0 $$
            <b>Simplification:</b> Eliminate $v$. From stationarity, $v = u + t\mathbf{1} - x$. The constraint $v \ge 0$ becomes $u + t\mathbf{1} \ge x$.
            $$ f(x) = \min_{t, u} \left\{ rt + \mathbf{1}^\top u \mid t\mathbf{1} + u \ge x, \ u \ge 0 \right\} $$
          </div>

          <div class="proof-step">
            <strong>Step 4: The Compact Constraint.</strong>
            By Strong Duality, $f(x) \le \alpha$ if and only if there exists a feasible dual point with objective $\le \alpha$.
            $$ \boxed{ rt + \sum_{i=1}^n u_i \le \alpha, \quad t + u_i \ge x_i, \quad u_i \ge 0 \quad (\forall i) } $$
            This uses $2n+1$ inequalities instead of $\binom{n}{r}$.
          </div>

          <div class="proof-step">
            <strong>Step 5: The "Threshold" Interpretation via KKT.</strong>
            The KKT conditions reveal the mechanical role of the dual variables.
            From stationarity ($u_i - v_i = x_i - t$) and complementary slackness ($u_i(y_i-1)=0, v_iy_i=0$), we can deduce the behavior of the optimal primal $y^*$ based on the threshold $t$:
            <ul>
                <li><b>Case A ($x_i > t$):</b> Then $u_i - v_i > 0 \implies u_i > 0 \implies y_i = 1$. (Must select).</li>
                <li><b>Case B ($x_i < t$):</b> Then $u_i - v_i < 0 \implies v_i > 0 \implies y_i = 0$. (Must reject).</li>
                <li><b>Case C ($x_i = t$):</b> Then $u_i = v_i$. We can have $y_i \in [0, 1]$.</li>
            </ul>
            <p>Thus, $t^*$ acts as a <b>cutoff value</b>. We select all elements strictly above $t^*$ and fill the remainder of our budget $r$ from the elements equal to $t^*$.</p>
            <p><b>Connection to Hinge Loss:</b> Minimizing over $u$ explicitly gives $u_i = \max(0, x_i - t)$. The dual problem reduces to a 1D convex minimization:
            $$ f(x) = \min_{t \in \mathbb{R}} \left( rt + \sum_{i=1}^n \max(0, x_i - t) \right) $$
            This formula is widely used in risk management (CVaR) and regression (SVR), avoiding the need for sorting in the optimization loop.</p>
          </div>
        </div>
        </div>

        <div class="problem">
        <h3>Problem 9: Markowitz Portfolio with Diversification (Problem 5.19 Continued)</h3>
        <p><strong>Context:</strong> Modern Portfolio Theory often yields solutions that are too concentrated in a few assets.
        <br><strong>Goal:</strong> Add a diversification constraint: "No more than 80% of the total budget can be invested in the top 10% of assets."
        <br><strong>Setup:</strong> Variables $x \in \mathbb{R}^n$, $\Sigma \succeq 0$, return vector $\bar{p}$.</p>

        <div class="solution-box">
          <h4>Solution</h4>
          <div class="proof-step">
            <strong>Step 1: The Constraint.</strong>
            Let $r = \lfloor 0.1 n \rfloor$. The "top 10% mass" is exactly $f(x) = \sum_{i=1}^r x_{[i]}$.
            The constraint is $f(x) \le 0.8$.
            <br><i>Sanity Check:</i> Is this feasible? If we invest uniformly ($x_i = 1/n$), the top $r$ sum is $r/n \approx 0.1$, which is well below $0.8$. So the feasible set is non-empty.
          </div>

          <div class="proof-step">
            <strong>Step 2: Substitution.</strong>
            We cannot plug $f(x)$ directly into a standard QP solver because of the sorting.
            Instead, we introduce auxiliary variables $t \in \mathbb{R}$ and $u \in \mathbb{R}^n$ and use the compact linear form derived in Problem 8.
          </div>

          <div class="proof-step">
            <strong>Step 3: The Full QP.</strong>
            $$
            \begin{aligned}
            \text{minimize}_{x, u, t} \quad & x^\top \Sigma x \\
            \text{subject to} \quad & \bar{p}^\top x \ge r_{\min} \quad (\text{Target Return}) \\
            & \mathbf{1}^\top x = 1, \quad x \ge 0 \quad (\text{Budget}) \\
            & rt + \mathbf{1}^\top u \le 0.8 \quad (\text{Diversification}) \\
            & t + u_i \ge x_i \quad \forall i \\
            & u_i \ge 0 \quad \forall i
            \end{aligned}
            $$
          </div>

          <div class="proof-step">
            <strong>Step 4: Convexity & Solvability.</strong>
            <ul>
                <li><b>Objective:</b> Convex quadratic (since $\Sigma \succeq 0$).</li>
                <li><b>Constraints:</b> All linear inequalities and equalities.</li>
            </ul>
            This is a standard convex QP. We successfully modeled a complex order-statistic constraint using duality!
            <br><b>Solver Note:</b> In a standard solver (like OSQP or SCS), the state vector is $z = [x, u, t]^\top$. The $P$ matrix will have $\Sigma$ in the top-left block and zeros elsewhere.
          </div>
        </div>
        </div>

        <div class="problem">
        <h3>Problem 10: Simplex Projection</h3>
        <p><b>Primal:</b> $\min \frac{1}{2}\|x-z\|_2^2$ s.t. $\mathbf{1}^\top x = 1, x \ge 0$.</p>
        <p><b>KKT Approach (No explicit dual needed for solution):</b>
        <br>Stationarity: $x - z - \lambda + \nu \mathbf{1} = 0 \implies x = z + \lambda - \nu \mathbf{1}$.
        <br>Complementary Slackness: $\lambda \ge 0, x \ge 0, \lambda_i x_i = 0$.
        <br>If $x_i > 0$, $\lambda_i=0 \implies x_i = z_i - \nu$.
        <br>If $x_i = 0$, $\lambda_i = \nu - z_i \ge 0 \implies z_i \le \nu$.
        <br>Unified: $x_i = \max(0, z_i - \nu)$.
        <br><b>Algorithm:</b> Find $\nu$ such that $\sum \max(0, z_i - \nu) = 1$ via sorting.
        </p>
        </div>

        <div class="problem">
        <h3>Problem 11: Logistic Regression</h3>
        <p><b>Primal:</b> $\min \sum \log(1 + e^{x_i^\top w}) - y_i x_i^\top w + \frac{\lambda}{2}\|w\|^2$.</p>
        <p><b>Dual:</b> Uses the conjugate of the logistic loss (binary entropy).
        <br>The dual involves maximizing entropy subject to correlation constraints with data.
        <br>This duality is the basis for Maximum Entropy models.
        </p>
        </div>
      </section>

      <section class="section-card" id="section-exercises">
      <h2><i data-feather="edit-3"></i> 11. Exercises</h2>

      <div class="insight">
        <h4>Recap & Key Concepts</h4>
        <p>These exercises consolidate your understanding of Lagrangian duality. We move from deriving duals of standard problems (QP, LP) to applying KKT conditions for analytic solutions (Water-filling), and finally using Strong Duality to prove fundamental theorems like Farkas' Lemma.</p>
      </div>

      <div class="proof-box">
        <h4>Appendix: Gap Certificate Cookbook</h4>
        <p>How to construct primal-dual certificates for common problems. In each case, $\text{gap} = p(x) - d(\text{dual vars})$.</p>

        <h5>1. Least Squares: $\min \frac{1}{2}\|Ax - b\|_2^2$</h5>
        <ul>
          <li><b>Primal:</b> Any $\mathbf{x}$.</li>
          <li><b>Dual:</b> Any $\mathbf{y}$ such that $A^\top \mathbf{y} = 0$ (orthogonal to range).</li>
          <li><b>Dual Objective:</b> $b^\top y - \frac{1}{2}\|y\|_2^2$.</li>
          <li><b>Gap:</b> $\frac{1}{2}\|Ax - b\|_2^2 - (b^\top y - \frac{1}{2}\|y\|_2^2)$.</li>
          <li><b>Recipe:</b> Let $\mathbf{r} = \mathbf{b} - A\mathbf{x}$. Project $\mathbf{r}$ onto $\mathcal{N}(A^\top)$ to get $\mathbf{y}$.</li>
        </ul>

        <h5>2. LASSO: $\min \frac{1}{2}\|Ax - b\|_2^2 + \lambda \|x\|_1$</h5>
        <ul>
          <li><b>Dual Feasibility:</b> $\|A^\top y\|_\infty \le \lambda$.</li>
          <li><b>Dual Objective:</b> $b^\top y - \frac{1}{2}\|y\|_2^2$.</li>
          <li><b>Recipe:</b> Let $r = b - Ax$. Scale $r$ to be feasible: $y = \min(1, \lambda / \|A^\top r\|_\infty) r$.</li>
        </ul>

        <h5>3. SVM: $\min \frac{1}{2}\|w\|_2^2 + C \sum \xi_i$</h5>
        <ul>
          <li><b>Dual Variable:</b> $0 \le \alpha \le C \mathbf{1}, \alpha^\top y_{labels} = 0$.</li>
          <li><b>Gap:</b> Standard primal-dual gap from SMO algorithm.</li>
        </ul>
      </div>

        <div class="problem">
  <h3>P9.1 — Deriving the Dual of a Quadratic Program</h3>
  <p>Consider the QP: $\min x^\top x$ subject to $Ax \preceq b$.
  <br>(a) Derive the Lagrange dual function $g(\lambda)$.
  <br>(b) State the dual problem explicitly.
  <br>(c) Verify weak duality directly for any feasible $\mathbf{x}$ and $\lambda$.</p>

  <div class="recap-box">
    <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
    <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
        <li><b>Algebraic Completion:</b> The derivation of the QP dual ($x^\top x \to \lambda^\top A A^\top \lambda$) is essentially completing the square in the Lagrangian.</li>
        <li><b>Geometric Insight:</b> The term $A A^\top$ in the dual objective reflects the geometry of the constraint boundaries. If $A A^\top$ is ill-conditioned, the dual is hard to solve.</li>
    </ul>
        </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      <strong>(a) Dual Function:</strong>
      $L(x, \lambda) = x^\top x + \lambda^\top (Ax - b)$.
      $\nabla_x L = 2x + A^\top \lambda = 0 \implies x^* = -1/2 A^\top \lambda$.
      $g(\lambda) = (-1/2 A^\top \lambda)^\top (-1/2 A^\top \lambda) + \lambda^\top (A(-1/2 A^\top \lambda) - b)$
      $= 1/4 \lambda^\top A A^\top \lambda - 1/2 \lambda^\top A A^\top \lambda - b^\top \lambda$
      $= -1/4 \lambda^\top (A A^\top) \lambda - b^\top \lambda$.
    </div>
    <div class="proof-step">
      <strong>(b) Dual Problem:</strong>
      $\max -1/4 \lambda^\top (A A^\top) \lambda - b^\top \lambda$ subject to $\lambda \ge 0$.
    </div>
    <div class="proof-step">
      <strong>(c) Weak Duality:</strong>
      $x^\top x - (-1/4 \lambda^\top A A^\top \lambda - b^\top \lambda) = \|x + 1/2 A^\top \lambda\|^2 - \lambda^\top(Ax - b)$.
      Since $\lambda \ge 0$ and $Ax - b \le 0$, the term $-\lambda^\top(Ax-b) \ge 0$. The norm is $\ge 0$. Sum $\ge 0$.
    </div>
  </div>
</div>

<div class="problem">
  <h3>P9.17 — Quadratic inequality via duality (Problem 5.4)</h3>
  <p>Consider the quadratic inequality
  $$
  x^T Q x + 2 b^T x + c \le 0
  $$
  over all $x \in \mathbb R^n$.
  <br><b>(a)</b> Derive a condition under which the inequality holds for all $x$ satisfying
  $$ w^T x = \beta. $$
  <b>(b)</b> Express this condition as a linear matrix inequality (LMI).
  <br><b>(c)</b> Interpret the result geometrically and via the Lagrange dual.</p>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      <strong>Part (a): Deriving the Condition (The S-Procedure).</strong>
      We are checking if the quadratic $f(x) = x^T Q x + 2b^T x + c$ is non-positive on the hyperplane $\mathcal{H} = \{x \mid w^T x - \beta = 0\}$.
      <br>This is a theorem of alternatives (specifically, a variant of the S-Procedure for equality constraints). The condition holds if and only if there exists a multiplier $\lambda \in \mathbb{R}$ such that the "Lagrangian" is non-positive <b>everywhere</b> in $\mathbb{R}^n$:
      $$ x^T Q x + 2b^T x + c + 2\lambda (w^T x - \beta) \le 0, \quad \forall x \in \mathbb{R}^n $$
      <b>Why?</b>
      <ul>
        <li>($\Leftarrow$) If this global inequality holds, then for any $x \in \mathcal{H}$, the term $2\lambda(w^T x - \beta)$ vanishes, leaving $f(x) \le 0$.</li>
        <li>($\Rightarrow$) This direction is deeper. If $f(x) \le 0$ on the affine space, the curvature of $f$ restricted to that space must be non-positive (concave). We can add a linear term $2\lambda w^T x$ to "tilt" the function without changing its curvature so that its unconstrained global maximum is $\le 0$.</li>
      </ul>
    </div>
    <div class="proof-step">
      <strong>Part (b): The Linear Matrix Inequality (LMI).</strong>
      We regroup the terms in the global inequality to form a single quadratic form in $x$.
      $$
      \begin{aligned}
      \text{LHS} &= x^T Q x + 2b^T x + c + 2\lambda w^T x - 2\lambda \beta \\
      &= x^T Q x + 2(b + \lambda w)^T x + (c - 2\lambda \beta)
      \end{aligned}
      $$
      A quadratic form $x^T A x + 2q^T x + r \le 0$ holds for all $x$ if and only if the "homogenized" matrix is negative semidefinite (NSD):
      $$
      \begin{bmatrix} Q & b + \lambda w \\ (b + \lambda w)^T & c - 2\lambda \beta \end{bmatrix} \preceq 0
      $$
      This constraint is linear in the unknown variable $\lambda$. Thus, the condition is the existence of $\lambda$ satisfying this LMI.
    </div>
    <div class="proof-step">
      <strong>Part (c): Geometric and Dual Interpretation.</strong>
      <ul>
        <li><b>Geometric:</b> The region $\mathcal{R} = \{x \mid f(x) \le 0\}$ is a quadratic sublevel set (e.g., the exterior of an ellipsoid or a half-space defined by a hyperboloid). The problem asks if the hyperplane $\mathcal{H}$ is a subset of $\mathcal{R}$ ($\mathcal{H} \subseteq \mathcal{R}$). The LMI condition essentially checks if the quadratic defining the set "dominates" the quadratic defining the hyperplane (conceptually), wrapping around it.</li>
        <li><b>Lagrange Dual:</b> Consider the maximization problem:
        $$ p^* = \max_{x} \{ f(x) \mid w^T x = \beta \} $$
        We want to verify $p^* \le 0$.
        <br>The dual function $g(\lambda)$ provides an upper bound on $p^*$.
        $$ g(\lambda) = \sup_x ( f(x) + 2\lambda(w^T x - \beta) ) $$
        For this supremum to be finite, the quadratic in $x$ must be bounded above (NSD). If it is NSD, the supremum is finite.
        <br>The LMI states exactly that the matrix representing this Lagrangian is NSD, ensuring the dual function is well-defined and non-positive. Thus, duality transforms a "local" check on a subspace into a "global" spectral check on a matrix.</li>
      </ul>
    </div>
  </div>
</div>

<div class="problem">
  <h3>P9.16 — Conjugate-based dual of least-squares (Problem 5.3)</h3>
  <p>Consider the least-squares problem
  $$
  \min_{x \in \mathbb R^n} \ \|Ax - b\|_2,
  $$
  where $A \in \mathbb R^{m\times n}$ and $b \in \mathbb R^m$.
  <br>Using the conjugate representation of the norm, derive the dual problem and show that the dual is
  $$
  \max_{\nu} \; - b^T \nu
  \quad \text{s.t.} \quad
  \| \nu \|_2 \le 1, \;
  A^T \nu = 0 .
  $$
  Show that strong duality holds.</p>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      <strong>Step 1: Strategic Reformulation.</strong>
      The problem involves a composition of a norm with an affine transformation. While we could analyze it directly, it is cleaner to "lift" the problem by introducing an explicit variable for the residual.
      <br>Let $y = Ax - b$. The problem becomes:
      $$ \min_{x \in \mathbb{R}^n, y \in \mathbb{R}^m} \|y\|_2 \quad \text{s.t.} \quad y = Ax - b $$
      This separates the "norm geometry" (in $y$) from the "linear subspace structure" (in $x$).
    </div>
    <div class="proof-step">
      <strong>Step 2: Constructing the Lagrangian.</strong>
      We assign a dual variable $\nu \in \mathbb{R}^m$ to the equality constraint $Ax - b - y = 0$. The Lagrangian is:
      $$
      \begin{aligned}
      L(x, y, \nu) &= \|y\|_2 + \nu^\top (Ax - b - y) \\
      &= \|y\|_2 - \nu^\top y + \nu^\top Ax - \nu^\top b \\
      &= (\|y\|_2 - \nu^\top y) + (A^\top \nu)^\top x - b^\top \nu
      \end{aligned}
      $$
      We have grouped terms by $y$ and $x$ to facilitate minimization.
    </div>
    <div class="proof-step">
      <strong>Step 3: Deriving the Dual Function.</strong>
      The dual function is $g(\nu) = \inf_{x, y} L(x, y, \nu)$. We minimize over $x$ and $y$ separately.
      <ul>
        <li><b>Minimizing over $x$:</b> The term $(A^\top \nu)^\top x$ is a linear function of $x$. Its infimum is $-\infty$ unless the gradient is zero.
        $$ \inf_x (A^\top \nu)^\top x = \begin{cases} 0 & \text{if } A^\top \nu = 0 \\ -\infty & \text{otherwise} \end{cases} $$
        This generates the constraint $A^\top \nu = 0$ (orthogonality to the range of $A$).
        </li>
        <li><b>Minimizing over $y$:</b> We need to evaluate $\inf_y (\|y\|_2 - \nu^\top y)$. This looks like the definition of the convex conjugate.
        $$ \inf_y (\|y\|_2 - \nu^\top y) = - \sup_y (\nu^\top y - \|y\|_2) = - f^*(\nu) $$
        where $f(y) = \|y\|_2$.
        <br><b>Recall:</b> The conjugate of a norm $f(y) = \|y\|$ is the indicator function of the dual norm unit ball.
        $$ f^*(\nu) = \begin{cases} 0 & \|\nu\|_* \le 1 \\ \infty & \text{otherwise} \end{cases} $$
        For the $\ell_2$ norm, the dual is also the $\ell_2$ norm ($\|\nu\|_* = \|\nu\|_2$).
        <br>Thus, the term is $0$ if $\|\nu\|_2 \le 1$ and $-\infty$ otherwise.
        </li>
      </ul>
    </div>
    <div class="proof-step">
      <strong>Step 4: The Dual Problem.</strong>
      Collecting the pieces, the dual function is finite only when $A^\top \nu = 0$ and $\|\nu\|_2 \le 1$. In that case, $g(\nu) = -b^\top \nu$.
      $$
      \begin{aligned}
      \text{maximize} \quad & -b^\top \nu \\
      \text{subject to} \quad & A^\top \nu = 0 \\
      & \|\nu\|_2 \le 1
      \end{aligned}
      $$
    </div>
    <div class="proof-step">
      <strong>Step 5: Strong Duality.</strong>
      Does $p^\star = d^\star$? We check Slater's condition.
      <br>The reformulated problem $\min \|y\|_2$ s.t. $y - Ax + b = 0$ is a convex optimization problem with:
      <ul>
        <li>Convex objective (norm).</li>
        <li>Linear equality constraints.</li>
        <li>No inequality constraints.</li>
      </ul>
      For problems with only linear equality constraints, Slater's condition is reduced to simple feasibility. Since for any $x$, we can find $y = Ax - b$, the problem is feasible.
      <br>Thus, <b>Strong Duality holds</b>.
    </div>
  </div>
</div>
        <div class="problem">
  <h3>P9.2 — KKT Conditions for Entropy Maximization</h3>
  <p>Maximize the entropy $-\sum x_i \log x_i$ subject to $\mathbf{1}^\top x = 1$ and $Ax \le b$.
  <br>Derive the KKT conditions. Show that the optimal solution has the form $x_i = e^{-\nu - 1 - (A^\top \lambda)_i}$.</p>

  <div class="recap-box">
    <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
    <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
        <li><b>Exponential Families:</b> The solution form $x_i \propto e^{-(A^\top \lambda)_i}$ shows that linear constraints on the probability mass function lead to exponential family distributions.</li>
        <li><b>Partition Function:</b> The Lagrange multiplier $\nu$ associated with normalization ($\sum x_i = 1$) becomes the log-partition function (normalizing constant) in the solution.</li>
    </ul>
        </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      <strong>Step 1: Construct the Lagrangian.</strong>
      We first convert the maximization problem to minimization:
      $$ \min \sum_{i=1}^n x_i \log x_i \quad \text{s.t.} \quad \mathbf{1}^\top x = 1, \quad Ax \le b $$
      The Lagrangian is:
      $$ L(x, \lambda, \nu) = \sum_{i=1}^n x_i \log x_i + \nu(\sum x_i - 1) + \lambda^\top (Ax - b) $$
      Note: We use $\nu$ for the equality constraint and $\lambda \ge 0$ for the inequality.
    </div>
    <div class="proof-step">
      <strong>Step 2: Stationarity Condition.</strong>
      The gradient with respect to $x_i$ must be zero at the optimum:
      $$ \frac{\partial L}{\partial x_i} = (1 + \log x_i) + \nu + (A^\top \lambda)_i = 0 $$
    </div>
    <div class="proof-step">
      <strong>Step 3: Solve for Primal Variables.</strong>
      Rearranging the stationarity equation:
      $$ \log x_i = -1 - \nu - (A^\top \lambda)_i $$
      $$ x_i^* = \exp\left( -1 - \nu - (A^\top \lambda)_i \right) $$
      This shows that the optimal distribution lies in an exponential family parameterized by the dual variables.
    </div>
    <div class="proof-step">
      <strong>Step 4: Other KKT Conditions.</strong>
      <ul>
        <li><b>Primal Feasibility:</b> $\sum x_i^* = 1$ (used to solve for $\nu$), $Ax^* \le b$.</li>
        <li><b>Dual Feasibility:</b> $\lambda \ge 0$.</li>
        <li><b>Complementary Slackness:</b> $\lambda_j (A_j^\top x^* - b_j) = 0$.</li>
      </ul>
    </div>
  </div>
</div>

        <div class="problem">
  <h3>P9.3 — Sensitivity Analysis and Shadow Prices</h3>
  <p>Consider $\min x^2$ s.t. $x \le -1$. Optimal $x^*=-1, p^*=1$.
  <br>Perturb to $\mathbf{x} \le -1 + u$. New optimum $\mathbf{x}^* = -1+u$ (for small $u$), $p^*(u) = (-1+u)^2 \approx 1 - 2u$.
  <br>Find the dual optimal $\lambda^*$ of the original problem and verify $p^*(u) \approx p^*(0) - \lambda^* u$.</p>

  <div class="recap-box">
    <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
    <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
        <li><b>Shadow Prices:</b> $\lambda^*$ quantifies the "marginal cost" of the constraint. If $\lambda^* = 2$, relaxing the bound by $\epsilon$ saves $2\epsilon$.</li>
        <li><b>Local vs Global:</b> For convex problems, $p^*(u) \ge p^*(0) - \lambda^* u$ is a global lower bound, offering a guarantee on the best possible improvement.</li>
    </ul>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      <strong>Step 1: Compute Dual Optimal.</strong>
      Original problem: $\min x^2$ s.t. $x \le -1$.
      Lagrangian: $L(x, \lambda) = x^2 + \lambda(x+1)$.
      Minimize over $x$: $\nabla_x L = 2x + \lambda = 0 \implies x^* = -\lambda/2$.
      Dual function: $g(\lambda) = (-\lambda/2)^2 + \lambda(-\lambda/2 + 1) = \frac{\lambda^2}{4} - \frac{\lambda^2}{2} + \lambda = -\frac{\lambda^2}{4} + \lambda$.
      Maximize $g(\lambda)$ for $\lambda \ge 0$: $g'(\lambda) = -\frac{\lambda}{2} + 1 = 0 \implies \lambda^* = 2$.
    </div>
    <div class="proof-step">
      <strong>Step 2: Predict Perturbed Value.</strong>
      The sensitivity theorem states $p^*(u) \ge p^*(0) - \lambda^* u$.
      For convex problems with strong duality, this is a first-order approximation:
      $$ p^*(u) \approx p^*(0) - \lambda^* u = 1 - 2u $$
    </div>
    <div class="proof-step">
      <strong>Step 3: Verify with Direct Calculation.</strong>
      Perturbed problem: $\min x^2$ s.t. $x \le -1 + u$.
      For small $u$, the constraint is active: $x^*(u) = -1 + u$.
      Optimal value: $p^*(u) = (-1+u)^2 = 1 - 2u + u^2$.
      Linear approximation: $p^*(u) \approx 1 - 2u$.
      This matches the prediction using $\lambda^* = 2$. The Lagrange multiplier is exactly the rate of change of the optimal value.
    </div>
  </div>
        </div>
        <div class="problem">
  <h3>P9.4 — Dual of a Linear Program</h3>
  <p>Derive the dual of the standard form LP:
  $$ \min c^\top x \quad \text{s.t.} \quad Ax = b, \ x \ge 0 $$
  Show it is $\max -b^\top \nu$ s.t. $A^\top \nu + c \ge 0$ (or equivalently $\max b^\top y$ s.t. $A^\top y \le c$ via reparameterization).</p>

  <div class="recap-box">
    <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
    <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
        <li><b>Symmetry:</b> The dual of the dual is the primal. For standard LP ($\min c^\top x, Ax=b, x \ge 0$), the dual is ($\max b^\top y, A^\top y \le c$).</li>
        <li><b>Economic Interpretation:</b> If primal variables are production quantities, dual variables are prices of resources ($Ax=b$). The dual constraint $A^\top y \le c$ means "value of resources consumed $\le$ cost/profit".</li>
    </ul>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      <strong>Step 1: Lagrangian.</strong>
      The constraints are $Ax - b = 0$ and $-x \le 0$.
      $L(x, \lambda, \nu) = c^\top x - \lambda^\top x + \nu^\top (Ax - b) = -b^\top \nu + (c - \lambda + A^\top \nu)^\top x$.
    </div>
    <div class="proof-step">
      <strong>Step 2: Dual Function.</strong>
      $g(\lambda, \nu) = \inf_x L(x, \lambda, \nu)$.
      If the coefficient of $x$ is not zero, the infimum is $-\infty$.
      Thus $g(\lambda, \nu) = -b^\top \nu$ if $c - \lambda + A^\top \nu = 0$, else $-\infty$.
    </div>
    <div class="proof-step">
      <strong>Step 3: Dual Problem.</strong>
      Maximize $-b^\top \nu$ subject to $\lambda \ge 0$ and $c - \lambda + A^\top \nu = 0$.
      Eliminate $\lambda$: $\lambda = c + A^\top \nu$. The condition $\lambda \ge 0$ becomes $c + A^\top \nu \ge 0$, or $A^\top (-\nu) \le c$.
      Let $y = -\nu$. Then we maximize $b^\top y$ subject to $A^\top y \le c$.
        </div>
  </div>
</div>

        <div class="problem">
  <h3>P9.5 — Farkas' Lemma</h3>
  <p>Use Strong Duality for LP to prove Farkas' Lemma:
  Exactly one of the following systems has a solution:
  <ol>
    <li>$Ax = b, \ x \ge 0$</li>
    <li>$A^\top y \ge 0, \ b^\top y < 0$</li>
  </ol>
  </p>

  <div class="recap-box">
    <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
    <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
        <li><b>Theorems of Alternatives:</b> Farkas' Lemma is the linear instance of a broad class of theorems (Gordan, Stiemke) relating feasibility of one system to infeasibility of another.</li>
        <li><b>Duality Proof:</b> The proof relies on Strong Duality: if the primal is infeasible ($p^*=\infty$), the dual must be unbounded ($d^*=\infty$), implying the existence of an improving direction (the certificate).</li>
    </ul>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      Consider the LP: $p^* = \min \{ 0^\top x \mid Ax = b, x \ge 0 \}$.
      If (1) is feasible, $p^* = 0$. If infeasible, $p^* = \infty$.
    </div>
    <div class="proof-step">
      The dual of the LP $\min \{ 0^\top x \mid Ax = b, x \ge 0 \}$ is:
      $$ d^* = \max \{ -b^\top \nu \mid A^\top \nu \ge 0 \} $$
      (Using the standard derivation where equality constraints $Ax=b$ have dual variables $\nu$).
      Alternatively, writing the dual in terms of $y = -\nu$, we maximize $b^\top y$ subject to $A^\top y \le 0$.
    </div>
    <div class="proof-step">
      <strong>Case 1: (1) has a solution (Feasible).</strong>
      If there exists $x \ge 0$ such that $Ax=b$, the primal optimal value is $p^* = 0$.
      <br>By Weak Duality, for any dual feasible $y$ (where $A^\top y \le 0$), we have $b^\top y \le p^* = 0$.
      <br>Thus $A^\top y \le 0 \implies b^\top y \le 0$.
      <br>Let $z = -y$. Then $A^\top (-z) \le 0 \implies A^\top z \ge 0$, and $b^\top (-z) \le 0 \implies b^\top z \ge 0$.
      <br>System (2) requires $A^\top z \ge 0$ and $b^\top z < 0$. But we showed $b^\top z \ge 0$.
      <br>Thus, system (2) has <b>no solution</b>.
    </div>
    <div class="proof-step">
      <strong>Case 2: (1) has no solution (Infeasible).</strong>
      If the primal is infeasible, then $p^* = +\infty$ (by convention for minimization).
      <br>By Strong Duality for LPs, $d^* = p^* = +\infty$.
      <br>This means the dual problem $\max \{ b^\top y \mid A^\top y \le 0 \}$ is unbounded above.
      <br>For the objective $b^\top y$ to grow arbitrarily large while $y$ remains in the cone $A^\top y \le 0$, there must exist a direction $y$ such that $A^\top y \le 0$ and $b^\top y > 0$ (otherwise the max would be 0).
      <br>Let $z = -y$. Then $A^\top (-z) \le 0 \implies A^\top z \ge 0$ and $b^\top (-z) > 0 \implies b^\top z < 0$.
      <br>This $z$ is a solution to system (2). Thus, system (2) <b>has a solution</b>.
    </div>
        </div>
</div>

        <div class="problem">
  <h3>P9.6 — KKT for Water-filling</h3>
  <p>Solve $\min \sum_{i=1}^n -\log(\alpha_i + x_i)$ subject to $x \ge 0, \mathbf{1}^\top x = 1$. Assume $\alpha_i > 0$. Derive the water-filling solution.</p>

  <div class="recap-box">
    <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
    <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
        <li><b>Marginal Utility:</b> Optimality requires equalizing marginal utility ($1/(\alpha_i+x_i)$) across all active allocations.</li>
        <li><b>Active Set:</b> The "water level" $\nu$ determines which channels are active. Channels with high noise ($\alpha_i > 1/\nu$) receive zero power.</li>
    </ul>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      <strong>Lagrangian:</strong> $L(x, \lambda, \nu) = -\sum \log(\alpha_i + x_i) - \lambda^\top x + \nu(\sum x_i - 1)$.
    </div>
    <div class="proof-step">
      <strong>Stationarity:</strong> $\frac{-1}{\alpha_i + x_i} - \lambda_i + \nu = 0 \implies \alpha_i + x_i = \frac{1}{\nu - \lambda_i}$.
        </div>
    <div class="proof-step">
      <strong>Complementary Slackness:</strong> $\lambda_i x_i = 0, \lambda_i \ge 0, x_i \ge 0$.
      <ul>
        <li>Case 1: $x_i > 0$. Then $\lambda_i = 0$. The stationarity condition becomes $\frac{1}{\alpha_i + x_i} = \nu \implies \alpha_i + x_i = \frac{1}{\nu}$. Thus $x_i = \frac{1}{\nu} - \alpha_i$. (Note: for $x_i > 0$, we need $1/\nu > \alpha_i$).</li>
        <li>Case 2: $x_i = 0$. The stationarity condition is $\frac{1}{\alpha_i} = \nu - \lambda_i$. Since $\lambda_i \ge 0$, we have $\nu - \lambda_i \le \nu$.
        Assuming $\nu > 0$ and $\nu - \lambda_i > 0$, taking reciprocals reverses the inequality:
        $$ \frac{1}{\nu - \lambda_i} \ge \frac{1}{\nu} $$
        Substituting back: $\alpha_i \ge \frac{1}{\nu}$.
        </li>
      </ul>
    </div>
    <div class="proof-step">
      <strong>Combined Solution:</strong>
      Combining the cases:
      $$ x_i = \max\left(0, \frac{1}{\nu} - \alpha_i\right) $$
      Here $\mu = 1/\nu$ acts as the "water level". We choose the water level such that the total amount of water poured equals the budget: $\sum x_i = 1$.
    </div>
  </div>
</div>

        <div class="problem">
  <h3>P9.7 — KKT for Standard QP</h3>
  <p>Consider the Quadratic Program:</p>
  $$ \min_x \frac{1}{2} x^\top P x + q^\top x \quad \text{s.t.} \quad Ax \le b $$
  <p>where $P \in \mathbb{S}^n_{++}$ (positive definite).</p>
  <p><strong>(a)</strong> Write down the KKT conditions for this problem.</p>
  <p><strong>(b)</strong> Combine them to show that solving the KKT system is equivalent to solving a system of equations involving the active set.</p>

  <div class="recap-box">
    <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
    <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
        <li><b>Linear KKT Systems:</b> For QPs, the stationarity condition is linear in $x$ and $\lambda$. If we knew which constraints were active (the "active set"), the KKT conditions would reduce to a single system of linear equations.</li>
        <li><b>Active Set Methods:</b> Many QP solvers work by iteratively guessing the active set and solving the resulting linear system.</li>
    </ul>
        </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      <strong>Part (a): KKT Conditions.</strong>
      <ol>
        <li><b>Primal Feasibility:</b> $Ax \le b$.</li>
        <li><b>Dual Feasibility:</b> $\lambda \ge 0$.</li>
        <li><b>Complementary Slackness:</b> $\lambda_i (a_i^\top x - b_i) = 0$ for all $i$.</li>
        <li><b>Stationarity:</b> $\nabla f_0(x) + \sum \lambda_i \nabla f_i(x) = 0 \implies Px + q + A^\top \lambda = 0$.</li>
      </ol>
    </div>
    <div class="proof-step">
      <strong>Part (b): Active Set Interpretation.</strong>
      Let $I \subseteq \{1, \dots, m\}$ be the set of indices where $a_i^\top x = b_i$ (active constraints).
      Complementary slackness implies $\lambda_i = 0$ for $i \notin I$.
      The stationarity equation becomes:
      $$ Px + q + \sum_{i \in I} \lambda_i a_i = 0 $$
      Combined with $a_i^\top x = b_i$ for $i \in I$, we have a square linear system (assuming $|I| \le n$ and independence):
      $$
      \begin{bmatrix} P & A_I^\top \\ A_I & 0 \end{bmatrix} \begin{bmatrix} x \\ \lambda_I \end{bmatrix} = \begin{bmatrix} -q \\ b_I \end{bmatrix}
      $$
    </div>
  </div>
</div>

        <div class="problem">
  <h3>P9.8 — Certificates of Infeasibility (Gordan's Theorem)</h3>
  <p>A system of inequalities is <b>infeasible</b> if no solution exists. A <b>certificate of infeasibility</b> is a dual vector that proves this fact.
  <br><strong>Gordan's Theorem</strong> states that exactly one of the following systems has a solution:</p>
  <ol>
    <li>$Ax < 0$ (Strict homogeneous inequalities)</li>
    <li>$A^\top y = 0, y \ge 0, y \ne 0$ (Dual certificate)</li>
  </ol>
  <p>Prove this using the separation of convex sets.</p>

  <div class="recap-box">
    <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
    <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
        <li><b>Theorems of Alternatives:</b> Gordan's Theorem is another variant of Farkas' Lemma. It deals with strict inequalities.</li>
        <li><b>Separation Argument:</b> If the set $K = \{Ax \mid x \in \mathbb{R}^n\}$ (a subspace) does not intersect the open negative orthant $\mathbb{R}^m_{--}$, we can separate them with a hyperplane. This hyperplane normal gives the certificate $y$.</li>
    </ul>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      <strong>Step 1: Set definitions.</strong>
      Let $S = \{Ax \mid x \in \mathbb{R}^n\}$ be the range space of $A$. This is a convex set (a subspace).
      Let $C = \{z \in \mathbb{R}^m \mid z < 0\}$ be the open negative orthant. This is a convex cone.
    </div>
    <div class="proof-step">
      <strong>Step 2: Mutual Exclusivity.</strong>
      System (1) has a solution iff $S \cap C \ne \emptyset$.
      Suppose both have solutions. There exists $x$ such that $Ax < 0$, and $y \ge 0, y \ne 0$ such that $A^\top y = 0$.
      Consider the inner product $y^\top (Ax)$.
      On one hand, $y^\top A x = (A^\top y)^\top x = 0^\top x = 0$.
      On the other hand, $y \ge 0, y \ne 0$ and $Ax < 0$ (strictly negative components). The dot product of a non-negative non-zero vector and a strictly negative vector must be strictly negative.
      $y^\top (Ax) < 0$.
      Contradiction ($0 < 0$). Thus, both cannot be true.
    </div>
    <div class="proof-step">
      <strong>Step 3: Covering all cases (Separating Hyperplane).</strong>
      If (1) has no solution, then $S \cap C = \emptyset$.
      Since $C$ is open and convex and $S$ is convex, there exists a separating hyperplane defined by normal $y \ne 0$ such that:
      $y^\top z \le y^\top w$ for all $z \in C, w \in S$.
      Since $S$ is a subspace, $y^\top w$ must be bounded below, which implies $y^\top w = 0$ for all $w \in S$ (otherwise it goes to $-\infty$). Thus $y \perp \text{range}(A) \implies A^\top y = 0$.
      The condition becomes $y^\top z \le 0$ for all $z < 0$. This implies $y \ge 0$.
      Thus we found $y \ge 0, y \ne 0$ with $A^\top y = 0$. This is a solution to (2).
        </div>
  </div>
</div>



        <div class="problem">
  <h3>P9.9 — The Gap Certificate Cookbook</h3>
  <p>For each of the following problems, determine the dual variables, the dual objective function $d(\lambda, \nu)$, and the formula for the duality gap $\text{gap} = p(x) - d(\lambda, \nu)$.</p>
  <ol>
    <li><b>Least Squares:</b> $\min_x \frac{1}{2}\|Ax-b\|_2^2$ (Use the equivalent constrained form $\min \frac{1}{2}\|y\|_2^2$ s.t. $y=Ax-b$)</li>
    <li><b>Ridge Regression:</b> $\min_x \frac{1}{2}\|Ax-b\|_2^2 + \frac{\lambda}{2}\|x\|_2^2$</li>
    <li><b>LASSO:</b> $\min_x \frac{1}{2}\|Ax-b\|_2^2 + \rho \|x\|_1$</li>
    <li><b>Basis Pursuit:</b> $\min_x \|x\|_1$ s.t. $Ax=b$</li>
  </ol>
  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      <strong>1. Least Squares:</strong>
      Primal: $\min_x \frac{1}{2}\|Ax-b\|^2$. No explicit dual usually, but using $y=Ax-b$:
      Dual Feasibility: $A^\top \nu = 0$.
      Dual Objective: $d(\nu) = -\frac{1}{2}\|\nu\|^2 - \nu^\top b$.
      Gap: $\frac{1}{2}\|Ax-b\|^2 + \frac{1}{2}\|\nu\|^2 + \nu^\top b$.
        </div>
    <div class="proof-step">
      <strong>2. Ridge Regression:</strong>
      Primal: $\min \frac{1}{2}\|Ax-b\|^2 + \frac{\lambda}{2}\|x\|^2$.
      Dual Variable: $y$ (unconstrained).
      Dual Objective: $d(y) = -\frac{1}{2}\|y\|^2 - y^\top b - \frac{1}{2\lambda}\|A^\top y\|^2$.
      Gap: $\frac{1}{2}\|Ax-b\|^2 + \frac{\lambda}{2}\|x\|^2 + \frac{1}{2}\|y\|^2 + y^\top b + \frac{1}{2\lambda}\|A^\top y\|^2$.
    </div>
    <div class="proof-step">
      <strong>3. LASSO:</strong>
      Primal: $\min \frac{1}{2}\|Ax-b\|^2 + \rho\|x\|_1$.
      Dual Variable: $y$. Constraint: $\|A^\top y\|_\infty \le \rho$.
      Dual Objective: $d(y) = -\frac{1}{2}\|y\|^2 - y^\top b$.
      Gap: $\frac{1}{2}\|Ax-b\|^2 + \rho\|x\|_1 + \frac{1}{2}\|y\|^2 + y^\top b$.
    </div>
    <div class="proof-step">
      <strong>4. Basis Pursuit:</strong>
      Primal: $\min \|x\|_1$ s.t. $Ax=b$.
      Dual Variable: $y$. Constraint: $\|A^\top y\|_\infty \le 1$.
      Dual Objective: $d(y) = b^\top y$.
      Gap: $\|x\|_1 - b^\top y$.
    </div>
  </div>
</div>

        <div class="problem">
  <h3>P9.10 — SDP Duality: Max Cut Relaxation</h3>
  <p>The Max Cut problem can be relaxed to the following SDP:
  $$ \max_X \quad \frac{1}{4} \mathrm{tr}(W X) \quad \text{s.t.} \quad X_{ii} = 1, \quad X \succeq 0 $$
  where $W$ is the weighted adjacency matrix. Derive the dual problem.</p>
  <div class="recap-box">
    <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
    <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
        <li><b>Matrix Lagrange Multipliers:</b> For the constraint $X \succeq 0$, the multiplier is a matrix $Z \succeq 0$, and the term is $-\mathrm{tr}(ZX)$.</li>
        <li><b>Diagonal Constraints:</b> The constraints $X_{ii} = 1$ can be written as $\mathrm{diag}(X) = \mathbf{1}$. The multiplier is a vector $\nu$.</li>
    </ul>
        </div>
  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      <strong>Step 1: Lagrangian.</strong>
      We want to minimize the negative objective: $\min -\frac{1}{4}\mathrm{tr}(WX)$.
      Constraints: $X_{ii} = 1$ (multiplier $\nu_i$) and $X \succeq 0$ (multiplier $Z \succeq 0$).
      $$ L(X, \nu, Z) = -\frac{1}{4}\mathrm{tr}(WX) + \sum_{i=1}^n \nu_i (X_{ii} - 1) - \mathrm{tr}(ZX) $$
      Note: $\sum \nu_i X_{ii} = \mathrm{tr}(\mathrm{diag}(\nu) X)$.
      $$ L(X, \nu, Z) = \mathrm{tr}\left( \left( \mathrm{diag}(\nu) - \frac{1}{4}W - Z \right) X \right) - \sum \nu_i $$
    </div>
    <div class="proof-step">
      <strong>Step 2: Dual Function.</strong>
      Minimizing $L$ over $X$ (unconstrained symmetric matrix) requires the gradient to vanish.
      $$ \mathrm{diag}(\nu) - \frac{1}{4}W - Z = 0 $$
      If this holds, the minimum is $-\sum \nu_i$. Otherwise $-\infty$.
    </div>
    <div class="proof-step">
      <strong>Step 3: Dual Problem.</strong>
      Maximize $-\sum \nu_i$ subject to $Z \succeq 0$ and $Z = \mathrm{diag}(\nu) - \frac{1}{4}W$.
      Substituting $Z$: $\mathrm{diag}(\nu) - \frac{1}{4}W \succeq 0$.
      Equivalent Dual: $\min \sum \nu_i$ s.t. $\mathrm{diag}(\nu) \succeq \frac{1}{4}W$.
      (Usually written as $\min \mathbf{1}^\top \nu$ s.t. $4 \mathrm{diag}(\nu) \succeq W$).
    </div>
  </div>
</div>

        <div class="problem">
  <h3>P9.11 — SOCP Duality: Robust Least Squares</h3>
  <p>Derive the dual of the Robust Least Squares problem:
  $$ \min_x \|Ax - b\|_2 + \rho \|x\|_2 $$
  Formulate the primal as an SOCP first.</p>
  <div class="recap-box">
    <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
    <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
        <li><b>SOCP Standard Form:</b> $\min c^\top x$ s.t. $\|A_i x + b_i\|_2 \le c_i^\top x + d_i$.</li>
        <li><b>Conic Duality:</b> The dual variables for second-order cone constraints lie in the second-order cone (self-dual).</li>
    </ul>
  </div>
  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      <strong>Step 1: Primal SOCP.</strong>
      Introduce $t_1, t_2$. Minimize $t_1 + \rho t_2$ subject to:
      $$ \|Ax - b\|_2 \le t_1 \iff (b - Ax, t_1) \in \mathcal{Q}_{m+1} $$
      $$ \|x\|_2 \le t_2 \iff (x, t_2) \in \mathcal{Q}_{n+1} $$
      (Note: we use $b-Ax$ to align with standard form $Ax=b$, but inside the norm signs matter less).
    </div>
    <div class="proof-step">
      <strong>Step 2: Lagrangian.</strong>
      We associate dual variables $(z_1, \mu_1) \in \mathcal{Q}_{m+1}$ and $(z_2, \mu_2) \in \mathcal{Q}_{n+1}$.
      The Lagrangian term for a conic constraint $y \in K$ is $-s^\top y$ where $s \in K^*$. Here $K=K^*$.
      $$ L = t_1 + \rho t_2 - [z_1^\top(Ax - b) + \mu_1 t_1] - [z_2^\top x + \mu_2 t_2] $$
      Minimizing over $t_1 \implies 1 - \mu_1 = 0 \implies \mu_1 = 1$.
      Minimizing over $t_2 \implies \rho - \mu_2 = 0 \implies \mu_2 = \rho$.
      Minimizing over $x \implies -A^\top z_1 - z_2 = 0 \implies z_2 = -A^\top z_1$.
    </div>
    <div class="proof-step">
      <strong>Step 3: Dual Constraints.</strong>
      From conic feasibility of dual vars:
      $\|z_1\|_2 \le \mu_1 \implies \|z_1\|_2 \le 1$.
      $\|z_2\|_2 \le \mu_2 \implies \|z_2\|_2 \le \rho$.
      Substituting $z_2 = -A^\top z_1$, we get $\|A^\top z_1\|_2 \le \rho$.
    </div>
    <div class="proof-step">
      <strong>Step 4: Dual Problem.</strong>
      The remaining term in Lagrangian is $z_1^\top b$.
      $$ \max_{z_1} \quad b^\top z_1 \quad \text{s.t.} \quad \|z_1\|_2 \le 1, \quad \|A^\top z_1\|_2 \le \rho $$
      This is the dual of Robust Least Squares. It is a maximization of a linear function over the intersection of a ball and an ellipsoidal cylinder.
    </div>
  </div>
        </div>

        <div class="problem">
  <h3>P9.12 — Deep Dive: Chebyshev Approximation vs Least Squares (Problem 5.6)</h3>
  <p>Consider the problem of minimizing the $\ell_\infty$ norm of the residual: $p^\star = \min_x \|Ax - b\|_\infty$.
  <br>Let $x_{\text{ls}}$ be the least-squares solution ($p_{\text{ls}} = \min \|Ax-b\|_2$).
  <br><strong>(a)</strong> Prove that the least-squares solution provides a $\sqrt{m}$-approximation: $\|Ax_{\text{ls}} - b\|_\infty \le \sqrt{m} p^\star$.
  <br><strong>(b)</strong> Derive the dual problem and show how to construct a lower bound certificate using the least-squares residual.</p>

  <div class="solution-box">
    <h4>Solution</h4>

    <div class="proof-step">
      <strong>Part (a): The Primal Bound (Norm Chain).</strong>
      We want to prove $|Ax_{\rm ls} - b|_\infty \le \sqrt{m} p^\star$.
      Let $r_{\rm ls} = Ax_{\rm ls} - b$ and $r_{\rm ch} = Ax_{\rm ch} - b$.
      <br>The proof relies on the chain of inequalities relating $\ell_2$ and $\ell_\infty$ norms in $\mathbb{R}^m$:
      $$ \|z\|_\infty \le \|z\|_2 \le \sqrt{m} \|z\|_\infty $$
      <br>We chain these inequalities together:
      <ol>
        <li><b>Step 1:</b> $\|r_{\rm ls}\|_\infty \le \|r_{\rm ls}\|_2$ (Max entry $\le$ Euclidean length).</li>
        <li><b>Step 2:</b> $\|r_{\rm ls}\|_2 \le \|r_{\rm ch}\|_2$. This is the definition of Least Squares: $x_{\rm ls}$ minimizes the $\ell_2$ norm, so it must be better (or equal) than the Chebyshev solution $x_{\rm ch}$ in the $\ell_2$ sense.</li>
        <li><b>Step 3:</b> $\|r_{\rm ch}\|_2 \le \sqrt{m} \|r_{\rm ch}\|_\infty$. (Euclidean length $\le \sqrt{m}$ times max entry).</li>
      </ol>
      Combining them:
      $$ \|r_{\rm ls}\|_\infty \le \|r_{\rm ls}\|_2 \le \|r_{\rm ch}\|_2 \le \sqrt{m} \|r_{\rm ch}\|_\infty = \sqrt{m} p^\star $$
    </div>

    <div class="proof-step">
      <strong>Part (b): The Dual Lower Bound.</strong>
      The dual problem for Chebyshev approximation is:
      $$ \max_{\nu} \ b^T \nu \quad \text{s.t.} \quad A^T \nu = 0, \ \|\nu\|_1 \le 1 $$
      Any $\nu$ satisfying the constraints provides a lower bound $b^T \nu \le p^\star$.
    </div>

    <div class="proof-step">
      <strong>Step 1: Manufacturing a Dual Candidate.</strong>
      We want to construct a feasible $\nu$ from the LS residual $r_{\rm ls} = b - Ax_{\rm ls}$.
      <br><b>Constraint 1: Orthogonality ($A^T \nu = 0$).</b>
      The LS residual satisfies the Normal Equations: $A^T (b - Ax_{\rm ls}) = 0$, so $A^T r_{\rm ls} = 0$.
      Thus, $r_{\rm ls}$ already satisfies the orthogonality constraint! This is the "magic" of least squares.
      <br><b>Constraint 2: Norm ($|\nu|_1 \le 1$).</b>
      The vector $r_{\rm ls}$ might be too large. We simply scale it:
      $$ \hat{\nu} = \frac{r_{\rm ls}}{\|r_{\rm ls}\|_1} $$
      This vector $\hat{\nu}$ satisfies both constraints.
    </div>

    <div class="proof-step">
      <strong>Step 2: Evaluating the Bound.</strong>
      The dual objective value is:
      $$ b^T \hat{\nu} = \frac{b^T r_{\rm ls}}{\|r_{\rm ls}\|_1} $$
      We simplify the numerator. Since $r_{\rm ls} = b - Ax_{\rm ls}$, we have $b = r_{\rm ls} + Ax_{\rm ls}$.
      $$ b^T r_{\rm ls} = (r_{\rm ls} + Ax_{\rm ls})^T r_{\rm ls} = r_{\rm ls}^T r_{\rm ls} + x_{\rm ls}^T A^T r_{\rm ls} $$
      Since $A^T r_{\rm ls} = 0$, the second term vanishes.
      $$ b^T \hat{\nu} = \frac{\|r_{\rm ls}\|_2^2}{\|r_{\rm ls}\|_1} $$
      By weak duality, this is a valid lower bound:
      $$ p^\star \ge \frac{\|r_{\rm ls}\|_2^2}{\|r_{\rm ls}\|_1} $$
    </div>

    <div class="proof-step">
      <strong>Comparison and Sandwiching.</strong>
      We now have a "sandwich" for the optimal value $p^\star$:
      $$ \frac{\|r_{\rm ls}\|_2^2}{\|r_{\rm ls}\|_1} \le p^\star \le \|r_{\rm ls}\|_\infty $$
      How good is the dual bound compared to Part (a)?
      <br>Using $\|r\|_1 \le \sqrt{m}\|r\|_2$, we see:
      $$ \text{Dual Bound} = \frac{\|r_{\rm ls}\|_2^2}{\|r_{\rm ls}\|_1} \ge \frac{\|r_{\rm ls}\|_2^2}{\sqrt{m}\|r_{\rm ls}\|_2} = \frac{\|r_{\rm ls}\|_2}{\sqrt{m}} \ge \frac{\|r_{\rm ls}\|_\infty}{\sqrt{m}} $$
      The dual bound is strictly stronger than the $\sqrt{m}$ bound derived in (a). It uses the specific "spikiness" of the residual (ratio of $\ell_2/\ell_1$) rather than the worst-case dimension factor.
    </div>
  </div>
</div>

        <div class="problem">
  <h3>P9.13 — Case Study: The Geometry of Max-of-Affines (Problem 5.7)</h3>
  <p>Consider the classic piecewise-linear minimization problem:
  $$ \min_{x \in \mathbb{R}^n} \; \max_{i=1,\dots,m} (a_i^\top x + b_i) $$
  This problem is convex but nonsmooth. We analyze it through four different lenses to see how smoothing relates to duality.</p>

  <div class="recap-box">
    <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
    <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
        <li><b>Geometric View:</b> The objective is the upper envelope of $m$ hyperplanes. Minimizing it means finding the lowest point on this "bowl".</li>
        <li><b>Dual Equivalence:</b> The dual can be derived via an "equivalent problem" trick or via standard LP duality. They yield the same result: maximizing a weighted average of intercepts subject to slope equilibrium.</li>
        <li><b>Smoothing:</b> Approximating the max with Log-Sum-Exp is equivalent to adding <b>entropy regularization</b> to the dual problem.</li>
    </ul>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>

    <div class="proof-step">
      <strong>Part (a): Dual via Equivalent Problem.</strong>
      Rewriting the problem: $\min_{x, y} \max_i y_i$ s.t. $y_i = a_i^\top x + b_i$.
      <br><b>Lagrangian Construction:</b>
      $$ L(x, y, \lambda) = \max_i y_i + \sum \lambda_i (a_i^\top x + b_i - y_i) = (\max_i y_i - \lambda^\top y) + (A\lambda)^\top x + b^\top \lambda $$
      <b>Deriving the Dual Function:</b>
      <ul>
        <li><b>Inf over $x$:</b> Linear term $(A\lambda)^\top x$. Finite (0) only if $A\lambda = \sum \lambda_i a_i = 0$.</li>
        <li><b>Inf over $y$:</b> This is $-\sup_y (\lambda^\top y - \max_i y_i)$.
        This supremum is the conjugate of the max function, evaluated at $\lambda$.
        <br><i>Fact:</i> The conjugate of $f(y) = \max y_i$ is the indicator of the unit simplex $\Delta$.
        <br><i>Why?</i> If $\lambda \in \Delta$, then $\lambda^\top y \le \max_i y_i (\sum \lambda_i) = \max_i y_i$, so $\lambda^\top y - \max y_i \le 0$ (tight at $y=0$).
        If $\lambda \notin \Delta$, we can drive the gap to $\infty$.
        <br>Thus, $\lambda \in \Delta$ is required.</li>
      </ul>
      <b>Result:</b> $\max b^\top \lambda$ s.t. $A\lambda = 0, \lambda \in \Delta$. (A force balance problem).
    </div>

    <div class="proof-step">
      <strong>Part (b): Dual via LP Formulation.</strong>
      Standard epigraph form: $\min t$ s.t. $a_i^\top x + b_i \le t$.
      $$ L(x, t, \lambda) = t + \sum \lambda_i (a_i^\top x + b_i - t) = (1 - \mathbf{1}^\top \lambda)t + (A\lambda)^\top x + b^\top \lambda $$
      Minimizing over $t$ (a scalar free variable) yields the equality constraint $1 - \mathbf{1}^\top \lambda = 0$.
      <br>Minimizing over $x$ yields $A\lambda = 0$.
      <br>Since $\lambda \ge 0$ (inequality multipliers), we recover exactly the same constraints: $\lambda \in \Delta, A\lambda = 0$.
    </div>

    <div class="proof-step">
      <strong>Part (c): Entropy Smoothing and its Dual.</strong>
      Let $f_{sm}(x) = \log \sum \exp(a_i^\top x + b_i)$.
      We use the <b>variational representation of log-sum-exp</b> (derived from Fenchel duality of negative entropy):
      $$ \log \sum_{i=1}^m e^{u_i} = \max_{\lambda \in \Delta} \left( \lambda^\top u - \sum_{i=1}^m \lambda_i \log \lambda_i \right) $$
      Substitute $u_i = a_i^\top x + b_i$:
      $$ \min_x f_{sm}(x) = \min_x \max_{\lambda \in \Delta} \left( \lambda^\top(Ax+b) + H(\lambda) \right) $$
      where $H(\lambda) = -\sum \lambda_i \log \lambda_i$ is the entropy.
      <br>Interchanging min and max (by minimax theorem):
      $$ \max_{\lambda \in \Delta} \left( b^\top \lambda + H(\lambda) + \min_x (\lambda^\top A x) \right) $$
      The inner min over $x$ forces $A^\top \lambda = 0$.
      <br><b>Result:</b> The dual is $\max_{\lambda \in \Delta, A\lambda=0} (b^\top \lambda + H(\lambda))$.
      This is the original dual regularized by entropy!
    </div>

    <div class="proof-step">
      <strong>Part (d): Bounds and Convergence.</strong>
      Consider the temperature-scaled approximation $f_\gamma(x) = \frac{1}{\gamma} \log \sum e^{\gamma(a_i^\top x + b_i)}$.
      <br>We use the fundamental inequality for LSE:
      $$ \max_i u_i \le \log \sum e^{u_i} \le \max_i u_i + \log m $$
      Applying this to vector $\gamma u$:
      $$ \gamma \max u_i \le \log \sum e^{\gamma u_i} \le \gamma \max u_i + \log m $$
      Divide by $\gamma$:
      $$ f_{pl}(x) \le f_\gamma(x) \le f_{pl}(x) + \frac{\log m}{\gamma} $$
      This holds for <b>all</b> $x$. Taking the minimum over $x$:
      $$ p^\star_{pl} \le p^\star_\gamma \le p^\star_{pl} + \frac{\log m}{\gamma} $$
      <b>Interpretation:</b>
      <ul>
        <li>As $\gamma \to \infty$, the gap vanishes at rate $1/\gamma$.</li>
        <li>In the dual, the objective is $b^\top \lambda + \frac{1}{\gamma} H(\lambda)$. As $\gamma \to \infty$, the "entropic barrier" $\frac{1}{\gamma} H(\lambda)$ weakens, allowing the dual solution to move toward the boundary (sparse solutions).</li>
      </ul>
    </div>
  </div>
</div>

        <div class="problem">
  <h3>P9.14 — Ellipsoid Volume Minimization (Löwner-John Approximation) (Problem 5.9)</h3>
  <p><strong>Context:</strong> We seek the minimum-volume ellipsoid $\mathcal{E}(X) = \{x \in \mathbb{R}^n \mid x^\top X x \le 1\}$ centered at the origin that contains a set of points $a_1, \dots, a_m \in \mathbb{R}^n$ (which span $\mathbb{R}^n$).
  <br>This is formulated as the convex problem:
  $$ \min_{X \in \mathbb{S}_{++}^n} \log \det(X^{-1}) \quad \text{s.t.} \quad a_i^\top X a_i \le 1, \quad i=1,\dots,m $$
  Consider the simple candidate solution $X_{\text{sim}} = \left(\sum_{k=1}^m a_k a_k^\top\right)^{-1}$.
  <br><strong>(a)</strong> Prove that $X_{\text{sim}}$ is feasible (contains all points).
  <br><strong>(b)</strong> Use the dual problem to prove that the volume of $\mathcal{E}(X_{\text{sim}})$ is at most $(\frac{m}{n})^{n/2}$ times the optimal volume.</p>

  <div class="recap-box">
    <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
    <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
        <li><b>Geometric Approximation:</b> This result shows that a simple statistical estimate (covariance-based) provides a guaranteed approximation to the optimal geometric shape.</li>
        <li><b>Schur Complements:</b> The feasibility proof relies on "lifting" the problem into a higher-dimensional block matrix to prove a quadratic inequality via Schur complements.</li>
    </ul>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      <strong>Step 0: Preliminaries.</strong>
      Let $S = \sum_{k=1}^m a_k a_k^\top$ be the empirical covariance matrix. Since $\{a_k\}$ spans $\mathbb{R}^n$, $S \succ 0$.
      The proposed solution is $X_{\text{sim}} = S^{-1}$.
      The ellipsoid is $\mathcal{E} = \{u \mid u^\top S^{-1} u \le 1\}$.
    </div>

    <div class="proof-step">
      <strong>Step 1: Proving Feasibility (The Schur Complement).</strong>
      We need to verify that every point $a_i$ lies inside the ellipsoid defined by $X_{\text{sim}}$.
      $$ a_i^\top S^{-1} a_i \le 1, \quad \forall i=1,\dots,m $$
      Construct the block matrix $M^{(i)} \in \mathbb{S}^{n+1}$:
      $$ M^{(i)} = \begin{bmatrix} S & a_i \\ a_i^\top & 1 \end{bmatrix} $$
      Notice that $M^{(i)}$ can be written as a sum of rank-1 matrices:
      $$ M^{(i)} = \sum_{k \ne i} \begin{bmatrix} a_k \\ 0 \end{bmatrix} \begin{bmatrix} a_k \\ 0 \end{bmatrix}^\top + \begin{bmatrix} a_i \\ 1 \end{bmatrix} \begin{bmatrix} a_i \\ 1 \end{bmatrix}^\top $$
      Each term is an outer product ($vv^\top$), so it is Positive Semidefinite (PSD). Thus $M^{(i)} \succeq 0$.
      <br><b>Schur Complement Lemma:</b> For $M = \begin{bmatrix} A & B \\ B^\top & C \end{bmatrix}$ with $A \succ 0$, $M \succeq 0 \iff C - B^\top A^{-1} B \ge 0$.
      <br>Applying this to $M^{(i)}$: $1 - a_i^\top S^{-1} a_i \ge 0 \implies a_i^\top S^{-1} a_i \le 1$.
      <br>Thus, $X_{\text{sim}}$ is strictly feasible.
    </div>

    <div class="proof-step">
      <strong>Step 2: Optimizing the Dual Bound.</strong>
      The dual problem maximizes $g(\lambda) = \log \det(\sum \lambda_i a_i a_i^\top) - \mathbf{1}^\top \lambda + n$ over $\lambda \succeq 0$.
      <br>We restrict our search to a symmetric candidate: $\lambda = t \mathbf{1}$ (where $t > 0$).
      $$ \sum \lambda_i a_i a_i^\top = t \sum a_i a_i^\top = t S $$
      $$ g(t \mathbf{1}) = \log \det(tS) - m t + n = \log(t^n \det S) - mt + n = n \log t + \log \det S - mt + n $$
      Maximize this scalar function over $t$:
      $$ \frac{d}{dt} (n \log t - mt) = \frac{n}{t} - m = 0 \implies t^* = \frac{n}{m} $$
      Substitute $t^*$ back to get the lower bound:
      $$ d^* \ge g(t^* \mathbf{1}) = n \log(n/m) + \log \det S - n + n = \log \det S - n \log(m/n) $$
    </div>

    <div class="proof-step">
      <strong>Step 3: Calculating the Approximation Ratio.</strong>
      The primal objective at $X_{\text{sim}}$ is $p(X_{\text{sim}}) = \log \det(S)$.
      We assume strong duality ($p^* = d^*$), but we only need Weak Duality ($p^* \ge d^*_{\text{best}} \ge g(t^*\mathbf{1})$).
      <br>The gap in objective values is:
      $$ \Delta = p(X_{\text{sim}}) - p^* \le \log \det S - (\log \det S - n \log(m/n)) = n \log(m/n) $$
      <b>Converting to Volume:</b>
      The volume of $\mathcal{E}(X)$ is proportional to $\det(X^{-1/2})$. In log-space: $\log \text{Vol} = -\frac{1}{2} \log \det X$.
      Wait, the objective is $\min \log \det(X^{-1}) = -\log \det X$. So the objective is exactly $2 \log \text{Vol}$.
      $$ 2 \log \text{Vol}(X_{\text{sim}}) - 2 \log \text{Vol}(X^*) \le n \log(m/n) $$
      $$ \log \frac{\text{Vol}(X_{\text{sim}})}{\text{Vol}(X^*)} \le \frac{n}{2} \log(m/n) = \log \left( (m/n)^{n/2} \right) $$
      Exponentiating gives the result:
      $$ \frac{\text{Vol}(X_{\text{sim}})}{\text{Vol}(X^*)} \le \left( \frac{m}{n} \right)^{n/2} $$
    </div>
  </div>
</div>

        <div class="problem">
  <h3>P9.15 — Dual of General LP (Problem 5.5)</h3>
  <p>Find the dual function and dual problem of the general Linear Program:
  $$
  \begin{aligned}
  \text{minimize} \quad & c^\top x \\
  \text{subject to} \quad & Gx \preceq h \\
  & Ax = b
  \end{aligned}
  $$
  Make the implicit equality constraints in the dual explicit.</p>

  <div class="recap-box">
    <h4 style="margin-top: 0; font-size: 0.9em; color: var(--primary-300); text-transform: uppercase; letter-spacing: 0.05em;">Recap & Key Concepts</h4>
    <ul style="margin: 8px 0 0 20px; font-size: 0.9em; color: var(--text-secondary);">
        <li><b>Unification:</b> This form covers both the Standard Form ($G=-I, h=0$) and Inequality Form ($A$ is empty).</li>
        <li><b>Domain of Dual:</b> The dual function of an LP is finite only on an affine subspace. Outside this subspace, it is $-\infty$.</li>
    </ul>
  </div>

  <div class="solution-box">
    <h4>Solution</h4>
    <div class="proof-step">
      <strong>Step 1: The Lagrangian.</strong>
      We associate multiplier $\lambda \succeq 0$ with $Gx \preceq h$ and $\nu \in \mathbb{R}^p$ with $Ax = b$.
      $$
      \begin{aligned}
      L(x, \lambda, \nu) &= c^\top x + \lambda^\top (Gx - h) + \nu^\top (Ax - b) \\
      &= -h^\top \lambda - b^\top \nu + (c + G^\top \lambda + A^\top \nu)^\top x
      \end{aligned}
      $$
    </div>
    <div class="proof-step">
      <strong>Step 2: The Dual Function.</strong>
      The dual function is $g(\lambda, \nu) = \inf_x L(x, \lambda, \nu)$.
      The term $(c + G^\top \lambda + A^\top \nu)^\top x$ is linear in $x$.
      <ul>
        <li>If the coefficient vector is non-zero, we can choose $x$ to drive the sum to $-\infty$.</li>
        <li>If the coefficient vector is zero, the term vanishes, and the infimum is $-h^\top \lambda - b^\top \nu$.</li>
      </ul>
      $$
      g(\lambda, \nu) = \begin{cases} -h^\top \lambda - b^\top \nu & \text{if } G^\top \lambda + A^\top \nu + c = 0 \\ -\infty & \text{otherwise} \end{cases}
      $$
    </div>
    <div class="proof-step">
      <strong>Step 3: The Dual Problem.</strong>
      We maximize the dual function subject to $\lambda \succeq 0$.
      $$
      \begin{aligned}
      \text{maximize} \quad & -h^\top \lambda - b^\top \nu \\
      \text{subject to} \quad & G^\top \lambda + A^\top \nu + c = 0 \\
      & \lambda \succeq 0
      \end{aligned}
      $$
      This problem has explicit equality constraints ($G^\top \lambda + A^\top \nu + c = 0$) which were implicit in the definition of the domain of $g$.
    </div>
  </div>
</div>

      </section>

    </article>

    <footer class="site-footer">
      <div class="container">
        <p style="margin: 0;">&copy; <span id="year"></span> Convex Optimization Course &middot; <a href="../../README.md" style="color: var(--brand);">About</a></p>
      </div>
    </footer>
  </main></div>

  <!-- Global utilities -->
  <script src="../../static/js/math-renderer.js"></script>
  <script src="../../static/js/ui.js"></script>
  <script src="../../static/js/toc.js"></script>
  <script>
    document.getElementById('year').textContent = new Date().getFullYear();
  </script>
  <script src="../../static/js/glossary-loader.js"></script>
  <script src="../../static/js/notes-widget.js"></script>
  <script src="../../static/js/pomodoro.js"></script>
  <script src="../../static/js/progress-tracker.js"></script>
</body>
</html>
