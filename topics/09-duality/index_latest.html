<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>09. Duality</title>
  <link rel="stylesheet" href="../../styles.css">
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script src="https://unpkg.com/feather-icons"></script>
</head>
<body>
  <div class="container">
    <header>
      <div class="topic-header">
        <h1>09. Duality</h1>
        <div class="topic-meta">
          <span><i data-feather="clock"></i> 90 min</span>
          <span><i data-feather="file-text"></i> Lecture Notes</span>
        </div>
      </div>
    </header>

    <div class="toc">
      <h4>Contents</h4>
      <ul>
        <li><a href="#section-1">1. Foundations & Geometry</a></li>
        <li><a href="#section-2">2. The Lagrangian</a></li>
        <li><a href="#section-3">3. The Dual Function</a></li>
        <li><a href="#section-4">4. Strong Duality & Slater</a></li>
        <li><a href="#section-5">5. KKT Conditions</a></li>
        <li><a href="#section-6">6. Sensitivity Analysis</a></li>
        <li><a href="#section-7">7. Conic Duality</a></li>
        <li><a href="#section-8">8. Canonical Duals</a></li>
        <li><a href="#section-exercises">9. Exercises</a></li>
      </ul>
    </div>

    <div class="insight" style="margin-bottom: 24px;">
      <h4>The Meta-Question</h4>
      <p>Before we begin, we must fix the central question of this lecture:</p>
      <blockquote style="border-left: 4px solid var(--accent); padding-left: 16px; margin: 16px 0; font-size: 1.1em; font-style: italic;">
        "How can we certify optimality without solving the primal problem directly?"
      </blockquote>
      <p>Everything in primal–dual theory is an answer to that question.
      <br>$\bullet$ Dual variables are <b>prices</b>, <b>forces</b>, or <b>supporting hyperplanes</b>.
      <br>$\bullet$ Dual objectives are <b>lower bounds</b>.
      <br>$\bullet$ Strong duality is the miracle that the bound is <b>tight</b>.</p>
    </div>

    <article>
      <section class="section-card" id="section-1">
        <h2>1. Foundations & Geometry of Constraints</h2>

        <h3>1.1 Optimization Problem as an Object</h3>
        <p>You must be fluent with:</p>
        <ul>
            <li><b>Decision variable</b> $x \in \mathbb{R}^n$: The "knob" you turn. It is not an "unknown" to be solved for algebraically, but a choice to be made.</li>
            <li><b>Objective</b> $f_0(x)$: The cost function mapping choices to values in $\mathbb{R} \cup \{+\infty\}$.</li>
            <li><b>Constraints:</b> $f_i(x) \le 0$ (inequality) and $h_j(x) = 0$ (equality). These define the <b>feasible set</b> $\mathcal{F}$.</li>
        </ul>
        <p><b>Optimal Value Definition:</b> The primary mathematical object is the optimal value $p^\star$, defined as an <b>infimum</b>:</p>
        $$ p^\star = \inf_{x \in \mathcal{F}} f_0(x) $$
        <p>Why infimum? Because a minimum might not be attained (e.g., $\min e^{-x}$). The infimum always exists in the extended reals.
        <br><b>Infeasibility:</b> If $\mathcal{F} = \emptyset$, then $p^\star = +\infty$ (infimum over empty set).
        <br><b>Unboundedness:</b> If we can drive $f_0$ to $-\infty$ inside $\mathcal{F}$, then $p^\star = -\infty$.</p>

        <h3>1.2 Geometry of Constraints</h3>
        <p>This phase explains <i>why</i> Lagrange multipliers are even a reasonable idea.</p>
        <p><b>Constraint Geometry:</b>
        <ul>
            <li>Inequality constraints $f_i(x) \le 0$ define curved regions (sublevel sets).</li>
            <li>Equality constraints $h_j(x) = 0$ define manifolds (surfaces).</li>
            <li><b>Active constraints</b> define the boundary where the optimum lives.</li>
        </ul>
        </p>
        <p><b>Normal Cone Definition:</b> For a convex set $C$ and a point $\mathbf{x} \in C$, the <b>normal cone</b> $N_C(\mathbf{x})$ describes the "outward" directions that are blocked by the boundary.
        $$ N_C(\mathbf{x}) = \{\mathbf{g} \in \mathbb{R}^n \mid \mathbf{g}^\top (\mathbf{y} - \mathbf{x}) \le 0 \text{ for all } \mathbf{y} \in C\} $$
        <b>Key Geometric Fact:</b> At the optimum $x^\star$, the negative gradient of the objective $-\nabla f_0(x^\star)$ points "into the wall". Formally, $-\nabla f_0(x^\star) \in N_C(x^\star)$.
        <br>This "pressure" against the boundary is what <b>dual variables</b> (Lagrange multipliers) measure.</p>

        <h3>1.3 Supporting Hyperplanes (The Skeleton)</h3>
        <p>This is the deep geometric backbone of optimization.</p>
        <div class="theorem-box">
            <h4>Supporting Hyperplane Theorem</h4>
            <p>A hyperplane $H = \{x \mid a^\top x = \alpha\}$ <b>supports</b> a set $C$ at a point $x_0 \in \partial C$ if:
            <ol>
                <li>$x_0$ lies on the hyperplane ($a^\top x_0 = \alpha$).</li>
                <li>The entire set $C$ lies in one of the halfspaces defined by $H$ (e.g., $a^\top x \le \alpha$ for all $x \in C$).</li>
            </ol>
            <b>Key Fact:</b> If $C$ is convex, then <i>every</i> point on its boundary has at least one supporting hyperplane.</p>
        </div>
        <p><b>Optimality Connection:</b> In optimization, we usually minimize $f_0(x)$ over a convex set $\mathcal{F}$.
        <br>At the optimal point $x^\star$, the level set $\{x \mid f_0(x) \le p^\star\}$ and the feasible set $\mathcal{F}$ touch but do not overlap (their interiors are disjoint).
        <br>Thus, there exists a <b>separating hyperplane</b> between them. This hyperplane supports both sets at $x^\star$.
        <br><b>Internalize:</b> Optimality = Existence of a hyperplane that supports the feasible set <i>and</i> the objective epigraph.</p>

        <div style="margin-top: 24px; border: 1px solid rgba(255,255,255,0.1); border-radius: 8px; overflow: hidden;">
            <iframe src="widgets/separation_two_disks.html" width="100%" height="520" style="border:none; background:#0b0d12;"></iframe>
        </div>
      </section>

      <section class="section-card" id="section-2">
        <h2>2. The Lagrangian: Bending Constraints into the Objective</h2>

        <div class="insight">
          <h4>Why Penalties Alone Are Not Enough</h4>
          <p>We want to minimize $f_0(x)$ subject to constraints. We could just add a huge penalty for violating constraints ("soft constraints"), but how huge?
          <br>$\bullet$ If the penalty is too small, we violate the constraints.
          <br>$\bullet$ If the penalty is too large, the problem becomes numerically ill-conditioned.
          <br>The Lagrangian introduces <b>adaptive penalties</b> (multipliers) that are determined by the geometry of the problem itself, not by an arbitrary choice.</p>
        </div>

        <h3>2.1 Definition of the Lagrangian</h3>
        <p>Given the standard form primal problem:</p>
        <div style="padding: 16px; background: var(--panel); border-left: 4px solid var(--brand); margin: 16px 0;">
          <p style="margin: 0;">
            $
            \begin{aligned}
            \min_{x \in \mathbb{R}^n} \quad & f_0(x) \\
            \text{s.t.} \quad & f_i(x) \le 0, \quad i = 1, \dots, m \\
            & h_j(x) = 0, \quad j = 1, \dots, p
            \end{aligned}
            $
          </p>
        </div>
        <p>The <a href="#" class="definition-link">Lagrangian</a> $\mathcal{L}: \mathbb{R}^n \times \mathbb{R}^m \times \mathbb{R}^p \to \mathbb{R}$ is:</p>
        $$
        \mathcal{L}(x, \lambda, \nu) = f_0(x) + \sum_{i=1}^m \lambda_i f_i(x) + \sum_{j=1}^p \nu_j h_j(x)
        $$
        <p>Key sign requirements you must internalize:</p>
        <ul>
            <li>$\mathbf{\lambda_i \ge 0}$ <b>is forced, not optional.</b> (Inequalities are one-sided).</li>
            <li>$\mathbf{\nu_j \in \mathbb{R}}$ <b>is free.</b> (Equalities are two-sided).</li>
        </ul>

        <h3>2.2 The Key Monotonicity Trick</h3>
        <p>Why do we require $\lambda_i \ge 0$? To ensure the Lagrangian is a <b>lower bound</b> on the objective for feasible points.</p>
        <p>Let $x$ be any feasible point. Then $f_i(x) \le 0$ and $h_j(x) = 0$.
        <br>If $\lambda_i \ge 0$, then $\lambda_i f_i(x) \le 0$.
        <br>Thus:</p>
        $$
        \mathcal{L}(x, \lambda, \nu) = f_0(x) + \underbrace{\sum \lambda_i f_i(x)}_{\le 0} + \underbrace{\sum \nu_j h_j(x)}_{= 0} \le f_0(x)
        $$
        <p>If we allowed $\lambda_i < 0$, the term $\lambda_i f_i(x)$ would be positive, and $\mathcal{L}$ could exceed $f_0(x)$, breaking the lower bound property.</p>

        <h3>2.3 The Geometric Interpretation</h3>
        <p>Recall from <a href="../03-convex-sets-geometry/index.html">Lecture 03</a> that optimality is related to <b>supporting hyperplanes</b>. The Lagrangian is simply the algebraic representation of a hyperplane supporting the "achievable set" of objective and constraint values.
        <br>The multipliers $(\lambda, \nu)$ are the normal vector to this hyperplane. The condition $\lambda \ge 0$ ensures the hyperplane orientation respects the "less than or equal to" direction of the inequality constraints.</p>

        <img src="assets/duality_lagrangian_demo.gif" alt="Lagrangian as Lower Bound" style="width: 100%; border-radius: 8px; margin: 16px 0;">

        <h3>2.4 The Minimax (Saddle Point) Interpretation</h3>
        <p>We can recover the primal problem from the Lagrangian by maximizing over the dual variables. Define the function:</p>
        $$
        \sup_{\lambda \succeq 0, \nu} \mathcal{L}(x, \lambda, \nu) = \sup_{\lambda \succeq 0, \nu} \left( f_0(x) + \sum \lambda_i f_i(x) + \sum \nu_j h_j(x) \right)
        $$
        <ul>
          <li><strong>If $\mathbf{x}$ is feasible:</strong> $f_i(\mathbf{x}) \le 0$ and $h_j(\mathbf{x})=0$. To maximize the sum, the best we can do is set $\lambda_i=0$ (since $\lambda_i \ge 0$ and $f_i(\mathbf{x}) \le 0$, any positive $\lambda$ would make the term negative). The $\nu$ term is always 0. Thus, the supremum is $f_0(\mathbf{x})$.</li>
          <li><strong>If $\mathbf{x}$ is infeasible:</strong>
            <ul>
              <li>If $f_i(x) > 0$, we can let $\lambda_i \to \infty$, making the sum $\infty$.</li>
              <li>If $h_j(x) \ne 0$, we can let $\nu_j \to \text{sign}(h_j(x)) \cdot \infty$, making the sum $\infty$.</li>
            </ul>
          </li>
        </ul>
        <p>Thus, the unconstrained problem $\min_x \sup_{\lambda \succeq 0, \nu} \mathcal{L}(x, \lambda, \nu)$ is exactly equivalent to the original constrained primal problem.</p>
        <div class="intuition-box">
          <p><b>Duality as a Game:</b>
          <br><b>Primal:</b> $\min_x \max_{\lambda, \nu} \mathcal{L}(x, \lambda, \nu)$ (Minimizer moves first, Maximizer exploits violations).
          <br><b>Dual:</b> $\max_{\lambda, \nu} \min_x \mathcal{L}(x, \lambda, \nu)$ (Maximizer moves first, setting prices; Minimizer optimizes given prices).
          <br><b>Weak Duality</b> is simply the max-min inequality: $\max_{\lambda, \nu} \min_x \mathcal{L}(x, \lambda, \nu) \le \min_x \max_{\lambda, \nu} \mathcal{L}(x, \lambda, \nu)$. This inequality holds for <em>any</em> function, not just Lagrangians.
          <br><b>Strong Duality</b> implies the existence of a <b>Saddle Point</b> where the order of play doesn't matter, i.e., we can swap min and max.</p>
        </div>

        <img src="assets/duality_saddle_path.gif" alt="Saddle Path Dynamics" style="width: 100%; border-radius: 8px; margin: 16px 0;">

        <div style="margin-top: 24px; border: 1px solid rgba(255,255,255,0.1); border-radius: 8px; overflow: hidden;">
            <iframe src="widgets/primal_dual_1d.html" width="100%" height="520" style="border:none; background:#0b0d12;"></iframe>
        </div>
      </section>

      <section class="section-card" id="section-3">
        <h2>3. The Lagrange Dual Function: Lower Bounds from Nowhere</h2>

        <div class="insight">
          <h4>The Core Idea</h4>
          <p>This is the first conceptual leap. We convert the Lagrangian $\mathcal{L}(x, \lambda, \nu)$ into a function of only the dual variables $(\lambda, \nu)$ by minimizing out $x$. This new function $g(\lambda, \nu)$ is the <b>engine</b> of duality.</p>
        </div>

        <h3>3.1 Dual Function Definition</h3>
        <p>The <a href="#" class="definition-link">dual function</a> $g: \mathbb{R}^m \times \mathbb{R}^p \to \mathbb{R} \cup \{-\infty\}$ is defined as the pointwise infimum of the Lagrangian over $x$:</p>
        $$
        g(\lambda, \nu) = \inf_{x \in \mathbb{R}^n} \mathcal{L}(x, \lambda, \nu) = \inf_{x \in \mathbb{R}^n} \left( f_0(x) + \sum_{i=1}^m \lambda_i f_i(x) + \sum_{j=1}^p \nu_j h_j(x) \right)
        $$
        <p><b>Note:</b> The infimum is over the <i>entire domain</i> of the functions (usually $\mathbb{R}^n$), not the feasible set. We have "relaxed" the constraints.</p>

        <div class="theorem-box">
          <h4>Key Property: Concavity</h4>
          <p>The dual function $g(\lambda, \nu)$ is <b>concave</b>, even if the primal problem is not convex.</p>
          <div class="proof-box">
            <h4>Proof</h4>
            <p>For each fixed $\mathbf{x}$, the function $(\lambda, \nu) \mapsto \mathcal{L}(\mathbf{x}, \lambda, \nu)$ is affine in $(\lambda, \nu)$.
            <br>The dual function $g$ is the pointwise infimum of a family of affine functions.
            <br>The infimum of concave (linear) functions is concave.</p>
          </div>
        </div>

        <div class="insight">
          <h4>Why the Dual is Always Convex (Even When the Primal is Not)</h4>
          <p>This is a fundamental fact that deserves emphasis. The dual problem:</p>
          $$ \max_{\lambda \succeq 0, \nu} g(\lambda, \nu) $$
          <p>is <b>always a convex optimization problem</b>:</p>
          <ul>
            <li>The domain $\{\lambda \succeq 0\}$ is a convex set (the non-negative orthant).</li>
            <li>Maximizing a concave function is equivalent to minimizing a convex function.</li>
          </ul>
          <p><b>Geometric Intuition:</b> For each fixed $x$, the Lagrangian is a "hyperplane" in $(\lambda, \nu)$-space. The dual function is the <b>lower envelope</b> of these hyperplanes. Lower envelopes of affine functions are always concave.</p>
        </div>

        <h3>3.2 Weak Duality (The Universal Inequality)</h3>
        <p>The fundamental property of the dual function is that it yields lower bounds on the optimal value $p^\star$.</p>

        <div class="theorem-box">
          <h4>Theorem (Weak Duality)</h4>
          <p>For <b>any</b> optimization problem (convex or not), and any $\lambda \succeq 0, \nu$:</p>
          $$
          g(\lambda, \nu) \le p^\star
          $$
          <div class="proof-box">
            <h4>Proof (3 lines)</h4>
            <p>For any feasible $\tilde{x}$ and any $\lambda \succeq 0$:</p>
            $$
            \begin{aligned}
            g(\lambda, \nu) &= \inf_x \mathcal{L}(x, \lambda, \nu) \le \mathcal{L}(\tilde{x}, \lambda, \nu) \quad \text{(infimum is } \le \text{ value at } \tilde{x}) \\
            &\le f_0(\tilde{x}) \quad \text{(by the Monotonicity Trick from §2.2)}
            \end{aligned}
            $$
            <p>Since this holds for <i>every</i> feasible $\tilde{x}$, it holds for the infimum of the right side: $g(\lambda, \nu) \le \inf \{f_0(\tilde{x})\} = p^\star$.</p>
          </div>
        </div>

        <h3>3.3 Computing $g(\lambda, \nu)$: The Templates</h3>
        <p>Calculating the dual function means solving an unconstrained minimization problem parameterized by $\lambda, \nu$. There are three main patterns:</p>

        <div class="example">
          <h4>Template 1: Linear / Affine (Equality Constraints)</h4>
          <p>Lagrangian is linear in $x$: $L(x) = (c - A^\top \lambda)^\top x$.
          <br>$\inf_x L(x) = -\infty$ unless the slope is zero.
          <br><b>Result:</b> $g(\lambda) = \text{constant}$ if slope is 0, else $-\infty$.
          <br>This generates <b>dual equality constraints</b>.</p>
        </div>

        <div class="example">
          <h4>Template 2: Quadratic (Completing the Square)</h4>
          <p>Lagrangian is quadratic in $x$: $L(x) = \frac{1}{2}x^\top P x + q(\lambda)^\top x + r(\lambda)$ with $P \succ 0$.
          <br>Minimum occurs at $\nabla L = 0 \implies Px = -q(\lambda)$.
          <br><b>Result:</b> $g(\lambda) = -\frac{1}{2} q(\lambda)^\top P^{-1} q(\lambda) + r(\lambda)$.
          <br>This generates <b>dual quadratic objectives</b>.</p>
        </div>

        <div class="example">
          <h4>Template 3: Conjugate Functions</h4>
          <p>Lagrangian form: $L(x) = f(x) + y(\lambda)^\top x$.
          <br>$\inf_x (f(x) + y^\top x) = -\sup_x ((-y)^\top x - f(x)) = -f^*(-y)$.
          <br><b>Result:</b> $g(\lambda) = -f^*(-y(\lambda))$.
          <br>This is the general tool for non-quadratic problems (norms, exp, log).</p>
        </div>

        <div style="margin-top: 24px; border: 1px solid rgba(255,255,255,0.1); border-radius: 8px; overflow: hidden;">
          <iframe src="widgets/logsumexp_conjugate_widget.html" width="100%" height="520" style="border:none; background:#0b0d12;"></iframe>
        </div>

        <div style="margin-top: 24px; border: 1px solid rgba(255,255,255,0.1); border-radius: 8px; overflow: hidden;">
            <iframe src="widgets/equality_dual_projection_2d.html" width="100%" height="520" style="border:none; background:#0b0d12;"></iframe>
        </div>
      </section>

      <section class="section-card" id="section-4">
        <h2>4. The Dual Problem and Strong Duality</h2>

        <h3>4.1 The Dual Problem</h3>
        <p>The dual problem seeks the <i>best</i> lower bound provided by the dual function:</p>
        $$
        \begin{aligned}
        \text{maximize} \quad & g(\lambda, \nu) \\
        \text{subject to} \quad & \lambda \succeq 0
        \end{aligned}
        $$
        <p>Let $d^\star$ be the optimal value of the dual problem. By weak duality, $d^\star \le p^\star$.
        <br><b>Note:</b> We define the domain of $g$ as those points where $g > -\infty$. This often introduces implicit constraints (e.g., $A^\top \nu + c = 0$ in LP).</p>

        <img src="assets/duality_gap_convergence.gif" alt="Duality Gap Convergence" style="width: 100%; border-radius: 8px; margin: 16px 0;">

        <h3>4.2 Strong Duality</h3>
        <p>Strong duality holds when the duality gap is zero: $p^\star = d^\star$. This is the "miracle" where the lower bound becomes exact.</p>

        <div class="theorem-box">
          <h4>Slater's Condition (The Gateway)</h4>
          <p>For a <b>convex</b> optimization problem:
          $$
          \begin{aligned}
          \min \quad & f_0(x) \\
          \text{s.t.} \quad & f_i(x) \le 0, \quad Ax = b
          \end{aligned}
          $$
          If there exists a strictly feasible point $\tilde{x}$ (i.e., $f_i(\tilde{x}) < 0$ and $A\tilde{x}=b$), then:
          <ol>
            <li><b>Strong duality holds:</b> $p^\star = d^\star$.</li>
            <li><b>Dual attainment:</b> If $d^\star > -\infty$, there exists a dual optimal pair $(\lambda^*, \nu^*)$.</li>
          </ol>
          </p>
        </div>

        <div style="margin-top: 24px; border: 1px solid rgba(255,255,255,0.1); border-radius: 8px; overflow: hidden;">
            <iframe src="widgets/slater_failure_dual_attainment.html" width="100%" height="520" style="border:none; background:#0b0d12;"></iframe>
        </div>

        <div class="proof-box">
          <h4>Geometric Proof of Strong Duality (Separating Hyperplanes)</h4>
          <p>Consider the set of achievable values $\mathcal{A} = \{(f_1(x), \dots, f_m(x), f_0(x)) \mid Ax=b\}$. This set is convex.
          <br>The optimal value $p^\star$ is the "lowest entry point" on the vertical axis.
          <br>If Slater's condition holds, the set $\mathcal{A}$ has interior points to the left of the axis.
          <br>We can separate the set $\mathcal{A}$ from the "better-than-optimal" region $\{(u, t) \mid u \le 0, t < p^\star\}$ using a hyperplane.
          <br>The normal vector to this hyperplane corresponds to the dual multipliers $(\lambda, 1)$. Normalizing gives the Lagrange multipliers.</p>
        </div>
      </section>

      <section class="section-card" id="section-5">
        <h2>5. KKT Conditions: Optimality as Equilibrium</h2>

        <h3>5.1 Deriving KKT</h3>
        <p>The Karush-Kuhn-Tucker (KKT) conditions are not just a formula; they are the inevitable result of the "sandwich" bound becoming tight.</p>

        <div class="proof-box">
          <h4>Derivation: The Tight Sandwich</h4>
          <p>We assume strong duality ($p^* = d^*$) and existence of primal/dual optimizers. Consider the chain:</p>
          $$
          \begin{aligned}
          d^* &= g(\lambda^*, \nu^*) \quad \text{(Dual Optimal Value)} \\
          &= \inf_x \mathcal{L}(x, \lambda^*, \nu^*) \quad \text{(Def of } g \text{)} \\
          &\le \mathcal{L}(x^*, \lambda^*, \nu^*) \quad \text{(Infimum is } \le \text{ value at } x^*) \\
          &\le f_0(x^*) \quad \text{(Lagrangian } \le \text{ Objective on feasible points)} \\
          &= p^* \quad \text{(Primal Optimal Value)}
          \end{aligned}
          $$
          <p>Since $d^* = p^*$, the entire chain collapses into equalities.
          <br>$\bullet$ <b>First Equality:</b> $\inf_x \mathcal{L}(x, \lambda^*, \nu^*) = \mathcal{L}(x^*, \lambda^*, \nu^*)$. This implies $x^*$ <b>minimizes</b> the Lagrangian $\mathcal{L}(\cdot, \lambda^*, \nu^*)$. The first-order condition for this unconstrained minimization is $\nabla_x \mathcal{L} = 0$ (<b>Stationarity</b>).
          <br>$\bullet$ <b>Second Equality:</b> $\mathcal{L}(x^*, \lambda^*, \nu^*) = f_0(x^*)$. This implies $\sum \lambda_i^* f_i(x^*) = 0$. Since each term is non-positive, each must be zero (<b>Complementary Slackness</b>).</p>
        </div>

        <div class="insight">
          <h4>Interpretation: Lagrangian Saddle Point</h4>
          <p>The KKT conditions are equivalent to saying that $(x^*, \lambda^*, \nu^*)$ is a <b>saddle point</b> of the Lagrangian:
          $$ \mathcal{L}(x^*, \lambda, \nu) \le \mathcal{L}(x^*, \lambda^*, \nu^*) \le \mathcal{L}(x, \lambda^*, \nu^*) $$
          for all $x$ and all $\lambda \ge 0, \nu$.
          <br>$\bullet$ Right inequality: Stationarity (minimizing w.r.t. $x$).
          <br>$\bullet$ Left inequality: Feasibility + Complementary Slackness (maximizing w.r.t. multipliers).</p>
        </div>

        <h3>5.2 The KKT System</h3>
        <ol>
          <li><b>Primal Feasibility:</b> $f_i(x) \le 0, h_j(x) = 0$.</li>
          <li><b>Dual Feasibility:</b> $\lambda_i \ge 0$.</li>
          <li><b>Complementary Slackness:</b> $\lambda_i f_i(x) = 0$. (Constraint is tight OR multiplier is zero).</li>
          <li><b>Stationarity:</b> $\nabla f_0(x) + \sum \lambda_i \nabla f_i(x) + \sum \nu_j \nabla h_j(x) = 0$. (Forces balance).</li>
        </ol>

        <img src="assets/duality_kkt_2d_fast.gif" alt="KKT Geometry" style="width: 100%; border-radius: 8px; margin: 16px 0;">
        <img src="assets/duality_comp_slack_switch.gif" alt="Complementary Slackness Switch" style="width: 100%; border-radius: 8px; margin: 16px 0;">

        <div class="insight">
          <h4>Geometric Interpretation via Normal Cones</h4>
          <p>The stationarity condition $0 \in \nabla f_0(x^*) + \sum \lambda_i \nabla f_i(x^*) + \sum \nu_j \nabla h_j(x^*)$ has a deep geometric meaning:
          $$ -\nabla f_0(x^*) \in N_{\mathcal{F}}(x^*) $$
          The negative gradient of the objective must lie in the <b>normal cone</b> of the feasible set at the optimal point. KKT simply expresses this normal vector as a linear combination of constraint gradients, provided a constraint qualification (like Slater's) holds.</p>
        </div>

        <div style="margin-top: 24px; border: 1px solid rgba(255,255,255,0.1); border-radius: 8px; overflow: hidden;">
          <iframe src="widgets/kkt_vector_balance.html" width="100%" height="520" style="border:none; background:#0b0d12;"></iframe>
        </div>
      </section>

      <section class="section-card" id="section-6">
        <h2>6. Perturbation and Sensitivity Analysis</h2>

        <p>Duality provides powerful insights into how the optimal value changes when constraints are perturbed.</p>

        <h3>6.1 The Value Function (Perturbation Function)</h3>
        <p>Consider the perturbed primal problem with optimal value $p^*(u, v)$:</p>
        $$
        \begin{aligned}
        \min \quad & f_0(x) \\
        \text{s.t.} \quad & f_i(x) \le u_i, \quad i=1\dots m \\
        & h_j(x) = v_j, \quad j=1\dots p
        \end{aligned}
        $$
        <p>Here $u \in \mathbb{R}^m$ relaxes the inequalities, and $v \in \mathbb{R}^p$ shifts the equalities. The original optimal value is $p^*(0, 0)$.
        <br><b>Domain Honesty:</b> This is an extended-real function $p^*: \mathbb{R}^{m+p} \to \mathbb{R} \cup \{+\infty, -\infty\}$. If perturbations make the problem infeasible, $p^*(u, v) = +\infty$.</p>

        <h3>6.2 Convexity of the Value Function</h3>
        <p>If the original problem is convex (convex $f_0, f_i$, affine $h_j$), then $p^*(u, v)$ is a <b>convex function</b> of $(u, v)$.</p>

        <h3>6.3 Global Inequality (Subgradient Interpretation)</h3>
        <div class="theorem-box">
          <h4>Theorem: Optimal Multipliers as Subgradients</h4>
          <p>The optimal dual variables are (negative) subgradients of the value function at zero:</p>
          $$ \boxed{ (-\lambda^*, -\nu^*) \in \partial p^*(0, 0) } $$
          <p>This implies the global inequality:
          $$ p^*(u, v) \ge p^*(0, 0) - \lambda^{*\top} u - \nu^{*\top} v $$
          <b>Shadow Price Interpretation:</b>
          <ul>
            <li>$\lambda_i^* \ge 0$. Relaxing constraint $i$ ($u_i > 0$) lowers the optimal value. $\lambda_i^*$ is the rate of this improvement.</li>
            <li>If $p^*$ is differentiable, then $\frac{\partial p^*}{\partial u_i} = -\lambda_i^*$ and $\frac{\partial p^*}{\partial v_j} = -\nu_j^*$. The Lagrange multipliers are exactly the <strong>sensitivity</strong> of the optimal value to constraint perturbations.</li>
          </ul>
          </p>
        </div>

        <img src="assets/duality_sensitivity_supporting_line_fast.gif" alt="Sensitivity Analysis" style="width: 100%; border-radius: 8px; margin: 16px 0;">

        <div style="margin-top: 24px; border: 1px solid rgba(255,255,255,0.1); border-radius: 8px; overflow: hidden;">
          <iframe src="widgets/value_function_support.html" width="100%" height="520" style="border:none; background:#0b0d12;"></iframe>
        </div>

        <h3>6.5 Certificates of Infeasibility</h3>
        <p>Duality can also prove that a problem is infeasible (primal) or unbounded below.</p>
        <div class="insight">
          <h4>The Core Pattern: Dual Rays</h4>
          <p>If the primal problem is infeasible, the dual problem is typically unbounded. We can find a "dual ray" (direction) along which the dual objective goes to $+\infty$.
          <br>Consider the LP feasibility problem: Find $x$ s.t. $Ax \le b$.
          <br><b>Farkas' Lemma:</b> The system $Ax \le b$ is infeasible if and only if there exists $y \ge 0$ such that $A^\top y = 0$ and $b^\top y < 0$.
          <br>This vector $y$ is a <b>certificate of infeasibility</b>. It constructs a linear combination of the inequalities $0 = y^\top A x \le y^\top b < 0$, yielding the contradiction $0 < 0$.</p>
        </div>
        <img src="assets/duality_farkas_xy_infeasible.gif" alt="Farkas Certificate" style="width: 100%; border-radius: 8px; margin: 16px 0;">
      </section>

      <section class="section-card" id="section-7">
        <h2>7. Conic Duality and Generalized Inequalities</h2>

        <div class="insight">
          <h4>Why Conic Duality Matters</h4>
          <p>The componentwise inequality $x \le 0$ (meaning $x \in -\mathbb{R}_+^n$) is just one special case of a <b>generalized inequality</b> $x \preceq_K 0$ (meaning $x \in -K$) where $K$ is a proper cone. Conic duality theory shows that <b>all convex optimization problems</b>—linear, quadratic, second-order cone, semidefinite, and beyond—are instances of the same unified framework.</p>
        </div>

        <h3>7.1 Standard Conic Form</h3>
        <p>
        $$
        \begin{aligned}
        \text{Primal:} \quad & \min c^\top x \quad \text{s.t.} \quad Ax = b, \ x \in K \\
        \text{Dual:} \quad & \max b^\top y \quad \text{s.t.} \quad c - A^\top y = s, \ s \in K^*
        \end{aligned}
        $$
        where $K^*$ is the dual cone. This unifies LP, SOCP, and SDP.
        </p>

        <div style="margin-top: 24px; border: 1px solid rgba(255,255,255,0.1); border-radius: 8px; overflow: hidden;">
          <iframe src="widgets/soc_dual_cone.html" width="100%" height="520" style="border:none; background:#0b0d12;"></iframe>
        </div>

        <h3>7.2 Semidefinite Programming (SDP)</h3>
        <p>For SDP, $K = \mathbb{S}_+^n$ (positive semidefinite cone). The cone is self-dual ($K^* = K$).
        <br><b>Primal:</b> $\min \mathrm{tr}(CX)$ s.t. $\mathrm{tr}(A_i X) = b_i, X \succeq 0$.
        <br><b>Dual:</b> $\max b^\top y$ s.t. $\sum y_i A_i \preceq C$.
        </p>

        <div style="margin-top: 24px; border: 1px solid rgba(255,255,255,0.1); border-radius: 8px; overflow: hidden;">
          <iframe src="widgets/psd_cone_2x2.html" width="100%" height="520" style="border:none; background:#0b0d12;"></iframe>
        </div>
      </section>

      <section class="section-card" id="section-8">
        <h2>8. Canonical Duals: A Problem Pack</h2>
        <p>This section provides a "micro-toolbox" of derivations for standard problems. Mastering these specific derivations builds the pattern-matching skills needed for general duality.</p>

        <div class="problem">
          <h3>Problem 1: Least Squares (Residual Form)</h3>
          <p><b>Primal:</b> $\min \frac{1}{2} \|Ax - b\|_2^2$. Rewrite as $\min \frac{1}{2}\|y\|_2^2$ s.t. $y = Ax - b$.
          <br><b>Dual:</b> $\max -\frac{1}{2}\|\nu\|^2 - b^\top \nu$ s.t. $A^\top \nu = 0$.</p>
        </div>

        <div class="problem">
            <h3>Problem 2: Linear Program</h3>
            <p><b>Primal:</b> $\min c^\top x$ s.t. $Ax \le b$.
            <br><b>Dual:</b> $\max -b^\top \lambda$ s.t. $A^\top \lambda + c = 0, \lambda \ge 0$.</p>
        </div>

        <div class="problem">
            <h3>Problem 3: LASSO</h3>
            <p><b>Primal:</b> $\min \frac{1}{2}\|Ax - b\|_2^2 + \lambda \|x\|_1$.
            <br><b>Dual:</b> $\max -b^\top \nu - \frac{1}{2}\|\nu\|^2$ s.t. $\|A^\top \nu\|_\infty \le \lambda$.
            <br>The dual constraint corresponds to the dual norm of the L1 penalty.</p>
        </div>
      </section>

      <section class="section-card" id="section-exercises">
        <h2>9. Exercises</h2>
        <div class="problem">
            <h3>P9.1 — Sensitivity Analysis</h3>
            <p>Consider $\min x^2$ s.t. $x \le -1$. Compute the optimal value $p^*(u)$ as a function of the constraint perturbation $x \le -1+u$. Verify that $\lambda^* = -p^{*'}(0)$.</p>
        </div>
        <div class="problem">
            <h3>P9.2 — Water-filling</h3>
            <p>Derive the KKT conditions for $\min -\sum \log(\alpha_i + x_i)$ s.t. $x \ge 0, \mathbf{1}^\top x = 1$. Interpret the Lagrange multiplier $\nu$ as a water level.</p>
        </div>
      </section>

    </article>
  </div>
</body>
</html>
