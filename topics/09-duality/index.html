<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>09. Duality — Convex Optimization</title>
  <link rel="stylesheet" href="../../static/css/convex-unified.css" />
  <script src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css" />
  <script src="https://unpkg.com/feather-icons"></script>
</head>
<body>
  <header class="site-header sticky">
    <div class="container">
      <div class="brand">
        <a href="../../index.html">Convex Optimization</a>
      </div>
      <nav class="nav">
        <a href="../../index.html"><i data-feather="grid"></i> All Lectures</a>
        <a href="../08-convex-problems-conic/index.html"><i data-feather="arrow-left"></i> Previous</a>
        <a href="../10-approximation-fitting/index.html">Next <i data-feather="arrow-right"></i></a>
      </nav>
    </div>
  </header>

  <div class="lecture-container"><aside class="sidebar"><div id="toc-container"><h2><i data-feather="list"></i> Table of Contents</h2><nav id="toc"></nav></div></aside><main class="lecture-content">
    <header class="lecture-header section-card">
      <h1>09. Duality Theory</h1>
      <div class="lecture-meta">
        <span>Date: 2025-11-25</span>
        <span>Duration: 90 min</span>
        <span>Tags: duality, lagrangian, KKT, slater, sensitivity, certificates</span>
      </div>
      <div class="lecture-summary">
        <p><strong>Overview:</strong> This lecture presents the core of duality theory. We construct the Lagrangian dual function and prove weak and strong duality theorems. We derive the KKT conditions, interpret dual variables as shadow prices, and show how to use duality for sensitivity analysis and reformulation.</p>
        <p><strong>Prerequisites:</strong> <a href="../04-convex-sets-cones/index.html">Lecture 04: Convex Sets Cones</a> (separating hyperplane theorem), <a href="../06-convex-functions-advanced/index.html">Lecture 06: Advanced Functions</a> (conjugate functions).</p>
      </div>
    </header>

    <section class="section-card">
      <h2><i data-feather="target"></i> Learning Objectives</h2>
      <p>After this lecture, you will be able to:</p>
      <ul>
        <li>Construct the Lagrangian and Dual Function for any optimization problem</li>
        <li>State and prove Weak Duality and Slater's Condition for Strong Duality</li>
        <li>Derive KKT conditions and use them to solve problems analytically</li>
        <li>Interpret dual variables as sensitivities ("shadow prices")</li>
        <li>Compute duals of LP, QP, SOCP, and SDP problems</li>
        <li>Use duality to certify infeasibility (Farkas' Lemma)</li>
      </ul>
    </section>

    <div class="insight" style="margin-bottom: 24px;">
      <h4>The Meta-Question</h4>
      <p>Before we begin, we must fix the central question of this lecture:</p>
      <blockquote style="border-left: 4px solid var(--accent); padding-left: 16px; margin: 16px 0; font-size: 1.1em; font-style: italic;">
        "How can we certify optimality without solving the primal problem directly?"
      </blockquote>
      <p>Everything in primal–dual theory is an answer to that question.
      <br>$\bullet$ Dual variables are <b>prices</b>, <b>forces</b>, or <b>supporting hyperplanes</b>.
      <br>$\bullet$ Dual objectives are <b>lower bounds</b>.
      <br>$\bullet$ Strong duality is the miracle that the bound is <b>tight</b>.</p>
    </div>

    <article>
      <section class="section-card" id="section-1">
      <h2>1. The Engine of Duality: Conjugates (Recap)</h2>
      <p>In <a href="../06-convex-functions-advanced/index.html">Lecture 06</a>, we defined the <b>Convex Conjugate</b> $f^*$ as the pointwise supremum of affine functions:
      $$ f^*(\mathbf{y}) = \sup_{\mathbf{x} \in \mathrm{dom} f} (\mathbf{y}^\top \mathbf{x} - f(\mathbf{x})) $$
      Geometric duality rests on this transformation. The conjugate $f^*(\mathbf{y})$ represents the maximum gap between the linear function $\mathbf{y}^\top \mathbf{x}$ and the function $f(\mathbf{x})$.</p>

      <h3>1.1 Key Properties for Duality</h3>
      <p>We recall two essential facts that drive the duality engine:</p>
      <ul>
        <li><b>Convexity:</b> $f^*$ is always convex (even if $f$ is not).</li>
        <li><b>Fenchel-Young Inequality:</b> For any $\mathbf{x}, \mathbf{y}$:
        $$ f(\mathbf{x}) + f^*(\mathbf{y}) \ge \mathbf{x}^\top \mathbf{y} $$
        Equality holds if and only if $\mathbf{y} \in \partial f(\mathbf{x})$. This inequality is the algebraic source of <b>Weak Duality</b> ($p^\star \ge d^\star$).</li>
      </ul>

      <h3>1.2 Support Functions</h3>
      <p>Constraints are modeled by indicator functions $I_C(\mathbf{x})$. Their conjugates are <b>Support Functions</b>:
      $$ \sigma_C(\mathbf{y}) = I_C^*(\mathbf{y}) = \sup_{\mathbf{x} \in C} \mathbf{y}^\top \mathbf{x} $$
      This explains why dual problems involve maximizing linear functions over convex sets.</p>
    </section>

    <section class="section-card" id="section-2">
        <h2>2. The Lagrangian: Bending Constraints into the Objective</h2>

        <div class="insight">
          <h4>Why Penalties Alone Are Not Enough</h4>
          <p>We want to minimize $f_0(x)$ subject to constraints. We could just add a huge penalty for violating constraints ("soft constraints"), but how huge?
          <br>$\bullet$ If the penalty is too small, we violate the constraints.
          <br>$\bullet$ If the penalty is too large, the problem becomes numerically ill-conditioned.
          <br>The Lagrangian introduces <b>adaptive penalties</b> (multipliers) that are determined by the geometry of the problem itself, not by an arbitrary choice.</p>
        </div>

        <h3>2.1 Definition of the Lagrangian</h3>
        <p>Given the standard form primal problem:</p>
        <div style="padding: 16px; background: var(--panel); border-left: 4px solid var(--brand); margin: 16px 0;">
          <p style="margin: 0;">
            $
            \begin{aligned}
            \min_{x \in \mathbb{R}^n} \quad & f_0(x) \\
            \text{s.t.} \quad & f_i(x) \le 0, \quad i = 1, \dots, m \\
            & h_j(x) = 0, \quad j = 1, \dots, p
            \end{aligned}
            $
          </p>
        </div>
        <p>The <a href="#" class="definition-link">Lagrangian</a> $\mathcal{L}: \mathbb{R}^n \times \mathbb{R}^m \times \mathbb{R}^p \to \mathbb{R}$ is:</p>
        $$
        \mathcal{L}(x, \lambda, \nu) = f_0(x) + \sum_{i=1}^m \lambda_i f_i(x) + \sum_{j=1}^p \nu_j h_j(x)
        $$
        <p>where $\lambda_i$ is the Lagrange multiplier associated with $f_i(\mathbf{x}) \le 0$, and $\nu_j$ with $h_j(\mathbf{x}) = 0$.
        <br>Domain: $\mathrm{dom}\, L = \mathcal{D} \times \mathbb{R}^m \times \mathbb{R}^p$.</p>
        <p>Key sign requirements you must internalize:</p>
        <ul>
            <li>$\mathbf{\lambda_i \ge 0}$ <b>is forced, not optional.</b> (Inequalities are one-sided).</li>
            <li>$\mathbf{\nu_j \in \mathbb{R}}$ <b>is free.</b> (Equalities are two-sided).</li>
        </ul>

        <h3>2.2 The Key Monotonicity Trick</h3>
        <div class="insight">
          <h4>Idea: Lower Bound Property</h4>
          <p>For any feasible $\mathbf{x}$ and any $\lambda \succeq 0, \nu$, we have:
          $$ \sum \lambda_i f_i(x) \le 0 \quad \text{and} \quad \sum \nu_j h_j(x) = 0 $$
          Thus, $L(x, \lambda, \nu) \le f_0(x)$. The Lagrangian is a <b>pointwise underestimator</b> of the objective function on the feasible set.</p>
        </div>
        <p>Why do we require $\lambda_i \ge 0$? To ensure the Lagrangian is a <b>lower bound</b> on the objective for feasible points.</p>
        <p>Let $x$ be any feasible point. Then $f_i(x) \le 0$ and $h_j(x) = 0$.
        <br>If $\lambda_i \ge 0$, then $\lambda_i f_i(x) \le 0$.
        <br>Thus:</p>
        $$
        \mathcal{L}(x, \lambda, \nu) = f_0(x) + \underbrace{\sum \lambda_i f_i(x)}_{\le 0} + \underbrace{\sum \nu_j h_j(x)}_{= 0} \le f_0(x)
        $$
        <p>If we allowed $\lambda_i < 0$, the term $\lambda_i f_i(x)$ would be positive, and $\mathcal{L}$ could exceed $f_0(x)$, breaking the lower bound property.</p>

        <h3>2.3 The Geometric Interpretation</h3>
        <p>Recall from <a href="../03-convex-sets-geometry/index.html">Lecture 03</a> that optimality is related to <b>supporting hyperplanes</b>. The Lagrangian is simply the algebraic representation of a hyperplane supporting the "achievable set" of objective and constraint values.
        <br>The multipliers $(\lambda, \nu)$ are the normal vector to this hyperplane. The condition $\lambda \ge 0$ ensures the hyperplane orientation respects the "less than or equal to" direction of the inequality constraints.</p>

        <figure class="animation-figure">
          <div class="animation-container">
            <img src="assets/duality_lagrangian_demo.gif" alt="Lagrangian Lower Bound Animation" loading="lazy">
          </div>
          <figcaption><i>Animation:</i> As $\lambda$ changes, the function $\mathcal{L}(x, \lambda)$ changes shape. For any $\lambda \ge 0$, $\min_x \mathcal{L}(x, \lambda)$ provides a lower bound on the constrained minimum. The "best" lower bound occurs at $\lambda^*$.</figcaption>
        </figure>

        <div class="example">
          <h4>Motivating Example: Primal Dual Optimization Walkthrough</h4>
          <p>Consider the simple problem:
          $$ \min_{x,y} x^2 + y^2 \quad \text{subject to} \quad x+y \ge 1 $$
          <br><b>1. Primal Problem:</b> The feasible region is the half-plane $x+y \ge 1$. The level sets of the objective are circles centered at the origin. Geometrically, the minimum is the point on the line $x+y=1$ closest to the origin, which is $(0.5, 0.5)$, yielding $p^* = 0.5$.</p>
          <p><b>2. Lagrangian:</b> $L(x, y, \lambda) = x^2 + y^2 + \lambda(1 - x - y)$. (Note the constraint $1-x-y \le 0$).</p>
          <p><b>3. Dual Function:</b> Minimize $L$ over unconstrained $x, y$:
          $$ \nabla_x L = 2x - \lambda = 0 \implies x^* = \lambda/2, \quad y^* = \lambda/2 $$
          $$ g(\lambda) = (\lambda/2)^2 + (\lambda/2)^2 + \lambda(1 - \lambda) = \lambda^2/2 + \lambda - \lambda^2 = \lambda - \lambda^2/2 $$</p>
          <p><b>4. Dual Problem:</b> Maximize $g(\lambda) = \lambda - \lambda^2/2$ for $\lambda \ge 0$.
          <br>$\nabla g = 1 - \lambda = 0 \implies \lambda^* = 1$.
          <br>Dual optimal value $d^* = g(1) = 1 - 0.5 = 0.5$.</p>
          <p><b>Result:</b> $p^* = d^* = 0.5$. Strong duality holds.</p>
        </div>

        <h3>2.4 The Minimax (Saddle Point) Interpretation</h3>
        <p>We can recover the primal problem from the Lagrangian by maximizing over the dual variables. Define the function:</p>
        $$
        \sup_{\lambda \succeq 0, \nu} \mathcal{L}(x, \lambda, \nu) = \sup_{\lambda \succeq 0, \nu} \left( f_0(x) + \sum \lambda_i f_i(x) + \sum \nu_j h_j(x) \right)
        $$
        <ul>
          <li><strong>If $\mathbf{x}$ is feasible:</strong> $f_i(\mathbf{x}) \le 0$ and $h_j(\mathbf{x})=0$. To maximize the sum, the best we can do is set $\lambda_i=0$ (since $\lambda_i \ge 0$ and $f_i(\mathbf{x}) \le 0$, any positive $\lambda$ would make the term negative). The $\nu$ term is always 0. Thus, the supremum is $f_0(\mathbf{x})$.</li>
          <li><strong>If $\mathbf{x}$ is infeasible:</strong>
            <ul>
              <li>If $f_i(x) > 0$, we can let $\lambda_i \to \infty$, making the sum $\infty$.</li>
              <li>If $h_j(x) \ne 0$, we can let $\nu_j \to \text{sign}(h_j(x)) \cdot \infty$, making the sum $\infty$.</li>
            </ul>
          </li>
        </ul>
        <p>Thus, the unconstrained problem $\min_x \sup_{\lambda \succeq 0, \nu} \mathcal{L}(x, \lambda, \nu)$ is exactly equivalent to the original constrained primal problem.</p>

        <figure class="animation-figure">
          <div class="animation-container">
            <img src="assets/duality_saddle_path.gif" alt="Saddle Point Path Animation" loading="lazy">
          </div>
          <figcaption><i>Animation:</i> The primal-dual dynamics seek the saddle point of the Lagrangian: minimizing over $x$ while maximizing over $\lambda$.</figcaption>
        </figure>

        <p>Consider a simple resource allocation example. The Primal seeks to minimize cost subject to meeting demand. The Dual sets prices for resources to maximize revenue while staying competitive. Strong duality means the minimum cost equals the maximum revenue, and the dual prices (shadow prices) reflect the true marginal value of the resources.</p>

        <div class="theorem-box">
            <h4>Deep Dive: Minimax Theorem and Zero-Sum Games</h4>
            <p>The duality gap for convex problems is intimately related to von Neumann's Minimax Theorem.
            <br>For a matrix game with payoff matrix $A$, player 1 minimizes loss $x^\top A y$ and player 2 maximizes gain.
            $$ \min_{x \in \Delta} \max_{y \in \Delta} x^\top A y = \max_{y \in \Delta} \min_{x \in \Delta} x^\top A y $$
            Linear programming duality is essentially the statement that this equality holds for linear constraints. Lagrangian duality extends this logic to general convex functions.</p>
        </div>

        <div class="intuition-box">
          <p><b>Duality as a Game:</b>
          <br><b>Primal:</b> $\min_x \max_{\lambda, \nu} \mathcal{L}(x, \lambda, \nu)$ (Minimizer moves first, Maximizer exploits violations).
          <br><b>Dual:</b> $\max_{\lambda, \nu} \min_x \mathcal{L}(x, \lambda, \nu)$ (Maximizer moves first, setting prices; Minimizer optimizes given prices).
          <br><b>Weak Duality</b> is simply the max-min inequality: $\max_{\lambda, \nu} \min_x \mathcal{L}(x, \lambda, \nu) \le \min_x \max_{\lambda, \nu} \mathcal{L}(x, \lambda, \nu)$. This inequality holds for <em>any</em> function, not just Lagrangians.
          <br><b>Strong Duality</b> implies the existence of a <b>Saddle Point</b> where the order of play doesn't matter, i.e., we can swap min and max.</p>
        </div>
      </section>

      <section class="section-card" id="section-3">
        <h2>3. The Lagrange Dual Function: Lower Bounds from Nowhere</h2>

        <div class="insight">
          <h4>The Core Idea</h4>
          <p>This is the first conceptual leap. We convert the Lagrangian $\mathcal{L}(x, \lambda, \nu)$ into a function of only the dual variables $(\lambda, \nu)$ by minimizing out $x$. This new function $g(\lambda, \nu)$ is the <b>engine</b> of duality.</p>
        </div>

        <h3>3.1 Dual Function Definition</h3>
        <p>The <a href="#" class="definition-link">dual function</a> $g: \mathbb{R}^m \times \mathbb{R}^p \to \mathbb{R} \cup \{-\infty\}$ is defined as the pointwise infimum of the Lagrangian over $x$:</p>
        $$
        g(\lambda, \nu) = \inf_{x \in \mathbb{R}^n} \mathcal{L}(x, \lambda, \nu) = \inf_{x \in \mathbb{R}^n} \left( f_0(x) + \sum_{i=1}^m \lambda_i f_i(x) + \sum_{j=1}^p \nu_j h_j(x) \right)
        $$
        <p><b>Note:</b> The infimum is over the <i>entire domain</i> of the functions (usually $\mathbb{R}^n$), not the feasible set. We have "relaxed" the constraints.</p>

        <div class="theorem-box">
          <h4>Key Property: Concavity</h4>
          <p>The dual function $g(\lambda, \nu)$ is <b>concave</b>, even if the primal problem is not convex.</p>
          <div class="proof-box">
            <h4>Proof</h4>
            <p>For each fixed $\mathbf{x}$, the function $(\lambda, \nu) \mapsto \mathcal{L}(\mathbf{x}, \lambda, \nu)$ is affine in $(\lambda, \nu)$.
            <br>The dual function $g$ is the pointwise infimum of a family of affine functions.
            <br>The infimum of concave (linear) functions is concave.</p>
            <p><b>The "One-Line" Proof:</b> For any $\lambda_1, \lambda_2 \ge 0$ and $\theta \in [0,1]$:
            $$ g(\theta\lambda_1 + (1-\theta)\lambda_2) = \inf_x L(x, \theta\lambda_1 + (1-\theta)\lambda_2) = \inf_x [\theta L(x,\lambda_1) + (1-\theta) L(x,\lambda_2)] $$
            $$ \ge \theta \inf_x L(x,\lambda_1) + (1-\theta) \inf_x L(x,\lambda_2) = \theta g(\lambda_1) + (1-\theta) g(\lambda_2) $$
            The inequality holds because $\inf$ of a convex combination is at least the convex combination of $\inf$s.</p>
            <p><b>Geometric Intuition:</b> For each fixed $x$, the Lagrangian is a "hyperplane" in $(\lambda, \nu)$-space. The dual function is the <b>lower envelope</b> of these hyperplanes. Lower envelopes of affine functions are always concave, regardless of the original problem's structure.</p>
          </div>
        </div>

        <figure class="animation-figure">
          <div class="animation-container">
            <img src="assets/duality_gap_convergence.gif" alt="Duality Gap Convergence Animation" loading="lazy">
          </div>
          <figcaption><i>Animation:</i> Visualizing the convergence of the primal value $f_0(x_k)$ (from above) and the dual bound $g(\lambda_k)$ (from below). The gap $f_0 - g$ goes to zero.</figcaption>
        </figure>

        <div class="proof-box">
          <h4>Deep Dive: The Dual of a Non-Convex Problem (Exercise 5.3)</h4>
          <p>We perform a rigorous derivation of the Lagrange dual for the problem $\min c^\top x$ subject to a single inequality $f(x) \le 0$. Crucially, we do <b>not</b> assume $f$ is convex.</p>
          <div class="proof-step">
            <strong>Step 0: The Primal Problem.</strong>
            Given $c \ne 0$ and $f: \mathbb{R}^n \to \mathbb{R} \cup \{+\infty\}$, we minimize $c^\top x$ subject to $f(x) \le 0$.
            $$ p^\star = \inf \{ c^\top x \mid f(x) \le 0 \} $$
            The feasible set might be nonconvex or disconnected.
          </div>
          <div class="proof-step">
            <strong>Step 1: The Lagrangian.</strong>
            We introduce a multiplier $\lambda \ge 0$. The Lagrangian is:
            $$ L(x, \lambda) = c^\top x + \lambda f(x) $$
            Since $\lambda \ge 0$, if $f(x) \le 0$, then $\lambda f(x) \le 0$. Thus $L(x, \lambda) \le c^\top x$ for all feasible $x$.
          </div>
          <div class="proof-step">
            <strong>Step 2: The Dual Function.</strong>
            The dual function is the best lower bound certified by $\lambda$:
            $$ g(\lambda) = \inf_x L(x, \lambda) = \inf_x (c^\top x + \lambda f(x)) $$
            This function $g(\lambda)$ is always concave (pointwise infimum of affine functions), regardless of $f$.
          </div>
          <div class="proof-step">
            <strong>Step 3: Introducing the Conjugate.</strong>
            Recall $f^*(y) = \sup_x (y^\top x - f(x))$.
            For $\lambda > 0$:
            $$ g(\lambda) = \lambda \inf_x \left( f(x) + \frac{c^\top x}{\lambda} \right) = \lambda \left[ -f^*\left(-\frac{c}{\lambda}\right) \right] $$
            For $\lambda = 0$: $g(0) = \inf c^\top x = -\infty$ (since $c \ne 0$).
          </div>
          <div class="proof-step">
            <strong>Step 4: The Dual Problem.</strong>
            We maximize $g(\lambda)$ over $\lambda > 0$:
            $$ \boxed{ \text{maximize } -\lambda f^*\left(-\frac{c}{\lambda}\right) \quad \text{subject to } \lambda > 0 } $$
          </div>
          <div class="proof-step">
            <strong>Step 5: Convexity.</strong>
            Why is this a convex problem?
            <ul>
              <li><b>Method A (General):</b> $g(\lambda)$ is the pointwise infimum of affine functions $L(x, \cdot)$, so it is concave.</li>
              <li><b>Method B (Specific):</b> The function $h(\lambda) = \lambda f^*(-c/\lambda)$ is the perspective transform of the convex function $f^*$, restricted to a line. Thus $h$ is convex, and $g(\lambda) = -h(\lambda)$ is concave.</li>
            </ul>
          </div>
        </div>

        <h3>3.2 Weak Duality (The Universal Inequality)</h3>
        <p>The fundamental property of the dual function is that it yields lower bounds on the optimal value $p^\star$.</p>

        <div class="theorem-box">
          <h4>Theorem (Weak Duality)</h4>
          <p>For <b>any</b> optimization problem (convex or not), and any $\lambda \succeq 0, \nu$:</p>
          $$
          g(\lambda, \nu) \le p^\star
          $$
          <div class="proof-box">
            <h4>Proof (3 lines)</h4>
            <p>For any feasible $\tilde{x}$ and any $\lambda \succeq 0$:</p>
            $$
            \begin{aligned}
            g(\lambda, \nu) &= \inf_x \mathcal{L}(x, \lambda, \nu) \le \mathcal{L}(\tilde{x}, \lambda, \nu) \quad \text{(infimum is } \le \text{ value at } \tilde{x}) \\
            &\le f_0(\tilde{x}) \quad \text{(by the Lower Bound Property from §2.2)}
            \end{aligned}
            $$
            <p>Since this holds for <i>every</i> feasible $\tilde{x}$, it holds for the infimum of the right side: $g(\lambda, \nu) \le \inf \{f_0(\tilde{x})\} = p^\star$.</p>
          </div>
        </div>

        <h3>3.3 Computing $g(\lambda, \nu)$: The Templates</h3>
        <p>Calculating the dual function means solving an unconstrained minimization problem parameterized by $\lambda, \nu$. There are three main patterns:</p>

        <div class="example">
          <h4>Template 1: Linear / Affine (Equality Constraints)</h4>
          <p>Lagrangian is linear in $x$: $L(x) = (c - A^\top \lambda)^\top x$.
          <br>$\inf_x L(x) = -\infty$ unless the slope is zero.
          <br><b>Result:</b> $g(\lambda) = \text{constant}$ if slope is 0, else $-\infty$.
          <br>This generates <b>dual equality constraints</b>.</p>
        </div>

        <div class="example">
          <h4>Template 2: Quadratic (Completing the Square)</h4>
          <p>Lagrangian is quadratic in $x$: $L(x) = \frac{1}{2}x^\top P x + q(\lambda)^\top x + r(\lambda)$ with $P \succ 0$.
          <br>Minimum occurs at $\nabla L = 0 \implies Px = -q(\lambda)$.
          <br><b>Result:</b> $g(\lambda) = -\frac{1}{2} q(\lambda)^\top P^{-1} q(\lambda) + r(\lambda)$.
          <br>This generates <b>dual quadratic objectives</b>.</p>
        </div>

        <div class="example">
          <h4>Template 3: Conjugate Functions</h4>
          <p>Lagrangian form: $L(x) = f(x) + y(\lambda)^\top x$.
          <br>$\inf_x (f(x) + y^\top x) = -\sup_x ((-y)^\top x - f(x)) = -f^*(-y)$.
          <br><b>Result:</b> $g(\lambda) = -f^*(-y(\lambda))$.
          <br>This is the general tool for non-quadratic problems (norms, exp, log).</p>
        </div>

        <div style="margin-top: 24px; border: 1px solid rgba(255,255,255,0.1); border-radius: 8px; overflow: hidden;">
          <iframe src="widgets/conjugate_function.html" width="100%" height="520" style="border:none; background:#0b0d12;"></iframe>
        </div>
      </section>

      <section class="section-card" id="section-4">
        <h2>4. The Dual Problem</h2>

        <h3>4.1 Definition</h3>
        <p>The <a href="#" class="definition-link">Lagrange dual problem</a> seeks the best lower bound:</p>
        <div style="padding: 16px; background: var(--panel); border-left: 4px solid var(--brand); margin: 16px 0;">
          <p style="margin: 0;">
            $
            \begin{aligned}
            \text{maximize} \quad & g(\lambda, \nu) \\
            \text{subject to} \quad & \lambda \succeq 0
            \end{aligned}
            $
          </p>
        </div>
        <p>This is a <b>convex optimization problem</b> (concave maximization is equivalent to convex minimization), regardless of the primal's properties.</p>

        <div class="insight">
          <h4>Why the Dual is Always Convex (Even When the Primal is Not)</h4>
          <p>This is a fundamental fact that deserves emphasis. The dual problem:</p>
          $$ \max_{\lambda \succeq 0, \nu} g(\lambda, \nu) $$
          <p>is <b>always a convex optimization problem</b>:</p>
          <ul>
            <li>The domain $\{\lambda \succeq 0\}$ is a convex set (the non-negative orthant).</li>
            <li>Maximizing a concave function is equivalent to minimizing a convex function.</li>
          </ul>
        </div>

        <h3>4.2 Weak Duality & Duality Gap</h3>
        <p>Let $d^*$ be the optimal value of the dual problem. We know $d^* \le p^*$. The difference $p^* - d^*$ is the <b>duality gap</b>.</p>

        <div class="insight">
          <h4>Bridge to Algorithms: The Stopping Criterion</h4>
          <p>The duality gap is the <b>universal speedometer</b> for optimization algorithms.
          <br>If you have a feasible primal point $x$ and a feasible dual point $(\lambda, \nu)$, then:
          $$ f_0(x) - g(\lambda, \nu) \ge p^* - d^* \ge 0 $$
          The quantity $f_0(x) - g(\lambda, \nu)$ is an upper bound on the suboptimality $f_0(x) - p^*$.
          <br><b>Algorithm Strategy:</b> Primal-dual algorithms (like Interior Point Methods) maintain feasible $x$ and $(\lambda, \nu)$ and iterate until the gap drops below a tolerance $\epsilon$.</p>
        </div>

        <div style="margin: 24px 0; border: 1px solid rgba(255,255,255,0.1); border-radius: 8px; overflow: hidden;">
          <iframe src="widgets/primal_dual_1d.html" width="100%" height="520" style="border:none; background:#0b0d12;"></iframe>
        </div>

        <figure class="animation-figure">
          <div class="animation-container">
            <img src="assets/duality_gap_convergence.gif" alt="Duality Gap Convergence Animation" loading="lazy">
          </div>
          <figcaption><i>Animation:</i> Visualizing the convergence of the primal value $f_0(x_k)$ (from above) and the dual bound $g(\lambda_k)$ (from below). The gap $f_0 - g$ goes to zero.</figcaption>
        </figure>

        <div class="example">
            <h4>Example: Non-Convex Problem with Duality Gap</h4>
            <p>We illustrate the duality gap with a simple discrete optimization problem where the feasible set is not convex.</p>
            <p><b>Primal Problem:</b>
            $$ \min x \quad \text{s.t.} \quad 2x = 1, \ x \in \{0, 1\} $$
            The constraint $2x=1$ requires $x=0.5$, but the domain is $\{0, 1\}$. Thus, the problem is infeasible and $p^* = +\infty$.</p>

            <p><b>Lagrangian:</b>
            $$ L(x, \nu) = x + \nu(1 - 2x) = (1-2\nu)x + \nu $$
            </p>

            <p><b>Dual Function:</b>
            The dual function minimizes the Lagrangian over the domain $D=\{0, 1\}$:
            $$ g(\nu) = \inf_{x \in \{0, 1\}} ((1-2\nu)x + \nu) = \min((1-2\nu)(0) + \nu, (1-2\nu)(1) + \nu) = \min(\nu, 1-\nu) $$
            </p>

            <p><b>Dual Problem:</b>
            Maximize $g(\nu) = \min(\nu, 1-\nu)$. The maximum occurs at $\nu = 0.5$, yielding $d^* = 0.5$.</p>

            <p><b>Result:</b> $p^* - d^* = \infty - 0.5 = \infty$. The duality gap is infinite, demonstrating that strong duality can fail for non-convex problems.</p>
        </div>
      </section>

      <section class="section-card" id="section-5">
        <h2>5. Strong Duality and Slater's Condition</h2>
        <p>Strong duality means $d^* = p^*$ (zero duality gap). It does not hold generally but usually holds for convex problems under mild conditions.</p>

        <div class="theorem-box">
          <h4>Theorem (Slater's Condition)</h4>
          <p>For a convex optimization problem:
          $$ \min f_0(x) \quad \text{s.t.} \quad f_i(x) \le 0, \quad Ax = b $$
          If there exists a point $\tilde{x} \in \mathrm{relint}(\mathcal{D})$ such that:
          $$ f_i(\tilde{x}) < 0, \quad i=1,\dots,m, \quad A\tilde{x} = b $$
          (strictly feasible for non-affine inequalities), then <b>strong duality holds</b> ($d^* = p^*$) and the dual optimal value is attained (if $p^* > -\infty$).</p>
        </div>

        <div style="margin-top: 24px; border: 1px solid rgba(255,255,255,0.1); border-radius: 8px; overflow: hidden;">
            <iframe src="widgets/slater_failure_dual_attainment.html" width="100%" height="520" style="border:none; background:#0b0d12;"></iframe>
        </div>

        <div class="proof-box">
          <h4>Geometric Proof via Separation</h4>
          <p>This proof constructs the dual variables as the coefficients of a separating hyperplane in the space of (constraints, objective).</p>
          <div class="proof-step">
            <strong>Step 1: The Set of Achievable Values $\mathcal{A}$.</strong>
            Consider the set of triplets $(u, v, t)$ that are "worse" than some feasible point $\mathbf{x}$:
            $$ \mathcal{A} = \{ (u, v, t) \mid \exists x \in \mathcal{D}, f_i(x) \le u_i, h_j(x) = v_j, f_0(x) \le t \} $$
            This set is convex.
          </div>
          <div class="proof-step">
            <strong>Step 2: Separation.</strong>
            The point $(0, 0, p^*)$ is on the boundary of $\mathcal{A}$. By the <a href="../03-convex-sets-geometry/index.html#section-3">Separating Hyperplane Theorem</a>, there exists a hyperplane separating $(0, 0, p^*)$ from $\mathcal{A}$. The normal vector gives the multipliers $(\lambda, \nu)$.
          </div>
          <div class="proof-step">
            <strong>Step 3: Slater's Condition.</strong>
            Slater's condition ensures the hyperplane is not vertical (i.e., it depends on the objective value $t$), which allows us to interpret it as a valid dual function lower bound.
          </div>
        </div>

        <div style="margin-top: 24px; border: 1px solid rgba(255,255,255,0.1); border-radius: 8px; overflow: hidden;">
            <iframe src="widgets/separation_two_disks.html" width="100%" height="520" style="border:none; background:#0b0d12;"></iframe>
        </div>
      </section>

      <section class="section-card" id="section-6">
        <h2>6. KKT Conditions</h2>

        <p>The Karush-Kuhn-Tucker (KKT) conditions provide a unified framework for optimality. For convex problems, they are necessary and sufficient.</p>

        <div class="theorem-box">
          <h4>Theorem (KKT Conditions)</h4>
          <p>Given a convex problem with differentiable functions that satisfies Slater's condition. $x^*$ and $(\lambda^*, \nu^*)$ are primal and dual optimal <b>if and only if</b>:</p>
          <ol>
            <li><b>Primal Feasibility:</b> $f_i(x^*) \le 0$, $h_j(x^*) = 0$.</li>
            <li><b>Dual Feasibility:</b> $\lambda^* \succeq 0$.</li>
            <li><b>Complementary Slackness:</b> $\lambda_i^* f_i(x^*) = 0$ for all $i$.</li>
            <li><b>Stationarity (Lagrangian Gradient):</b> $\nabla_x L(x^*, \lambda^*, \nu^*) = 0$:
              $$ \nabla f_0(x^*) + \sum \lambda_i^* \nabla f_i(x^*) + \sum \nu_j^* \nabla h_j(x^*) = 0 $$
            </li>
          </ol>
        </div>

        <div style="margin-top: 24px; border: 1px solid rgba(255,255,255,0.1); border-radius: 8px; overflow: hidden;">
          <iframe src="widgets/kkt_vector_balance.html" width="100%" height="520" style="border:none; background:#0b0d12;"></iframe>
        </div>

        <div class="proof-box">
          <h4>Derivation: The Tight Sandwich</h4>
          <p>We assume strong duality ($p^* = d^*$) and existence of primal/dual optimizers. Consider the chain:</p>
          $$
          \begin{aligned}
          d^* &= g(\lambda^*, \nu^*) \quad \text{(Dual Optimal Value)} \\
          &= \inf_x \mathcal{L}(x, \lambda^*, \nu^*) \quad \text{(Def of } g \text{)} \\
          &\le \mathcal{L}(x^*, \lambda^*, \nu^*) \quad \text{(Infimum is } \le \text{ value at } x^*) \\
          &\le f_0(x^*) \quad \text{(Lagrangian } \le \text{ Objective on feasible points)} \\
          &= p^* \quad \text{(Primal Optimal Value)}
          \end{aligned}
          $$
          <p>Since $d^* = p^*$, the entire chain collapses into equalities. Because Strong Duality holds ($d^* = p^*$), the start and end of this chain are equal. This forces <b>every inequality in the middle to be an equality</b>.</p>
          <div class="proof-step">
            <strong>Conclusion 1: Stationarity.</strong>
            The inequality $\inf_x L(x, \lambda^*, \nu^*) \le L(x^*, \lambda^*, \nu^*)$ becomes an equality.
            This implies that $\mathbf{x}^*$ is a global minimizer of the Lagrangian function $L(\mathbf{x}, \lambda^*, \nu^*)$ with respect to $\mathbf{x}$.
            If the functions are differentiable, the gradient at a global minimizer (of an unconstrained problem) must be zero:
            $$ \nabla_x L(x^*, \lambda^*, \nu^*) = 0 $$
          </div>
          <div class="proof-step">
            <strong>Conclusion 2: Complementary Slackness.</strong>
            The inequality $L(x^*, \lambda^*, \nu^*) \le f_0(x^*)$ is also an equality. This means:
            $$ \sum_{i=1}^m \lambda_i^* f_i(x^*) = 0 $$
            Since every term $\lambda_i^* f_i(x^*)$ is non-positive (product of $\ge 0$ and $\le 0$), the sum can only be zero if <b>every single term is zero</b>.
            $$ \lambda_i^* f_i(x^*) = 0, \quad \forall i $$
          </div>
        </div>

        <figure class="animation-figure">
          <div class="animation-container">
            <img src="assets/duality_kkt_2d_fast.gif" alt="2D KKT Geometry Animation" loading="lazy">
          </div>
          <figcaption><i>Animation:</i> 2D KKT geometry: the minimizer of the Lagrangian (unconstrained) moves as $\lambda$ changes. It hits the constraint boundary exactly when $\lambda$ is optimal, satisfying stationarity and feasibility simultaneously.</figcaption>
        </figure>

        <div class="insight">
          <h4>Geometric Interpretation via Normal Cones</h4>
          <p>The stationarity condition $-\nabla f_0(x^*) \in \sum \lambda_i \nabla f_i(x^*) + \sum \nu_j \nabla h_j(x^*)$ has a deep geometric meaning:
          $$ -\nabla f_0(x^*) \in N_{\mathcal{F}}(x^*) $$
          The negative gradient of the objective must lie in the <b>normal cone</b> of the feasible set at the optimal point.</p>
        </div>

        <div class="insight">
          <h4>Complementary Slackness "Switch"</h4>
          <p>$\lambda_i f_i(x) = 0$ acts as a switch:
          <br>$\bullet$ If the constraint is loose ($f_i < 0$), the multiplier must be zero ($\lambda_i = 0$, "free").
          <br>$\bullet$ If the multiplier is positive ($\lambda_i > 0$, "force"), the constraint must be tight ($f_i = 0$).</p>
        </div>

        <figure class="animation-figure">
          <div class="animation-container">
            <img src="assets/duality_comp_slack_switch.gif" alt="Complementary Slackness Switch Animation" loading="lazy">
          </div>
          <figcaption><i>Animation:</i> Complementary slackness in action. As the constraint relaxes (u increases), $\lambda^*$ drops to zero exactly when the constraint becomes inactive.</figcaption>
        </figure>
      </section>

      <section class="section-card" id="section-7">
        <h2>7. Sensitivity Analysis ("Shadow Prices")</h2>

        <p>Duality provides powerful insights into how the optimal value changes when constraints are perturbed.</p>

        <h3>7.1 The Value Function</h3>
        <p>Consider the perturbed primal problem with optimal value $p^*(u, v)$ where $f_i(x) \le u_i$ and $h_j(x) = v_j$.
        <br>If the original problem is convex, $p^*(u, v)$ is convex.</p>

        <h3>7.2 Global Inequality</h3>
        <p>Using weak duality on the perturbed problem, we can show:</p>
        $$ p^*(u, v) \ge p^*(0, 0) - \lambda^{*\top} u - \nu^{*\top} v $$
        <p>This means $(-\lambda^*, -\nu^*)$ is a <b>subgradient</b> of the value function at zero:
        $$ (-\lambda^*, -\nu^*) \in \partial p^*(0, 0) $$
        </p>

        <div style="margin-top: 24px; border: 1px solid rgba(255,255,255,0.1); border-radius: 8px; overflow: hidden;">
          <iframe src="widgets/value_function_support.html" width="100%" height="520" style="border:none; background:#0b0d12;"></iframe>
        </div>

        <figure class="animation-figure">
          <div class="animation-container">
            <img src="assets/duality_sensitivity_supporting_line_fast.gif" alt="Sensitivity Analysis Animation" loading="lazy">
          </div>
          <figcaption><i>Animation:</i> The dual variable $\lambda$ defines the slope of a supporting line to the value function $p(u)$. At optimality, this line is tangent (or supporting) at $u=0$.</figcaption>
        </figure>

        <h3>7.3 Local Sensitivity</h3>
        <p>If $p^*(u, v)$ is differentiable, then:
        $$ \frac{\partial p^*(0, 0)}{\partial u_i} = -\lambda_i^*, \quad \frac{\partial p^*(0, 0)}{\partial v_j} = -\nu_j^* $$
        Relaxing constraint $i$ ($u_i > 0$) improves the objective by approximately $\lambda_i^* u_i$. This is why dual variables are called <b>shadow prices</b>.</p>
      </section>

      <section class="section-card" id="section-8">
        <h2>8. Certificates of Infeasibility</h2>
        <p>Duality can also prove that a problem is infeasible (primal) or unbounded below.</p>

        <div class="insight">
          <h4>Farkas' Lemma and Dual Rays</h4>
          <p>If the primal problem is infeasible, the dual problem is typically unbounded. We can find a "dual ray" (direction) along which the dual objective goes to $+\infty$.
          <br><b>Farkas' Lemma:</b> The system $Ax \le b$ is infeasible if and only if there exists $y \ge 0$ such that $A^\top y = 0$ and $b^\top y < 0$.
          <br>This vector $y$ is a <b>certificate of infeasibility</b>.</p>
        </div>

        <figure class="animation-figure">
          <div class="animation-container">
            <img src="assets/duality_farkas_xy_infeasible.gif" alt="Farkas Infeasibility Certificate Animation" loading="lazy">
          </div>
          <figcaption><i>Animation:</i> A visual demonstration of Farkas' Lemma. If two halfspaces don't intersect, there is a specific dual vector that proves it.</figcaption>
        </figure>
      </section>

      <section class="section-card" id="section-9">
        <h2>9. Canonical Duals: A Pattern Library</h2>
        <p>We conclude with a library of standard dual derivations. Recognizing these patterns is key to practical usage.</p>

        <div style="margin-top: 24px; border: 1px solid rgba(255,255,255,0.1); border-radius: 8px; overflow: hidden;">
          <iframe src="widgets/equality_dual_projection_2d.html" width="100%" height="520" style="border:none; background:#0b0d12;"></iframe>
        </div>

        <div class="example">
          <h4>1. Linear Programming (LP)</h4>
          <p>Primal: $\min c^\top x$ s.t. $Ax = b, x \ge 0$.
          <br>Constraints: $h(x) = Ax - b$, $f(x) = -x$.
          <br>Lagrangian: $L(x, \lambda, \nu) = c^\top x - \sum \lambda_i x_i + \nu^\top (Ax - b) = -b^\top \nu + (c + A^\top \nu - \lambda)^\top x$.
          <br>Dual function:
          $$ g(\lambda, \nu) = \inf_{x} L(x, \lambda, \nu) = \begin{cases} -b^\top \nu & \text{if } c + A^\top \nu - \lambda = 0 \\ -\infty & \text{otherwise} \end{cases} $$
          Dual Problem: Maximize $-b^\top \nu$ subject to $A^\top \nu + c = \lambda, \lambda \ge 0$.
          <br>Eliminating $\lambda$: Maximize $-b^\top \nu$ subject to $A^\top \nu + c \ge 0$ (i.e., $A^\top (-\nu) \le c$).
          <br>Usually written with $y = -\nu$: Maximize $b^\top y$ s.t. $A^\top y \le c$. Standard LP dual.</p>
        </div>

        <div class="example">
          <h4>2. Quadratic Programming (QP)</h4>
          <p>Primal: $\min \frac{1}{2}x^\top P x + q^\top x$ s.t. $Ax \le b$. ($P \succ 0$).
          <br>Dual: $\max -\frac{1}{2} (q + A^\top \lambda)^\top P^{-1} (q + A^\top \lambda) - b^\top \lambda$ s.t. $\lambda \ge 0$.
          <br>Derivation: Complete the square in the Lagrangian.</p>
        </div>

        <div class="example">
          <h4>3. Entropy Maximization</h4>
          <p>Primal: $\min \sum x_i \log x_i$ s.t. $Ax = b, \mathbf{1}^\top x = 1$.
          <br>Dual uses the conjugate of $x \log x$, which is $\log \sum e^{y_i}$.</p>
        </div>

        <div style="margin-top: 24px; border: 1px solid rgba(255,255,255,0.1); border-radius: 8px; overflow: hidden;">
          <iframe src="widgets/logsumexp_conjugate_widget.html" width="100%" height="520" style="border:none; background:#0b0d12;"></iframe>
        </div>

        <div class="example">
          <h4>4. Conic Duality (SOCP/SDP)</h4>
          <p>For generalized inequalities $x \succeq_K 0$, dual variables live in the dual cone $K^*$.
          <br><b>SOCP:</b> $K$ is the Second-Order Cone (Self-dual).
          <br><b>SDP:</b> $K$ is the Positive Semidefinite Cone (Self-dual).</p>
        </div>

        <div style="margin-top: 24px; border: 1px solid rgba(255,255,255,0.1); border-radius: 8px; overflow: hidden;">
          <iframe src="widgets/soc_dual_cone.html" width="100%" height="520" style="border:none; background:#0b0d12;"></iframe>
        </div>

        <div style="margin-top: 24px; border: 1px solid rgba(255,255,255,0.1); border-radius: 8px; overflow: hidden;">
          <iframe src="widgets/psd_cone_2x2.html" width="100%" height="520" style="border:none; background:#0b0d12;"></iframe>
        </div>
      </section>

      <section class="section-card" id="section-10">
        <h2>10. Exercises</h2>
        <div class="problem">
          <h3>P9.1 — Deriving the Dual of a Quadratic Program</h3>
          <p>Consider the QP: $\min x^\top x$ subject to $Ax \preceq b$.
          <br>(a) Derive the Lagrange dual function $g(\lambda)$.
          <br>(b) State the dual problem explicitly.
          <br>(c) Verify weak duality directly for any feasible $\mathbf{x}$ and $\lambda$.</p>
        </div>

        <div class="problem">
          <h3>P9.2 — KKT for Standard QP</h3>
          <p>Consider the Quadratic Program:</p>
          $$ \min_x \frac{1}{2} x^\top P x + q^\top x \quad \text{s.t.} \quad Ax \le b $$
          <p>where $P \in \mathbb{S}^n_{++}$ (positive definite).</p>
          <p><strong>(a)</strong> Write down the KKT conditions for this problem.</p>
          <p><strong>(b)</strong> Combine them to show that solving the KKT system is equivalent to solving a system of equations involving the active set.</p>
        </div>

        <div class="problem">
          <h3>P9.3 — Sensitivity Analysis</h3>
          <p>Consider $\min x^2$ s.t. $x \le -1$. Optimal $x^*=-1, p^*=1$.
          <br>Perturb to $\mathbf{x} \le -1 + u$. New optimum $\mathbf{x}^* = -1+u$ (for small $u$), $p^*(u) = (-1+u)^2 \approx 1 - 2u$.
          <br>Find the dual optimal $\lambda^*$ of the original problem and verify $p^*(u) \approx p^*(0) - \lambda^* u$.</p>
        </div>

        <div class="problem">
          <h3>P9.4 — Farkas' Lemma</h3>
          <p>Use Strong Duality for LP to prove Farkas' Lemma:
          Exactly one of the following systems has a solution:
          <ol>
            <li>$Ax = b, \ x \ge 0$</li>
            <li>$A^\top y \ge 0, \ b^\top y < 0$</li>
          </ol>
          </p>
        </div>

        <div class="problem">
          <h3>P9.5 — Water-filling (Channel Capacity)</h3>
          <p>Problem: $\min -\sum \log(\alpha_i + x_i)$ subject to $x \ge 0, \sum x_i = 1$.
          <br>Derive the KKT conditions and show the solution is $x_i = \max(0, 1/\nu - \alpha_i)$. Interpret this as water-filling.</p>
        </div>

        <div class="problem">
          <h3>P9.6 — Support Vector Machine (Hinge Loss)</h3>
          <p><b>Primal:</b> $\min \frac{1}{2}\|w\|^2 + C \sum \max(0, 1 - y_i w^\top x_i)$.
          <br>Rewrite as $\min \frac{1}{2}\|w\|^2 + C \sum \xi_i$ s.t. $\xi_i \ge 1 - y_i w^\top x_i, \xi_i \ge 0$.
          <br>Derive the dual problem and show it involves constraints $0 \le \alpha_i \le C$.</p>
        </div>

        <div class="problem">
          <h3>P9.7 — LASSO Dual</h3>
          <p><b>Primal:</b> $\min \frac{1}{2}\|Ax - b\|_2^2 + \lambda \|x\|_1$.
          <br>Rewrite with $y = Ax - b$ and derive the dual problem. Show the dual constraint is $\|A^\top \nu\|_\infty \le \lambda$.</p>
        </div>

        <div class="problem">
          <h3>P9.8 — Semidefinite Programming (Max Cut Relaxation)</h3>
          <p>The Max Cut problem can be relaxed to the following SDP:
          $$ \max_X \quad \frac{1}{4} \mathrm{tr}(W X) \quad \text{s.t.} \quad X_{ii} = 1, \quad X \succeq 0 $$
          where $W$ is the weighted adjacency matrix. Derive the dual problem.</p>
        </div>
      </section>

      <section class="section-card" id="section-11">
        <h2>11. Further Applications (Advanced)</h2>
        <div class="problem">
          <h3>P9.9 — The Gap Certificate Cookbook</h3>
          <p>For each of the following problems, determine the dual variables, the dual objective function $d(\lambda, \nu)$, and the formula for the duality gap $\text{gap} = p(x) - d(\lambda, \nu)$.</p>
          <ol>
            <li><b>Least Squares:</b> $\min_x \frac{1}{2}\|Ax-b\|_2^2$ (Use the equivalent constrained form $\min \frac{1}{2}\|y\|_2^2$ s.t. $y=Ax-b$)</li>
            <li><b>Ridge Regression:</b> $\min_x \frac{1}{2}\|Ax-b\|_2^2 + \frac{\lambda}{2}\|x\|_2^2$</li>
            <li><b>LASSO:</b> $\min_x \frac{1}{2}\|Ax-b\|_2^2 + \rho \|x\|_1$</li>
            <li><b>Basis Pursuit:</b> $\min_x \|x\|_1$ s.t. $Ax=b$</li>
          </ol>
        </div>

        <div class="problem">
          <h3>P9.10 — SDP Duality: Max Cut Relaxation</h3>
          <p>The Max Cut problem can be relaxed to the following SDP:
          $$ \max_X \quad \frac{1}{4} \mathrm{tr}(W X) \quad \text{s.t.} \quad X_{ii} = 1, \quad X \succeq 0 $$
          where $W$ is the weighted adjacency matrix. Derive the dual problem.</p>
        </div>

        <div class="problem">
          <h3>P9.11 — SOCP Duality: Robust Least Squares</h3>
          <p>Derive the dual of the Robust Least Squares problem:
          $$ \min_x \|Ax - b\|_2 + \rho \|x\|_2 $$
          Formulate the primal as an SOCP first.</p>
        </div>

        <div class="problem">
          <h3>P9.12 — Chebyshev Approximation vs Least Squares</h3>
          <p>Consider the problem of minimizing the $\ell_\infty$ norm of the residual: $p^* = \min_x \|Ax - b\|_\infty$.
          <br>Let $x_{ls}$ be the least-squares solution ($p_{ls} = \min \|Ax-b\|_2$).
          <br><strong>(a)</strong> Prove that the least-squares solution provides a $\sqrt{m}$-approximation: $\|Ax_{ls} - b\|_\infty \le \sqrt{m} p^*$.
          <br><strong>(b)</strong> Derive the dual problem and show how to construct a lower bound certificate using the least-squares residual.</p>
        </div>

        <div class="problem">
          <h3>P9.13 — Log-Sum-Exp Smoothing and Entropy</h3>
          <p>Consider minimizing the piecewise-linear function $f(x) = \max_i (a_i^\top x + b_i)$.
          <br><strong>(a)</strong> Derive the dual of the smooth approximation $f_{sm}(x) = \log(\sum \exp(a_i^\top x + b_i))$.
          <br><strong>(b)</strong> Show that the smoothing corresponds to adding an entropy regularization term to the dual.</p>
        </div>

        <div class="problem">
          <h3>P9.14 — Ellipsoid Volume Minimization (Löwner-John Approximation)</h3>
          <p><strong>Context:</strong> We seek the minimum-volume ellipsoid $\mathcal{E}(X) = \{x \in \mathbb{R}^n \mid x^\top X x \le 1\}$ centered at the origin that contains a set of points $a_1, \dots, a_m \in \mathbb{R}^n$ (which span $\mathbb{R}^n$).
          <br>This is formulated as the convex problem:
          $$ \min_{X \in \mathbb{S}_{++}^n} \log \det(X^{-1}) \quad \text{s.t.} \quad a_i^\top X a_i \le 1, \quad i=1,\dots,m $$
          Consider the simple candidate solution $X_{\text{sim}} = \left(\sum_{k=1}^m a_k a_k^\top\right)^{-1}$.
          <br><strong>(a)</strong> Prove that $X_{\text{sim}}$ is feasible (contains all points).
          <br><strong>(b)</strong> Use the dual problem to prove that the volume of $\mathcal{E}(X_{\text{sim}})$ is at most $(\frac{m}{n})^{n/2}$ times the optimal volume.</p>
        </div>
      </section>

    </article>

    <footer class="site-footer">
      <div class="container">
        <p>© <span id="year"></span> Convex Optimization Course</p>
      </div>
    </footer>
  </main></div>

  <script src="../../static/js/math-renderer.js"></script>
  <script src="../../static/js/ui.js"></script>
  <script src="../../static/js/toc.js"></script>
  <script>
    feather.replace();
    document.getElementById('year').textContent = new Date().getFullYear();
  </script>
  <script src="../../static/js/glossary-loader.js"></script>
  <script src="../../static/js/notes-widget.js"></script>
  <script src="../../static/js/pomodoro.js"></script>
  <script src="../../static/js/progress-tracker.js"></script>
</body>
</html>